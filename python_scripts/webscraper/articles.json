[
    {
        "url": "https://iapp.org/news/a/european-commission-holds-firm-on-ai-act-implementation-timeline",
        "title": "European Commission holds firm on AI Act implementation timeline",
        "location": "Europe",
        "date_published": "7 July 2025",
        "keywords": [
            "AI Governance",
            "Frameworks & Standards",
            "Law & Regulation"
        ],
        "description": "The European Commission is not considering a pause on the implementation or enforcement of the landmark EU Artificial Intelligence Act, even as policymakers mull a broader simplification of the bloc's digital rulebook.",
        "content": [
            "The European Commission is not considering a pause on the implementation or enforcement of the landmark EU Artificial Intelligence Act, even as policymakers mull a broader simplification of the bloc's digital rulebook.",
            "During a 4 July press briefing, Commission spokesperson Thomas Regnier ended speculation regarding a potential delay on AI rules with the August deadline for general-purpose AI compliance approaching and a voluntary GPAI code of practice unpublished.",
            "\"Let me be clear as possible: there is no stop the clock, there is no grace period, there is no pause,\" said Regnier, noting the firm stance relates to legal obligations to uphold implementation deadlines. In a LinkedIn post further elaborating on his comments, Regnier noted the Commission is working on setting up an AI Act service desk to provide business compliance assistance.",
            "He did indicate there is ongoing consideration for delaying implementation of GPAI code until the end of 2025. While the code is nonbinding, adherence to its principles helps signal compliance with the AI Act's general-purpose requirements.",
            "The code was due to be finalized in May after multiple draft iterations, but debate over the contents of the code have created a lag. European Commission Executive Vice-President for Technological Sovereignty, Security and Democracy Henna Virkkunen said the finalized text is expected to be published before August.",
            "Before the Commission's latest comments, Virkkunen put consideration into a version of an enforcement delay sought by a group of EU member states. Poland pitched a potential pause during a 5 June European Council Transport, Telecommunications and Energy Council meeting, while the Czech Republic went as far as calling for a delay of at least two years.",
            "European and U.S. companies are also advocating for a delay. According to The Financial Times, Airbus and Mistral AI are among the companies that joined an open letter to the Commission on how the complex set of digital regulatory rules in Europe will make it difficult for companies to deploy AI at scale. The group called for a two-year delay to AI Act obligations as well as postponing enforcement until practical standards and guidance are in place.",
            "\"This is not a call for delay for delay's sake. It's a call for strategic implementation to ensure regulation protects what matters most without compromising innovation or industrial leadership,\" the letter stated.",
            "According to Reuters, the Computer and Communications Industry Association Europe, a trade group whose members include Alphabet, Meta and Apple, are also lobbying for a relaxed approach to implementation.",
            "On the other hand, members of civil society support the Commission going full steam ahead with implementation. Corporate Europe Observatory researcher Bram Vranken said any delay would play into some companies' desire for less regulation overall and promote products and services that could potentially hurt consumers.",
            "\"But while there is widespread support among citizens to enforce the EU's digital rule-book, the Commission's misguided obsession with competitiveness and deregulation is putting fundamental rights on the line in favour of Big Tech's corporate interests,\" he said in a press release.",
            "Some members of the European Parliament have questioned whether a delay would benefit anyone in the long run. Irish MEP Michael McNamara said during the IAPP and Berkman Klein Center For Internet and Society's Digital Policy Leadership Retreat 2025 a delay is logical but could hurt EU regulatory efforts in the long run.",
            "\"I think a delay is acceptable, but there comes a point at which any delay, if it's for a long time, just kind of deprives (the regulation) of the momentum it needs to work. That would be a concern,\" he said.",
            "The Commission has been considering an omnibus package of digital simplification rules, which is expected by the end of the year. According to Euractiv, a separate Commission spokesperson said, \"all options remain open for consideration at this stage\" with the omnibus.",
            "Caitlin Andrews is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-asia-pacific-region-indias-digital-landscape-marches-ahead",
        "title": "Notes from the Asia-Pacific region: India's digital landscape marches ahead",
        "location": "",
        "date_published": "3 July 2025",
        "keywords": [
            "Telecommunications",
            "AI Governance",
            "Biometrics",
            "Law & Regulation",
            "Children's Privacy"
        ],
        "description": "While the monsoon season starts its annual sweep across India bringing rain that provides the much-awaited respite from the hot summer months, the growth of the digital landscape in India is hardly seasonal, marching ahead rapidly. The country's digital trust and governance community watches this march with a mix of awe and apprehension, often tearing our hair out about the accompanying risks.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "While the monsoon season starts its annual sweep across India bringing rain that provides the much-awaited respite from the hot summer months, the growth of the digital landscape in India is hardly seasonal, marching ahead rapidly. The country's digital trust and governance community watches this march with a mix of awe and apprehension, often tearing our hair out about the accompanying risks.",
            "The optimist in me chooses to observe the streaks of silver lining.",
            "For those of us who patiently wait to hear any news pertaining to India's Digital Personal Data Protection Act, which has yet to become operational, some news emerged a couple days ago. The Economic Times reported it is likely the DPDPA may be referred to the Attorney General of India for an opinion on whether it dilutes the powerful Right to Information Act.",
            "While discussion on this has been going on since the DPDPA was passed, this is the first time any action relating to it has been reported. Its impact on the roll-out of the law could be potentially significant, much delayed as it already is.",
            "While on the topic of privacy, the Telecom Regulatory Authority of India announced the launch of a pilot for rolling out digital consent in the sphere of telemarketing. Given how intrusive and voluminous unwanted telemarketing calls have become for the average user, this is the latest in a series of measures by the TRAI.",
            "In this latest endeavor, telemarketing entities would be required to obtain explicit digital consent from users. Further, the consent would need to be registered \"in a secure and interoperable digital consent registry maintained by the Telecom Service Providers (TSPs) for easy verification of consents while commercial communication is made to the consumers.\"",
            "Dark patterns, another area impacting a large swathe of consumers, also saw some action. Given how an average user can be manipulated via design tactics into making choices they would not have otherwise, and the growing complaints associated, the Department of Consumer Affairs issued a press release requiring e-commerce platforms to address the problem.",
            "It has set up a Joint Working Group to \"identify and eradicate dark patterns\" and given platforms a three-month deadline to conduct self-audits to identify dark patterns in their operations and take steps to mitigate them. Further, the advisory asks the platforms to make self-declarations about nonindulgence in such activities.",
            "Meanwhile, regulators are gradually starting to show awareness of the adoption of artificial intelligence. After the Reserve Bank of India, the Securities and Exchange Board of India \u2014 the regulator for the securities sector covering exchanges, brokerages and mutual funds \u2014 has spoken up.",
            "In a consultation paper titled \"Guidelines for Responsible Usage of AI/ML in Indian Securities Market\" released 20 June, the SEBI articulated five key principles as the basis for governance of AI applications in the securities market. These include model governance, investor protection, testing framework, fairness and bias, and data privacy and cyber security measures. Comments and feedback is requested by 11 July.",
            "As baby steps are being taken on the regulatory front, the digital juggernaut powers on, raising several questions around associated risks.",
            "For instance, the Ministry of Electronics and Information Technology recently announced that the Unique Identification Authority of India \u2014 the authority that operates and oversees the critical Aadhaar identity ecosystem of 1.4 billion Indians \u2014 is sharing \"non-personal\" and \"anonymized\" Aadhaar data with India's open government data platform.",
            "This set off a flurry of criticisms from a variety of stakeholders centering around the risk of re-identification and lack of a legal framework in India around nonpersonal and anonymized data.",
            "In another development, the Ministry of Women and Child Development issued a 30 May directive mandating the use of facial recognition systems to authenticate beneficiaries and record attendance under the Poshan Abhiyaan scheme \u2014 which provides benefits like food rations and mid-day meals to children in government-run schools and childcare centers. This requires collection of facial data of children under the age of 6. At age 6, children in India become eligible to obtain an independent Aadhaar card \u2014 so this means 80 million children across 1.4 million Anganwadi centers.",
            "Finally, some interesting statistics.",
            "According to the recently published \"2024 Piracy Trends and Insights\" report from the Museum of Solutions, India ranked second in global piracy traffic \u2014 second only to the U.S. A cringeworthy statistic, for sure.",
            "In a recent report by the Telecom Regulatory Authority of India on telecom subscription data, there was a 0.11% decline in April 2025 in broadband users. At the same time, emerging technologies like fixed wireless access and machine-to-machine are gaining momentum, particularly in rural areas. For example, fixed wireless access subscribers went from 6.7 million to 7.5 million.",
            "To understand the context of this: Fixed line internet is scarce in rural areas even now. Ambitious government programs are being rolled out to address this. One of the flagship programs is the BharatNet project, an initiative to get broadband to all villages in India \u2014 which number over 250,000. Fixed wireless access enables the last mile here.",
            "Hopefully the various initiatives to provide the necessary guardrails to the digital juggernaut that is India start seeing the light of day rapidly. One does not need to articulate to this community of readers the implications otherwise.",
            "Shivangi Nadkarni is senior vice president and general manager, digital governance at Persistent Systems.",
            "This article originally appeared in the Asia-Pacific Dashboard Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/a-view-from-brussels-will-the-eu-pause-the-ai-act",
        "title": "A view from Brussels: Will the EU pause the AI Act?",
        "location": "Europe",
        "date_published": "3 July 2025",
        "keywords": ["AI Governance", "Law & Regulation", "Enforcement"],
        "description": "Hitting the pause button. Voices calling for a pause in the implementation of the EU Artificial Intelligence Act grew louder this past month. In early June, European Commission Executive Vice-President Henna Virkkunen noted the option was on the table, saying the EU \"should not rule out postponing some parts of the AI Act\" if standards and guidelines were not ready in time. This week, Virkkunen clarified a decision would be made by late August, turning rumors into real prospects.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "Hitting the pause button. Voices calling for a pause in the implementation of the EU Artificial Intelligence Act grew louder this past month. In early June, European Commission Executive Vice-President Henna Virkkunen noted the option was on the table, saying the EU \"should not rule out postponing some parts of the AI Act\" if standards and guidelines were not ready in time. This week, Virkkunen clarified a decision would be made by late August, turning rumors into real prospects.",
            "The AI Act entered into force a year ago with a phased implementation, most of its requirements becoming applicable by 2 Aug. 2026. Halfway through this transition period, a lot is still needed to get EU-harmonized standards and guidelines ready, meaning operators in scope will have at best one year to get clarity on what good looks like under the AI Act, and to make it happen internally and across their supply chains as needed.",
            "Shorter term, a 2 Aug. deadline is also coming up quickly for obligations to go into effect. New obligations will apply to providers of general-purpose AI models, member states must appoint their competent authorities, and the Commission should conduct an annual review of the list of prohibited AI.",
            "Industry, civil society, government and elected officials are divided on what to think of the potential pause. For some, a delay is necessary to provide legal certainty and clarity on rules for proper implementation. The European technology industry even argues the same rationale should be extended to the Data Act.",
            "\"New data-sharing obligations kick in this September, with unclear rules and high risks for Europe's data economy. A one-year delay is essential,\" Director General of DIGITALEUROPE Cecilia Bonefeld-Dahl said on LinkedIn.",
            "For others, pausing now could lead to politicizing what should remain a technical process, at a time when many organizations are already building their AI governance programs because that is what their business requires.",
            "The dilemma around pausing AI Act implementation happens at a complicated time for the European Commission.",
            "First, the Commission must navigate optics and political atmospherics. When adopted, then-commissioner Thierry Breton dubbed the act as \"historic,\" seeing it as much more than a rulebook and as a launchpad for EU startups and researchers to lead the global AI race. Which begs the question: What might be the impact of Europe's AI performance? Would it slow down, fare equally well, or even improve?",
            "Let's not lose sight of the fact that the AI Act is only a portion of Europe's broader AI strategy, which cuts across computing power with a newly adopted Quantum Europe Strategy, capacity building with AI factories, skills and talent, data rules updates, and initiatives to accelerate AI adoption \u2014 much of it folded under the AI Continent Action Plan.\u00a0",
            "The turbulent trans-Atlantic relationship also means Europe has a tough balancing act. It is leading Europe to stand even stronger on its values, defending its digital rulebook as non-negotiable as a trade war looms, while pursuing a competitiveness and simplification agenda fully recognizing the rulebook is complicated, and that some pragmatism is needed when it comes to its impact in practice on European businesses.",
            "Amid all this, European Commission President Ursula von der Leyen is facing a no-confidence vote before European Parliament next week, following months of mounting frictions. The motion is unlikely to be adopted, but it is indicative of the fragility of her personal situation and shows negotiations with parliamentarians to roll-out the Commission's agenda may be very challenging at times.",
            "It is in this context that the rotating Presidency of the Council of the European Union went from Poland to Denmark. In a short video address, Danish Prime Minister Mette Frederiksen expressed that \"Europe is at a defining moment in time,\" putting the focus on her presidency squarely on rearming Europe, boosting Ukraine security, and tackling migration as a \"great challenge to the social balance of our societies.\" She also underlined the need for fewer burdens, more strategic investments and boosting the green transition as a driver for growth and jobs.",
            "Isabelle Roccia, CIPP/E, is the managing director, Europe, for the IAPP.",
            "This article originally appeared in the Europe Data Protection Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/latin-america-the-caribbean-caught-in-the-middle-on-ai-governance",
        "title": "Latin America, the Caribbean caught in the middle on AI governance",
        "location": "Europe, North America",
        "date_published": "2 July 2025",
        "keywords": ["AI Governance", "Law & Regulation"],
        "description": "Artificial intelligence governance is set to become a defining issue in the geopolitics of global digital trade. The U.S. and EU, major players in the digital economy, have signaled their respective policy positions for the development, growth and governance of AI \u2014 differing notably on balancing AI innovation and development with appropriate governance frameworks and regulatory oversight.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "Artificial intelligence governance is set to become a defining issue in the geopolitics of global digital trade. The U.S. and EU, major players in the digital economy, have signaled their respective policy positions for the development, growth and governance of AI \u2014 differing notably on balancing AI innovation and development with appropriate governance frameworks and regulatory oversight.",
            "In January 2025, U.S. President Donald Trump rescinded the former Biden administration's executive order on AI safety with the clear aim of deregulating the federal government's use of AI. In early June 2025, the U.S. House of Representatives passed President Donald Trump's spending and tax bill, which included a 10-year moratorium on all state and local laws related to artificial intelligence. The Senate, however, overwhelmingly voted to remove the proposed moratorium. The U.S. does not have any comprehensive federal legislation or regulations on the development of AI, or prohibiting or restricting its use. The result could be a fragmented approach to AI governance with states adopting varying legislative approaches to the regulation of AI. ",
            "The U.S. position stands in stark contrast to the EU, which passed the AI Act in August 2024 \u2014 widely regarded as pioneering legislation that will ensure ethical, trustworthy and responsible AI development. The European Commission is working with European standardization organizations to draft the necessary AI standards to complement the act's provisions.",
            "This contrasting approach is not new to the digital landscape. The U.S. and EU navigated the invalidated EU-U.S. Privacy Shield's evolution to the EU-U.S. Data Privacy Framework in order to comply with data transfer requirements of the EU General Data Protection Regulation and its predecessor the EU Data Protection Directive.",
            "As the geopolitical clash over AI governance evolves, the policy positions which Latin America and the Caribbean adopt will require careful observation in the context of the digital economy. According to the 2023 UN Trade and Development statistics on digitally deliverable services, those services made up 35% of Latin America and the Caribbean's total services exports. That compares to 65.6% in North America, 60% in Europe and 51.4% in Asia.",
            "The 2023 Digital Government Index for Latin America and the Caribbean, published by the Organisation for Economic Co-operation and Development and the Inter-American Development Bank, noted the region made significant progress in strengthening digital government institutions to \"enhance public services and improve governance through digital government strategies.\"",
            "The report also noted, however, that few countries in the region are proactively engaging emerging technologies like AI, with only 22% establishing a comprehensive AI strategy for the public sector. The report also recorded that 78% of countries in the region have not \"established frameworks for the trustworthy management of algorithms.\"",
            "It is in this context that the region finds itself wedged between the competing policy frameworks of the EU and the U.S. on AI governance. Interestingly, most data protection legislation in Latin America and the Caribbean adopt core principles similar to the GDPR, with specific requirements varying by jurisdiction.",
            "Since the AI Act builds on and complements the GDPR framework, Latin America and the Caribbean could naturally lean toward the EU model for developing its legislative frameworks governing AI, while leveraging existing data protection and privacy frameworks.",
            "While there is interplay between the AI Act and the GDPR on the protection of fundamental rights and freedoms related to personal data and privacy, the AI Act's focus on AI systems creates an underlying objective linked to product liability and safety. As the act's opening recital states, its objective is to lay down a framework for \"the development, the placing on the market, the putting into service and the use of AI systems.\"",
            "The challenge for Latin America and the Caribbean will be whether the region will be driven by the development of AI technology and its potential economic benefits or a governance framework centered around protecting individuals' rights and freedoms, including their right to personal data protection.",
            "The current geopolitical environment in international trade is volatile given U.S. tariff policies which have led to significant fluctuation in prices of goods and services, especially digitally deliverable exports. It will be interesting to see whether the tariff war will be a determining factor in shaping the region's position on AI governance.",
            "The 2023 OECD-IDB Digital Government Index highlighted the region's lag in the consistent development of tools, digital infrastructure and software and noted it consequently ranks low in the design and delivery of public services and responsible and strategic public-sector AI use. The OECD's Survey on Digital Government indicated Latin American and Caribbean countries showed 22% progress as compared to 53% in the OECD in the area of implementation.",
            "Given that countries in Latin America and the Caribbean may have to rely on U.S. imports of AI hardware to develop AI systems, the region will have to decide, when faced with the U.S.' new tariff strategy and related negotiation tactics, whether it embraces the U.S. position on AI development and regulation, seeks alternative suppliers or asserts its digital sovereignty and independence.\u00a0",
            "Jason Grant, CIPM, is an attorney from Trinidad and Tobago and served as a member of a multidisciplinary committee to fully operationalize the country's data protection legislation."
        ]
    },
    {
        "url": "https://iapp.org/news/a/navigate-2025-rise-of-ai-brings-novel-litigation-copyright-issues",
        "title": "Navigate 2025: Rise of AI brings novel litigation, copyright issues",
        "location": "",
        "date_published": "2 July 2025",
        "keywords": [
            "AI Governance",
            "Data Processing",
            "Data Protection Obligations",
            "Frameworks & Standards",
            "Law & Regulation"
        ],
        "description": "Artificial intelligence's ability to revolutionize society and economic productivity will largely be shaped by how governments react to various deployments and use cases. The most common reaction will be the introduction of new laws, even as AI deployments simultaneously challenge and potentially upend existing laws and established legal frameworks.",
        "content": [
            "Artificial intelligence's ability to revolutionize society and economic productivity will largely be shaped by how governments react to various deployments and use cases. The most common reaction will be the introduction of new laws, even as AI deployments simultaneously challenge and potentially upend existing laws and established legal frameworks.",
            "At the IAPP and the Berkman Klein Center for Internet and Society's Digital Policy Leadership Retreat 2025, legal professionals and scholars discussed the legal fallout stemming from novel applications of AI. Conversations included observations on how training models are throwing a wrench into long-held principles of copyright law and the legal system itself.",
            "Issues surrounding AI are already being litigated in the U.S. court system.",
            "U.S. Court of Federal Claims Judge Molly Silfen said during a retreat breakout session that courts are confronting a range of major legal concerns related to AI. Potential copyright violations by AI developers, the use of AI in obtaining patents, lawyers' use of the technology and the ability of judges to use AI to write their decisions are among the unresolved issues.",
            "High-profile developer copyright cases are beginning to set some precedent.",
            "According to Reuters, the U.S. District Court for the Northern District of California recently ruled Anthropic did not violate copyright laws by using books to train its AI system. Despite allegedly not violating copyright laws, Anthropic must face a trial after Judge William Alsup claimed the company \"infringed the authors' copyrights and was not fair use.\"",
            "Frank Stanton Professor of the First Amendment at Harvard Law School Rebecca Tushnet said the impact AI will eventually have on perpetuating potential trademark violations will require rethinking foundational approaches that have defined current trademark law.",
            "\"The liability arguments for trademark and rights to publicity always depend on the outputs, unlike the AI training arguments we see in copyright law,\" Tushnet said. \"These outputs usually come from noncommercial end users, which means that the intuition lawmakers have that AI means we have to regulate more heavily, or we need to give people more rights to their rights to publicity; we're going to have to start covering activities that we would have previously been considered non-commercial (under trademark law).\"",
            "According to Tushnet, the future use of generative AI to create content and behavioral advertising based on personal data could pose a disruption in the legal ecosystem. Courts have fostered accountability among advertisers that would otherwise be subjected to class action lawsuits in the event they falsely marketed a product.",
            "\"Currently a lot of advertising law enforcement is done through class action (lawsuits). You get people who have been exposed to the same ad and they sue over the misrepresentation that was in that ad,\" Tushnet said. \"I'm not sure how long that will stay viable in a world where the average consumer has seen an ad that is tailored just for them.\"",
            "Questions around AI's use in legal proceedings is also a thorny area.",
            "Silfen indicated her court has begun developing rules to govern how AI can be used by lawyers, including the potential implementation of AI disclosure requirements in the preparation of legal briefs. If a lawyer applied AI, they would have to attest that the submitted information was verified and accurate.",
            "However, she said her court ultimately has refrained from putting rules into force for the time being.",
            "\"What we came down to, at least for now, is that there was not a strong case for us to develop a specific rule disclosing AI uses because, to some extent, it is always a lawyer's obligation to make sure that what they say to the court is accurate,\" Silfen said. \"I still worry about AI. I worry about it from a confidentiality perspective because the inputs (in legal filings) are confidential and I don't want the drift getting out there, so there's sort of a minefield to navigate.\u201d",
            "Copyright protections are arguably facing the most legally disruptive impacts from the proliferation of AI.",
            "In a retreat breakout session, Harvard Law School Professor William Fisher presented research that examined how 16 countries and the EU as a whole are applying copyright law to AI development and use.",
            "The research generated eight AI legal criteria commonly used across jurisdictions. The criteria included where the ability for AI developers to train models using copyrighted material is illegal, fair-use privileges, exceptions for both commercial and non-commercial text data mining with and without opt-outs for rights holders, extended collective licensing provisions for rights holders, and transparency obligation requirements.",
            "Among the jurisdictions Fisher covered, China, France, Saudi Arabia and the United Arab Emirates are either considering or have some legal mechanism in place to prevent using copyrighted material in training AI. Israel is the only country that currently allows some form of fair use of copyrighted work for training AI. Canada, India, South Korea and the U.S. are exploring potential legislation to allow fair-use exceptions to varying extents.",
            "With transparency obligations, Fisher said the EU as a bloc is the only jurisdiction of the 17 he examined that requires developers to disclose what material their AI models were trained with. However, he noted said Brazil, Chile, France and the U.K. were in varying stages of drafting potential legislation governing transparency obligations on the part of AI developers.",
            "\"(The different jurisdictions) have very polar positions,\" Fisher said. \"Some are taking a very harsh view on this activity. Some are taking a very permissive view, and there are lots of positions in between.\"",
            "World Intellectual Property Organization Copyright Law Division Director Michele Woods said the absence of a standardized global copyright regime leaves her organization tasked with administering several international copyright treaties between the WIPO's 194 member states.",
            "Woods said international organizations like the WIPO will serve a crucial role as generative AI puts further strains on countries' existing copyright legal frameworks. That role includes potentially setting a baseline standard for how copyright holders can be adequately compensated while also avoiding undue burdens on AI innovation.",
            "\u00a0\"At least on a minimum level, we think we have a role of harmonizing some aspects of (countries' own) copyright laws,\u201d Woods said. \"In terms of taking a position on AI, we follow our member states. We have quite clearly set out a human centered approach that is focused on the impact (of AI) on intellectual property, individual creators and innovators.\"",
            "Alex LaCasse is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/navigate-2025-how-individuals-feelings-inform-ai-governance-practices",
        "title": "Navigate 2025: How individuals' feelings inform AI governance practices",
        "location": "",
        "date_published": "2 July 2025",
        "keywords": ["AI Governance", "Customer Trust & Expectations"],
        "description": "To improve understanding of how artificial intelligence should be managed, digital leaders at the Digital Policy Leadership Retreat 2025 \u2014 hosted by the IAPP and Berkman Klein Center for Internet and Society \u2014 offered a new perspective. They argued people should reflect on how various AI applications make them feel.",
        "content": [
            "To improve understanding of how artificial intelligence should be managed, digital leaders at the Digital Policy Leadership Retreat 2025 \u2014 hosted by the IAPP and Berkman Klein Center for Internet and Society \u2014 offered a new perspective. They argued people should reflect on how various AI applications make them feel.",
            "Presenters spoke at length about how governance will shape the future of the digital landscape, including the ever-advancing nature of AI. While governance debates often touch on data management, privacy, trust and safety, the societal expectations of what technology is meant to do in our lives is of equal importance.",
            "Emotions, and subsequent responses, stemming from the perceived impacts of AI are becoming increasingly important to public perception.",
            "A survey found workers, often worried about job displacement or frustrated by tools they feel do not fit their work needs, are sabotaging their company\u2019s AI rollout efforts. According to Stanford University\u2019s 2025 AI Index Report, optimism about the technology is unevenly increasing worldwide, even as investment is rising.",
            "The debate can be seen in companion AI rollouts like ElliQ, a robot aimed at curbing the elderly loneliness epidemic, said Jonathan Zittrain, a professor at Harvard Law School and the co-founder of the Berkman Klein Center.",
            "During a keynote presentation, he surveyed reactions from the audience to a video of ElliQ talking to a grandmother. Creepy, sad, and freaky were among the responses, demonstrating how these feelings provide initial signposts on how a technology should be managed.",
            "Underneath those reactions are questions about what it means if ElliQ starts making product recommendations or endorses a political candidate. Those interactions might be expected from a website or news channel, but they become less comprehendible when coming from a large language model that provides companionship, Zittrain said.",
            "That complexity may not be wrangled by standard means of transparency, such as simple disclosures.",
            "\u201cAt the moment, we don\u2019t have the frameworks to think about these things that can be so subtle,\u201d Zittrain said.",
            "But the initial feelings of the public might not align with those of the people developing the technology or its target audience, according to Future of Privacy Forum CEO Jules Polonetsky, CIPP/US.",
            "Speaking during a separate conversation, Polonetsky said ElliQ will likely inspire different feelings in caregivers or activists thinking about the role technology can play in our daily lives. It shows the importance of having an AI governance team that does not just think about the law, he said, but also how the media, consumers, stakeholders and civil society might think.",
            "\u201cAlthough we have laws and evolving law, there\u2019s this whole set of issues where we don\u2019t understand what the norms are,\u201d Polonetsky said.",
            "To tackle the more amorphous elements of AI, Meta Vice President and Deputy Chief Privacy Officer for Policy Rob Sherman said his company spent time hashing out holistic rules for how its AI products should operate, arguing a business cannot make good decisions if it does not think about how elements like privacy, free expression, safety and security all interact. Those rules were then distilled into automated forms product managers can fill out to understand where they are on answering those fundamental questions. \u00a0",
            "\"It avoids the need for humans to spend a lot of time programmatically applying the same decisions and instead focusing on those bigger societal or ambiguous, hard questions,\u201d Sherman said.",
            "How much time developers think about these issues does not escape the notice of regulators. Irish Data Protection Commissioner Des Hogan said the thoroughness of an impact assessment \u2014 requirements which appear in various degrees in the General Data Protection Regulation, Digital Services Act and EU AI Act for certain technologies \u2014 that looks at a product\u2019s effect on society is a clue to how serious a company is in ensuring their technology is well designed.",
            "\u201cWe know very quickly whether the design of the product has been thoughtful enough to answer those questions,\u201d he said.",
            "Caitlin Andrews is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/there-s-no-opting-out-of-universal-opt-outs",
        "title": "There's no opting-out of universal opt-outs",
        "location": "North America",
        "date_published": "2 July 2025",
        "keywords": [
            "Advertising & Marketing",
            "Enforcement",
            "Law & Regulation",
            "Data Processing"
        ],
        "description": "Did you know website visitors have the option to send businesses automated privacy opt-out signals, and even more notably, that respecting these signals has become increasingly mandatory under modern privacy laws?",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. \r",
            "Did you know website visitors have the option to send businesses automated privacy opt-out signals, and even more notably, that respecting these signals has become increasingly mandatory under modern privacy laws?",
            "The concept of automating consumer privacy opt-outs from a web browser is not new. In fact, various forms of universal opt-out mechanisms have been proposed and developed over the years. These mechanisms potentially have great value to privacy-conscious consumers who appreciate a streamlined browsing experience.",
            "Sixteen years ago, one of the first notable UOOM efforts took shape with the proposal and development of the Do Not Track browser signal. While promising at the time, the DNT initiative ultimately failed to gain widespread adoption \u2014 most notably due to a lack of enforcement mechanisms and meaningful incentives for businesses to support and respect the standard.",
            "Regrettably, due to its limited adoption, DNT signals now serve as a highly effective tool for server-side browser fingerprinting \u2014 further diminishing the standard's value to those concerned with their personal privacy.",
            "In recent years,and against the backdrop of emerging privacy legislation, new forms of UOOMs are gaining traction. The clearest example is the Global Privacy Control, developed in 2020 with the intention of making it easier for individuals to exercise their privacy rights online.",
            "The GPC allows users to configure their browser \u2014 or if unsupported natively, a browser extension \u2014 to send a privacy signal to every website users visit. This signal, transmitted as an HTTP header or JavaScript variable, is meant to inform participating websites that the visitor wishes to opt-out of certain types of data processing. While websites can interpret and respond to these signals in different ways, the GPC is widely recognized as a mechanism for users to communicate a \"Do Not Sell or Share\" preference.",
            "In stark contrast with recent history, respecting UOOM signals is no longer optional for many businesses. This is particularly true in the U.S. where over half of state comprehensive privacy laws require, or will require, businesses to support universal opt-out mechanisms when utilized by consumers. Each of these states has, or will have, the ability to take regulatory action against organizations that do not adequately respect customer privacy preferences \u2014 particularly those declared via UOOMs.",
            "In California, Colorado, Connecticut, Montana, Nebraska, New Hampshire and Texas, UOOM-related requirements are already in effect.Each states' UOOM requirements, excluding California and Colorado, went into effect 1 Jan.",
            "Additionally, several states are set to enforce UOOM requirements within the next 12 months, including Delaware, Maryland, Minnesota, New Jersey and Oregon. Some of these states have already enacted their laws but have been slightly delayed in the enforcement of UOOM-related provisions.",
            "For many businesses, it will be important to evaluate and identify what type of UOOMs should be supported so that websites and personal data-handling practices can be optimized and tested for compliance. Except for Colorado \u2014 which currently considers the GPC to be the only valid UOOM \u2014 all remaining state laws take a more agnostic approach, leaving the proverbial door open for multiple consumer UOOMs now and in the future.",
            "Even so, there is only one UOOM \u2014 the GPC \u2014 that has been consistently referenced and acknowledged as valid by state attorneys general. For example, the attorneys general in California, Connecticut and New Jersey all reference the GPC on their websites, describing it in a non-exclusionary fashion as an \"option\" for consumers.",
            "Other states don't reference the GPC or any other specific UOOM.",
            "Considering these factors, a reasonable stance for many organizations is probably to support the GPC while monitoring emerging UOOM technologies and related guidance from individual states.",
            "Businesses must carefully consider the types of opt-outs they will respect via UOOM signals. There are a few variations between the laws and their requirements. The California Consumer Privacy Act, as amended by the California Privacy Rights Act, remains the most in-depth and unique of the state laws with respect to UOOM requirements. California requires businesses to support automated consumer opt-out mechanisms for the sale and sharing of personal data.",
            "The remaining state laws tend to be similar, generally requiring UOOM support for opt-outs relating to the sale of personal data and targeted advertising. Notably, one key difference between the state laws is that some require that UOOMs support profiling-related opt-outs while others exclude profiling-related rights.",
            "Organizations should carefully consider the specific ways they respond to automated opt-out requests because they may be received under a variety of conditions. One important scenario to consider involves cookies and online tracking. While UOOMs like the GPC aren't primarily intended for consumers to manage granular cookie consent preferences, they should impact the use of website tracking technologies when activated.",
            "Each of the state laws mentioned requires businesses to support automated opt-outs for targeted advertising, so disabling targeting and marketing cookies is an important and crucial factor in responding to UOOM signals.",
            "It is also noteworthy that automated opt-outs may need to be more thoroughly addressed. This is complicated by the fact that the specific identity of a web-browsing data subject may or may not be known at the time a UOOM-based request is received.",
            "Imagine a scenario where an organization holds and sells personal data pertaining to the data subject, but the subject isn't authenticated or logged into a web service at the time the automated opt-out is delivered. In this instance, the automated opt-out may not be associated with the relevant personal data, and the organization may not be able to fully honor the request.",
            "In such scenarios, it may be prudent to provide the data subject with an opportunity to provide additional identifying information, such that opt-out requests can be fully evaluated and completely fulfilled. In the inverse scenario \u2014 in which the data subject is logged into a service, with a linkable and known identity \u2014 it may be appropriate for automated opt-out requests to flow downstream without further prompting of the data subject.",
            "For those who operate a website or manage a U.S. organization's privacy compliance, it has become increasingly critical to ensure that websites, consent management platforms and other relevant systems are configured to properly respect automated visitor opt-out signals.",
            "There is significant risk if this standard is not met. The first CCPA enforcement action involved this exact concern. In 2022, Sephora was fined $1.2 million for violating the privacy law. This enforcement was a reactionto Sephora's failure to respect Californian customers' opt-out preference signals delivered via the GPC.",
            "In addition to meeting the requirements of U.S. state privacy laws, organizations may want to consider whether to globally honor the GPC \u2014 even where it is not yet a legal requirement. Taking a proactive approach may help build consumer trust, streamline compliance efforts and reduce regulatory risk as more jurisdictions adopt similar UOOM requirements.",
            "Alexander Proctor, AIGP, CIPP/E, CIPP/US, CIPM, CIPT, FIP, is chief trust and privacy officer at Captain Compliance."
        ]
    },
    {
        "url": "https://iapp.org/news/a/us-senate-abandons-proposed-state-ai-law-as-compromise-falls-through",
        "title": "US Senate abandons proposed state AI law moratorium as compromise falls through",
        "location": "North America",
        "date_published": "1 July 2025",
        "keywords": ["AI Governance", "Law & Regulation"],
        "description": "U.S. Congress' proposal to block states from regulating artificial intelligence has been removed from consideration in the Senate's reconciliation bill after a near-unanimous vote to abandon the provision.",
        "content": [
            "U.S. Congress' proposal to block states from regulating artificial intelligence has been removed from consideration in the Senate's reconciliation bill after a near-unanimous vote to abandon the provision.",
            "Senators voted 99-1 to strip the provision from the bill altogether after a deal on a revised moratorium framework fell through during the Senate voting session. Momentum existed for an amended moratorium crafted by Sens. Marsha Blackburn, R-Tenn., and Ted Cruz, R-Texas, before Blackburn ultimately backed out of the deal and joined Senate Democrats on an amendment to remove the AI measure.",
            "The revised moratorium sought to reduce the AI law enactment and enforcement pause to five years while creating exceptions for laws tackling how AI affects children's online safety, images and likeness. The proposal to tie the provision to federal broadband funding was set to remain in place if the compromise advanced.",
            "Blackburn, a proponent of children's privacy and online safety, was among four Republican senators vocally opposed to the AI provision from the beginning of the Senate reconciliation debates. She backed away from her negotiated compromise less than 24 hours after striking the deal, saying it could lead to greater harm.",
            "\"This body has proven it cannot legislate on emerging technology,\" she said during a 1 July morning floor speech. \"It is frustrating. We have not passed online privacy. We have not passed the No Fakes Act, the COPIED Act. There are all of these pieces of legislation dealing with AI that we haven't passed, but you know who has passed it? It is our states.\"",
            "Sen. Cruz, who voted to remove the moratorium he originally pitched, said that President Donald Trump characterized the negotiated moratorium compromise as \"a terrific agreement\" while acknowledging the demise of the proposal was due in part to \"outside interests\" during Senate floor remarks.",
            "A range of opposing stakeholders argued the watered-down version proposed by Blackburn and Cruz would still hurt consumers by limiting states' abilities to regulate AI at a time when the technology is rapidly changing and Congress has yet to take up a comprehensive piece of AI legislation beyond regulating sexually explicit deepfakes.",
            "Senate Committee on Commerce, Science and Transportation Ranking Member Maria Cantwell, D-Wash., released an outline that highlights the disparate impacts of a moratorium and zeroes in on the proposed compromise.",
            "Cantwell indicated the state-level pause could affect existing laws and proposals that address AI governance and civil rights. It would also impede online platforms' algorithms aimed at children\u2019s safety and preventing child sexual abuse imagery.",
            "\u201cThe Blackburn-Cruz amendment does nothing to protect kids or consumers,\u201d Cantwell said. \u201cIt\u2019s just another giveaway to tech companies. This provision gives AI and social media a brand-new shield against litigation and state regulation.",
            "She added the moratorium is \u201cSection 230 on steroids,\u201d referring to the provision in the Communications Decency Act that gives online platforms a certain level of liability protection from content posted by their users.",
            "Blackburn and Cantwell teamed up to co-sponsor the amendment to strip the AI provision from the bill. In a statement after the vote to strip the moratorium, Cantwell said senators \"came together tonight to say that we can't just run over good state consumer protection laws.\" She also noted that removing the provision gives the Senate time to create a national AI framework that \"accelerates U.S. leadership in AI while still protecting consumers.\"",
            "Backers of the moratorium focused on preventing a fragmented landscape of state AI laws that would complicate compliance for companies, hurting their ability to innovate. Trade association TechNet was among the industry stakeholders to note a pause in regulation would better support Congress' efforts to build a regulatory framework in coordination with tech companies.",
            "\u201cThe administration, the House, and the Senate have made great progress over the past year on AI regulation,\u201d said TechNet President and CEO Linda Moore, speaking on the Blackburn-Cruz revision. \u201cWe look forward to working with policymakers to pass and implement smart AI policy that will ensure America leads the world in this transformative technology and sets the global standard for responsible AI development.\u201d",
            "The compromise text would have prevented states from passing legislation that imposes burdens on the use of AI, a concept the Center for Democracy and Technology indicated might invite reams of litigation and lead to a different kind of patchwork of state rules.",
            "Backlash against the provision has been multi-faceted and bipartisan at the state level. A group of Republican governors wrote a letter to Senate Majority Leader John Thune, R-S.D., and House Speaker Mike Johnson, R-La., to remove the provision, Axios reported.",
            "State privacy and technology leaders told the IAPP a moratorium would undermine their authority and prevent their ability to protect consumers. The Multi-State AI Policymaker Working Group Steering Committee, a bipartisan, cross-sector coalition of state legislators, added in a separate statement that the provision \"further united us\" and \"further collaborative action\" on AI policy is soon to come.",
            "\"State innovation is not a barrier to federal leadership \u2014 it\u2019s often the spark,\" the working group stated. \"This is just the beginning of the hard, essential work to craft responsible, transparent and people-centered AI governance. States are ready to lead \u2014 and to partner with Washington to get it right.\"",
            "The moratorium could reemerge when the Senate sends its final reconciliation bill back to the House for concurrence. However, the House is dealing with new bipartisan opposition to the provision, with Rep. Marjorie Taylor Greene, R-Ga, among the lawmakers saying they won't sign off on the final bill if the AI language is included.",
            "Caitlin Andrews is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/navigate-2025-doj-s-antitrust-unit-zeroes-in-on-consumer-protection-innovation",
        "title": "Navigate 2025: DOJ's antitrust unit zeroes in on consumer protection, innovation",
        "location": "North America",
        "date_published": "1 July 2025",
        "keywords": [
            "Advertising & Marketing",
            "AI Governance",
            "Data Security",
            "Enforcement",
            "Litigation & Case Law"
        ],
        "description": "Monopolization is a top concern in a fast-growing U.S. digital economy, notably due to mass data collection and secondary use, as well as artificial intelligence development. The expansion of digital markets and services has sparked a wave of calls for antitrust enforcement to help maintain widespread competition and equal opportunity.",
        "content": [
            "Monopolization is a top concern in a fast-growing U.S. digital economy, notably due to mass data collection and secondary use, as well as artificial intelligence development. The expansion of digital markets and services has sparked a wave of calls for antitrust enforcement to help maintain widespread competition and equal opportunity.",
            "At the IAPP and Berkman Klein Center For Internet and Society's Digital Policy Leadership Retreat 2025, U.S. Department of Justice Principal Deputy Assistant Attorney General Roger Alford indicated the DOJ has its sights set on promoting innovation across industries, but it will not come at the cost of strong consumer protection.",
            "\"Consumer welfare rises when companies innovate, and new technologies disrupt incumbent technologies,\u201d Alford told retreat attendees in his keynote remarks. \"The answer was not to abandon antitrust in digital markets, or to abandon consumer welfare. The answer was to recognize the many dimensions of the competitive process that maximizes consumer welfare online.\"",
            "U.S. government agency's are attempting to combat issues through lawsuits against several Big Tech companies, including Google, Apple and Meta. According to Alford, those efforts work to clarify consumer protection priorities that have fallen by the wayside with industry leaders and the consumers themselves.",
            "\"(We) have become so used to smokestack industries that many assume consumer welfare should always be measured in the prices and outputs of the goods that rolled off the assembly line,\" Alford said. \"Privacy, attention, choice, innovation, all of those were half results in traditional analysis. And so, some suggested that there could be no antitrust enforcement in many digital markets because traditional measures of consumer welfare were difficult to apply.\u201d",
            "Alford indicated the DOJ antitrust unit will prioritize a \"clear vision for robust antitrust enforcement\" over the next four years. Among the top objectives in that vision is to foster more organizational transparency.",
            "\"Our paramount focus will be to put consumer welfare first, accounting for the wide range of harms and benefits to consumers and workers that can arise in modern markets,\" Alford said.",
            "Specifically with privacy, Alford indicated consumers are paying for digital services \"in time, attention and data\" and \"consumers benefit when their privacy is protected.\"",
            "He noted increased competition in the digital market will allow consumers more privacy-protective choices. Challenging companies and pushing for fair competition \"brings better quality, improved privacy options, lower advertising loads, greater data portability, more choice, and increased innovations.\"",
            "Despite concerns around how potential DOJ intervention in proposed mergers might interfere with companies' AI innovation plans, the antitrust division approaches enforcement work with a consumer-first agenda.",
            "\"Regardless of the digital sector, we at the DOJ will follow the facts and apply the law in connection with algorithmic pricing and potential collusion,\" Alford said. \"These issues provide an opportunity for our enforcers to engage critically with the practical realities of how complex technologies are affecting Americans\u2019 lives today and in the future.\"",
            "The EU has a similar consumer-driven approach to antitrust enforcement under the Digital Markets Act and the Digital Services Act. Apple and Meta were fined a combined\u00a0700 million euros under the DMA, including a 200 million-euro penalty against Meta's highly-debated pay-or-consent practices, charging EU users for ad-free services.",
            "The White House has argued the DMA and DSA are burdensome and means to target U.S. companies. In February, U.S. Vice President JD Vance criticized the burdens raised by the EU digital rulebook, making clear the U.S. \"cannot and will not accept\" other nations \"tightening the screws\" on U.S. tech companies.",
            "With ongoing EU enforcement, Alford said, \"As long as the cases are being brought against those U.S. companies on merit because it's affecting them in their markets, not in our market in the United States, in a non-discriminatory way, then that is permissible.\"",
            "The DOJ filed a landmark antitrust lawsuit against Google in 2023 after the agency claimed the company's online search and advertising technology business each constituted a monopoly in violation of the Sherman Antitrust Act.",
            "The U.S. District Court for the Eastern District of Virginia\u00a0ruled in favor of the DOJ 17 April, claiming Google \"harmed Google's publishing customers, the competitive process, and, ultimately, consumers of information on the open web.\" Final arguments regarding potential remedies to dissolve the dominance were heard 30 May.",
            "Alford told retreat attendees the Google ruling represents a \"bipartisan consensus in favor of rigorous antitrust enforcement\" and recognizes the company has \"abused its monopoly status by controlling how digital advertisements are placed on the free and open Internet.\"",
            "DOJ Assistant Attorney General Gail Slater noted if the company's practices are not remedied \"it will control much of the internet for the next decade and not just in internet search, but in new technologies like artificial intelligence.\"",
            "The agency previously sued Google in 2020 due to its search engines\u2019 alleged monopolization. The DOJ's lawsuit proposed the company request consumers consent to make Google\u2019s search engine as a default on Google Pixel devices. Google argued the proposal would \"result in unprecedented government overreach that would harm American consumers, developers, and small businesses \u2014 and jeopardize America's global economic and technological leadership at precisely the moment it\u2019s needed most.\"",
            "Alongside its case against Google, the DOJ announced a USD14 million settlement in its case targeting the merger of Hewlett Packard Enterprises\u2019 acquisition of Juniper Networks. The settlement will require the company to license Junipers' Must AI for its wireless network services.",
            "\"The American way of winning the global economic competition is with strong competition in our domestic firms that make our companies stronger to compete abroad,\" Alford said.",
            "Lexie White is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/emerging-trends-insights-from-public-enforcement-of-us-state-privacy-laws",
        "title": "Emerging trends, insights from public enforcement of US state privacy laws",
        "location": "North America",
        "date_published": "30 June 2025",
        "keywords": ["Enforcement", "Law & Regulation"],
        "description": "Data privacy is becoming more important to the average American consumer. Recognizing this, nineteen states have passed comprehensive privacy legislation that tasks their attorneys general with protecting their constituents' privacy. Some of those states, including California, Connecticut, New Hampshire, New Jersey, Oregon, Texas and Virginia, have even created privacy-focused subunits within the office of the attorney general. ",
        "content": [
            "Data privacy is becoming more important to the average American consumer. Recognizing this, nineteen states have passed comprehensive privacy legislation that tasks their attorneys general with protecting their constituents' privacy. Some of those states, including California, Connecticut, New Hampshire, New Jersey, Oregon, Texas and Virginia, have even created privacy-focused subunits within the office of the attorney general. ",
            "Attorneys general in California, Colorado, Connecticut, Delaware, Indiana, New Jersey and Oregon as well as the California Privacy Protection Agency have created the bipartisan Consortium of Privacy Regulators to collaborate on enforcing their respective state privacy laws.",
            "State attorneys general and other public enforcers play a huge part in shaping how businesses understand and carry out compliance with state privacy laws. As of now, only the California Consumer Privacy Act allows private parties to file legal actions for potential violations, but every state's privacy law tasks their respective attorney general with enforcement. Indeed, state attorneys general are the spearheads of carrying out privacy laws throughout the U.S.",
            "Though there are not many publicly disclosed investigations yet, each action taken sheds vital light on this ever-evolving field. Attorneys general have often brought actions to defend consumer data privacy under more general unfair competition or false advertising laws. The recent proliferation of comprehensive state privacy laws has given them new and more specialized tools to do so.",
            "Given these developments, how have attorneys general enforced enacted state privacy laws? Focusing on publicly disclosed legal actions and identifying shared trends across states over time, what lessons can be learned by only analyzing the claims made under comprehensive state privacy laws?",
            "The first comprehensive U.S. state privacy law was the CCPA, which passed in 2018 and came into effect in 2020. While there were no public legal actions taken within the first year of its enforcement, California Attorney General Rob Bonta announced in 2021 that his office had sent out private notices of potential noncompliance to many businesses. In the press release, Bonta noted that \"upon receiving a notice of alleged violation, 75% of businesses acted to come into compliance within the 30-day statutory cure period.\"",
            "Anonymized notice summaries posted on the California attorney general's website provide some insight into the holistic approach taken toward enforcement. They range widely both in the recipients' industries and the referenced provisions of the CCPA. From grocery stores to car manufacturers, from inadequate privacy policies to a lack of opt-out mechanisms, Bonta has been keeping watch over as many potential infractions as possible. Soon after the enforcement sweep, one of the private notices turned public.",
            "The first public complaint under the CCPA came in 2022 when Bonta launched an investigation into the makeup and lifestyle company Sephora. The investigation resulted in a complaint and subsequent settlement of claims that Sephora illegally sold California consumer personal data by \"mak[ing] consumers\u2019 personal information available to third-party companies for the purpose of obtaining advertising and analytics,\" even though its privacy policy at the time stated that \"we do not sell personal information.\"",
            "Bonta stated that this alleged disclosure fell into the CCPA\u2019s definition of sale, regardless of whether Sephora received direct monetary compensation. Similarly, allowing third-party companies to install trackers in return for discounted or higher-quality analytics \"including the option to target advertisements to customers that had merely browsed for products online\" was also a sale. The attorney general broadly interpreted the CCPA\u2019s definition of a sale to include exchanging personal information for \"anything of value,\" a theme which runs through multiple other public CCPA complaints.",
            "The CCPA obliges businesses that sell personal information to take several compliance measures, such as disclosing what categories of personal information they collect and giving consumers the opportunity to opt out of the collection and sale of their data. Businesses must comply with both manual requests to not sell or share a consumer\u2019s personal information and global opt-out signals. These signals, such as those provided by the Global Privacy Control, transmit a do-not-sell request in a standard format to every website the consumer visits.",
            "Sephora was legally required to implement these measures and failed to do so, Bonta stated. Thus, after giving Sephora notice of potential CCPA noncompliance and waiting the requisite 30 days for a cure that failed to manifest, California's Office of the Attorney General filed the complaint. At the time, this mandatory notice-and-cure period allowed businesses to avoid liability by putting potential violations to rights. The provision requiring notice has since expired; the attorney general\u2019s office may provide notice at its discretion but is not required to do so.",
            "The parties settled for a USD1.2 million fine and the establishment of requirements that Sephora change its privacy practices. These requirements included giving notice to consumers that Sephora was selling personal information, allowing both manual opt-out requests and those made through signals like GPC and implementing a two-year assessment and monitoring program.",
            "That first broad enforcement sweep that led to the Sephora complaint was followed by more targeted sweeps focused on businesses that operate loyalty programs in 2022, businesses with mobile apps in 2023, large California employers in 2023, streaming services in 2024 and the location data industry in 2025. In this period, Bonta\u2019s office filed more complaints that sought to protect consumer privacy under California\u2019s consumer protection and protection of medical information laws, but the next CCPA action came after the sweep that targeted streaming services.",
            "In early 2024, the attorney general announced an investigation into and complaint against the food delivery company DoorDash alleging similar claims to the Sephora complaint: that DoorDash was selling consumer information in violation of the CCPA without notice or an opportunity to opt out.",
            "Instead of a traditional sale, DoorDash allegedly participated in a marketing cooperative \"in exchange for the opportunity to send mailed advertisements to customers of the other participating businesses.\" Continuing the thread of an expansive definition of \"sale,\" Bonta stated that this fell under CCPA even though it did not result in direct monetary benefit. Similar to Sephora, the existence of an alleged sale required DoorDash to provide notice and opt-out opportunities, which the company did not do.",
            "DoorDash took measures to cure the violation by ceasing to sell California consumers' personal information and requesting that the marketing cooperative delete all of their data. However, the attorney general said that this was too little too late. Other entities in the cooperative had sold the data to outside businesses, including a data broker that resold the data multiple times. Bonta stated DoorDash could not cure the violation \"because it did not make affected consumers whole by restoring them to the same position they would have been in if their date had never been sold.\"",
            "The settlement agreement included a USD375,000 civil penalty as well as requirements to provide notice and opt-out methods for selling personal information, update the privacy policy and create a three-year compliance program.",
            "Later in 2024, the California Department of Justice and Los Angeles City Attorney's Office jointly filed a complaint against Tilting Point Media, a company that creates mobile free-to-play games targeted towards children. The allegations in the complaint differ significantly from Sephora and DoorDash's infractions primarily because the complaint centers around alleged violations of the increased protections the CCPA provides to minors.",
            "With adult consumers, the CCPA permits opt-out consent, where businesses can collect and process personal information by default unless they opt out. However, minors or their parents or guardians must give opt-in consent, where they affirmatively choose to share information with the business. Tilting Point allegedly collected known children's data without authorization in violation of this provision.",
            "When users identified themselves as under 16, the app directed them to a child-specific version of the game, but Tilting Point had allegedly misconfigured its software such that it collected consumer data regardless. Tilting Point and the enforcers settled for a USD500,000 civil penalty as well as requirements related to affirmative opt-in consent, notice of how Tilting Point sells or shares personal information, an updated privacy policy and the creation of programs to monitor its practices and how it configures its software.",
            "These three complaints each allege different claims under the CCPA, but all share an assertive attitude towards privacy enforcement. They define important terms like \"sale\" and \"cure\" broadly to provide the greatest possible protection to consumers under the CCPA's terms. Press releases from Bonta\u2019s office have repeatedly emphasized the attorney general\u2019s commitment to ardent enforcement, a claim backed up by these public complaints as well as the number of notices disclosed on the attorney general\u2019s website.",
            "In 2020, the CPRA created the California Privacy Protection Agency, which is the first enforcer that is independent from the state attorney general\u2019s office. Although it has taken multiple actions under the CCPA, including a settlement with Honda and an order against clothing retailer Todd Snyder, the CPPA upholds multiple California privacy laws. Together, the California attorney general and CPPA form a dual enforcement structure that continues to evolve. As both entities develop their complementary enforcement strategies, businesses should expect more coordinated and sustained scrutiny going forward.",
            "Attorneys general from many states have not filed any complaints enforcing their privacy laws, but complaints are not the only source of insight. Six months after the Connecticut Data Privacy Act came into effect, the office of Attorney General William Tong released a report detailing its enforcement procedures and privacy-related findings.",
            "Similar to the CCPA, the Connecticut privacy law had a provision that required the attorney general to provide notice and wait 60 days for a cure for the violation, which expired on 1 Jan. 2025. The report states that Tong sent out 10 such cure notices in the first six months of enforcement across multiple industries and regarding multiple potential violations.",
            "The violations in Connecticut are like those reported by the California attorney general: absent or inadequate disclosure of a consumer's rights as well as absent or inadequate mechanisms for consumers to opt out or otherwise exercise their rights. The attorney general noted that many of the recipients of cure notices took prompt steps to rectify violations, in some cases going above and beyond to fix issues the cure notice didn't point out.",
            "However, the report also identifies some growing pains with what constitutes a cure under the Connecticut law. As with the CCPA, curing a violation may be difficult or even impossible in some cases. The report indicates a wait-and-see approach to the iterative process of figuring out what can suffice. \"[O]nly time will tell,\" it says, \"which companies fully satisfy our concerns and which matters will ultimately require more formal enforcement action.\"",
            "The report also points out that many consumers don't yet understand the finer points of submitting a violation complaint. Despite outreach efforts, of the more than 30 complaints received, around a third concerned entities or data exempted from the Connecticut law\u2019s purview. Consumers were also confused about what information they could request a business delete and what information is \"publicly available\" and thus outside of the law\u2019s scope.",
            "The report concludes with recommendations for how Connecticut's legislature could amend its privacy law to \"strengthen or clarify privacy protections.\" The section draws from provisions of other states' laws to suggest, for example, that Connecticut expand its definition of biometric data to align with a newer law in Oregon. The proposed changes also include reducing entity-level exemptions, such as exemptions for entities subject to the Gramm-Leach-Bliley Act, covered entities or business associates under the Health Insurance Portability and Accountability Act and nonprofit entities. This would make the Connecticut law apply to a broader swath of businesses, similar to the scopes of California, Colorado, Delaware and Oregon.",
            "The report suggests that Connecticut enact a one-stop-shop deletion mechanism, like that in California's Delete Act, and the right to know to which third parties a business has disclosed a particular consumer's personal information, as defined in Delaware's and Oregon's respective privacy laws.",
            "These recommendations grow out of the fact the Connecticut law is both one of the earliest state privacy laws and has a slightly different style than the CCPA \u2014 its provisions follow the same general shape as the CCPA, but it has a smaller scope due to its narrower applicability thresholds and broader exceptions. Later laws have learned from the Connecticut law and changed their provisions slightly. This report shows implementing those changes into the law could help make enforcement clearer and more effective.",
            "The Texas Department of Information Resources created a similar report in late 2024 that reviewed feedback on the much newer Texas Data Privacy and Security Act. Consumers and data controllers alike indicated confusion about the specifics of the law and asked for clarification of its technical details.",
            "Texas consumers stated that they wanted more education about how to exercise their privacy rights. They found the process of doing so confusing because the method varies from controller to controller. This report was released before 1 Jan 2025, when a provision of the Texas law went into effect that requires controllers to honor global opt-out signals in certain circumstances.",
            "This can alleviate some of the frustration with the lack of streamlining or standardizing opt-out requests, but the problem with exercising rights to access, correct or delete remains. Consumers also indicated confusion about how long their preferences would remain in effect. One asked \"(i)f I opt out of sale of my data at one point in time, and then the business gets new data about me, do I need to opt out again?\"",
            "Data controllers who responded to the survey reported similar confusion, especially with definitions of terms like \"data deletion\" and \"publicly available information.\" They disliked the uncertainty of yet another compliance burden on top of all the other state privacy laws and advocated for a single federal standard to simplify operations.",
            "For example, most state privacy laws provide a cure period, where the attorney general's office must send a controller notice of a potential violation; the controller then has some time to cure the alleged wrong to avoid official action. However, the Texas law is unique in that this cure period is mandatory and exists in perpetuity. Other states provide for discretionary notice or include a sunset clause for this provision. The report recommended that Texas revise its cure provision to bring it into alignment with those of other states.",
            "In March 2025, the Oregon Department of Justice released a report on the first six months of enforcing the Oregon Consumer Privacy Act. Oregon's dedicated Privacy Unit has started out with outreach and education efforts, including sending \"light\" cure letters to data brokers with privacy policies that did not comply with the state\u2019s privacy law and running an informational marketing campaign for consumers. Like some other states, the Oregon DOJ opened a consumer complaint portal on its website, through which consumers reported confusing privacy policies and difficulties exercising their privacy rights, especially the right to delete their data.",
            "These reports show a microcosm of the wider privacy landscape: consumers and businesses alike aren't quite sure yet how to adapt to the rights and responsibilities created by privacy laws. They show a glimpse into the important behind-the-scenes collaboration between the public and private sectors working towards setting standards that are sustainable for both.",
            "In stark contrast, Texas Attorney General Ken Paxton exploded onto the scene a month after the DIR report by filing the first ever formal lawsuit under a state privacy law, even though the Texas Data Privacy and Security Act is a relatively new law that only came into effect 1 July 2024. The complaint includes a demand for a jury trial \u2014 the first public complaint to do so. California's actions were only announced along with their associated settlements, so this is the first contested action filed under a comprehensive state privacy law.",
            "Paxton alleged that the data analytics company Arity, a subsidiary of the insurance company Allstate, violated the Texas law by collecting and processing consumer data without notice, consent or a way for consumers to exercise their privacy rights. Arity allegedly licensed tracking software to developers of mobile applications that offered location-based services, like tracking prices at local gas stations or getting alerts when a family member arrives or leaves certain places.",
            "\u00a0The complaint claimed that this software harvested, among other things, a consumer's \"phone's latitude, longitude, speed, GPS time, bearing, and altitude\" and sent it back to Arity. The complaint also alleged that Arity bought data from car manufacturers to refine the data it collected, selling it to insurance companies without notice or consent from consumers.",
            "This marks a sea of change in the history of comprehensive state privacy laws; it may be the first lawsuit to enforce them in the U.S., but it certainly will not be the last. Public enforcers are aware of increased privacy consciousness among their constituents. For example, the report from the Texas DIR stated that 77% of respondents were \"very concerned\" with how businesses use their data.",
            "Oregon's report found that in the first six months of the Oregon Consumer Privacy Act coming into effect, its online consumer complaint portal received more than triple the number of complaints as did Connecticut's similar complaint portal in its own first six months. Consumers are becoming more aware of their rights and the effect that potential breaches could have on their lives. Some enforcers are responding with actions to show that their laws have teeth.",
            "This period of rapid data-privacy-related development in the public and private sectors has created growing pains for both domains. Some public enforcers are securing settlements with massive monetary and injunctive penalties for alleged violations of fundamental tenets of state privacy laws, like disclosing what data a business collects or providing methods for consumers to exercise their privacy rights. At the same time, attorneys general in other states are requesting increased funding to deal with an influx of complaints and potential violations.",
            "For their part, consumers are also still coming to grips with what rights they have and how to exercise them. In 2023, the IAPP surveyed consumers and found that 68% of respondents said they are either somewhat or very concerned about their online privacy. However, only 30% of respondents had a strong understanding of what personal information industries collect and why and how they use it.",
            "Across the U.S., private and public entities are locked in a complex negotiation with each other to determine what a \"sale\" or a \"cure\" is under applicable laws. These terms radically impact the scope of what these laws cover, but there is still a dearth of solid precedent on which to build a shared understanding. Young as they are, state privacy laws have still shaped how all stakeholders approach data privacy practices.",
            "Whether through soft power outreach like notice letters or through aggressive legal actions, the ultimate goal for public enforcers is compliance with law. At the IAPP's Global Privacy Summit, a panel of officials from the CPPA and the offices of the attorneys general of Colorado and Oregon emphasized the need for cooperation and transparency within and across sectors. These states are part of the Consortium of Privacy Regulators, which aims to avoid more piecemeal enforcement and harmonize it throughout the states.",
            "As the older state privacy laws settle in and the newer ones come into effect, regulators are leveraging their growing expertise to take strategic, targeted enforcement actions, often focusing on sectors with high consumer impact or business practices that have been brought to light by consumers and others. As the regulatory landscape matures, companies should expect state attorneys general to move fluidly between both headline-grabbing settlements and a steady track record of privacy enforcement that shapes compliance expectations nationwide.",
            ""
        ]
    },
    {
        "url": "https://iapp.org/news/a/how-proposed-ai-enforcement-moratorium-cuts-into-us-state-level-powers",
        "title": "How proposed AI enforcement moratorium cuts into US state-level powers",
        "location": "North America",
        "date_published": "27 June 2025",
        "keywords": ["AI Governance", "Law & Regulation", "Enforcement"],
        "description": "Public policy differences between the U.S. Congress and state legislatures are routine, especially with debates on digital policy. The latest example comes with U.S. Congress' proposed 10-year ban on enforcing state artificial intelligence laws, viewed by state lawmakers and enforcers as cutting into their respective authority and mission to serve their constituents.",
        "content": [
            "Public policy differences between the U.S. Congress and state legislatures are routine, especially with debates on digital policy. The latest example comes with U.S. Congress' proposed 10-year ban on enforcing state artificial intelligence laws, viewed by state lawmakers and enforcers as cutting into their respective authority and mission to serve their constituents.",
            "The moratorium emerged from the U.S. House's budget reconciliation proposal in May and has withstood criticism and updates to reach a potential full Senate vote. The current iteration of the moratorium, characterized in the Senate bill as a \"temporary pause,\" moves away from an outright ban and ties states' compliance to their right to access a federal funding pool for broad infrastructure improvements.",
            "IAPP Managing Director, Washington, D.C., Cobun Zweifel-Keegan, CIPP/US, CIPM, redlined the latest changes to the provision, which is still receiving bipartisan opposition in the Senate despite momentum toward inclusion in the final bill text. The Senate bill will require concurrence back in the House, where opposition now exists after the lower chamber's initial approval of the AI provision.",
            "According to Politico, the Senate parliamentarian is asking the Senate Committee on Commerce, Science and Transportation to clarify the exact nature of the broadband funding tie before the provision can move forward. Confusion exists as to whether noncompliance would prohibit access to the full USD42 billion fund or a USD500 million allocation, with the former scenario likely to add to existing Senate Republican opposition.",
            "The motivation behind the moratorium is clear: Avoid watering down a booming industry with fragmented regulation. U.S. Sen. Ted Cruz, R-Texas, has touted his AI proposal as necessary to support American leadership on AI innovation.",
            "While Congress is focused on AI's potential, states are keeping consumer safety front and center.",
            "States have been firm with their displeasure over the moratorium from the onset. State lawmakers and enforcers have sent multiple letterspleading their case against limiting states to establish AI governance requirements and mitigate harms that may crop up from AI development and use.",
            "\"There's nothing to fall back on. This moratorium\u00a0actually reduces rights that people currently have,\" California Privacy Protection Agency Executive Director Tom Kemp told the IAPP. \"We've always believed, whether it's AI, automated decision-making or privacy, there should be a high floor. But even then, there should be an ability for states to go over and beyond to best address the needs of their constituents.\"",
            "In the latest opposition letter, Kemp joined six state attorneys general to reiterate to Senate leadership how the proposal does not benefit consumer protection. They claimed the ban would \"create a regulatory vacuum that benefits AI developers at the expense of privacy rights\" and AI-driven technology \"demands the flexibility and responsiveness that only multi-level governance can provide.\"",
            "Meanwhile, industry recognizes the appetite for firm guardrails, but largely views a potential state patchwork as unworkable.",
            "OpenAI Associate General Counsel for AI Policy and Regulation Ben Rossen, CIPP/US, said the state patchwork on comprehensive privacy law is \"not ideal\" but has become \"manageable\" due to aligned concepts and provisions. However, he indicated the many interpretations of AI across state lines might not yield the same sense of harmonization.",
            "\"The AI moratorium is actually a fascinating thing,\" Rossen said at the IAPP and Berkman Klein Center For Internet and Society's Digital Policy Leadership Retreat 2025. \"More than 1,000 bills have been proposed on AI in the past six months. Some of them really do kind of regulate these sort of fundamental national security questions. ... But a state-level patchwork of all these frontier (AI) regulations would also be really damaging.\"",
            "State lawmakers are singing a consumer-focused refrain in their opposition to the moratorium.",
            "In a 3 June letter to Congress, lawmakers harped on needing the ability and runway to support consumer concerns and risks. They wrote, \"AI will raise some of the most important public policy questions of our time, and it is critical that state policymakers maintain the ability to respond.\"",
            "The letter also covered how states can be \"more nimble in their response\" to AI than Congress and a moratorium in this moment would \"would freeze policy innovation in developing the best practices for AI governance at a time when experimentation is vital.\"",
            "\"Over the past several years, states across the country have enacted AI-related laws increasing consumer transparency, setting rules for the government acquisition of new technology, protecting patients in our health care system, and defending artists and creators,\" lawmakers wrote.",
            "In prior remarks to the IAPP on the passing of the Texas Responsible Artificial Intelligence Governance Act, state Rep. Giovanni Capriglione, R-Texas, raised similar flags spelled out in the letter. He argued the vague and proscriptive nature of the current provision is not workable while Congress does not currently have an immediate federal fallback if issues arise in the next 10 years.",
            "\"I appreciate all the federal government does. However, they have not really been able to work on super complicated, technical things like this for a long time and actually get them passed,\" Capriglione said. \"I would make the case (Congress) is still quite a ways away from having something in place that will sufficiently protect my constituents here in the state of Texas.\"",
            "Hall Estill Partner Collin Walke served as Democrat member of the Oklahoma House from 2016-22, spearheading the state legislature's comprehensive privacy law efforts over multiple years. A common refrain in his side of debates was Oklahoma needed to act because Congress was not, an argument he insists is resurfacing here.",
            "\"It's astounding that the federal government would prohibit states from taking up important issues affecting their citizens,\" Walke told the IAPP. \"We elect our officials to solve problems. If our federal delegation is unwilling to act, the states absolutely must.\"",
            "There is a difference between an attempt to harmonize approaches versus the objective of the moratorium, according to Center for Democracy and Technology CEO Alexandra Reeve Givens. She told IAPP-Berkman Klein Center retreat attendees that the proposed ban can be viewed as 10-year \"free pass\" and supports state legislators fighting back.",
            "\"You can't deny the rights of different jurisdictions, whether regulatory agencies or, in this case, states, to do their jobs and protect their citizens if people at the federal or harmonized level aren't doing so,\" she said.",
            "State Rep. Steve Elkins, D-Minn., told the IAPP that Minnesota has AI-focused laws concerning deepfakes in elections and revenge porn that would clearly be paused under the moratorium. Minnesota's comprehensive privacy law, which Elkins authored and takes force 31 July, might also be a casualty based on its AI ties in definitions and provisions for \"profiling\" and \"legally consequential decisions.\"",
            "\"These provisions would probably be preempted even though the words 'artificial intelligence' are nowhere to be found in these provisions,\" Elkins said. \"I think it's silly to try to define AI for this use case. There is a continuum of mathematical prediction techniques used to \"profile\" consumers, ranging from regression analysis to neural networks. Even within the neural network family of techniques there is a continuum with respect to transparency. No judge or jury will ever be able to find that boundary.\"",
            "Unlike Elkins, Walke does not envision existing state privacy laws getting swept up in the budget provision.",
            "\"That would be a big legal fight given the number of states that have enacted such legislation,\" he told the IAPP. \"And there's the fact that most companies are already able to comply with the data privacy laws on the books, so there is no longer a reason to push back.\"",
            "Walke added the legal battles are likely to come from states with a \"heavy technological presence\" while others have \"little incentive\" to challenge because AI is not a legislative priority for them.",
            "Joe Duball is the news editor for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-iapp-canada-building-momentum-to-address-youth-privacy-issues",
        "title": "Notes from the IAPP Canada: Building momentum to address youth privacy issues ",
        "location": "",
        "date_published": "27 June 2025",
        "keywords": [
            "AI Governance",
            "Children's Privacy",
            "Law & Regulation",
            "Data Security"
        ],
        "description": "I was at an event last week focused on youth privacy issues and how young people are inheriting a whole new world that requires skills, knowledge and savvy to navigate. Privacy Commissioner of Canada Philippe Dufresne moderated the day's first panel which featured a handful of some of the most impactful speakers I've heard in a while.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "I was at an event last week focused on youth privacy issues and how young people are inheriting a whole new world that requires skills, knowledge and savvy to navigate. Privacy Commissioner of Canada Philippe Dufresne moderated the day's first panel which featured a handful of some of the most impactful speakers I've heard in a while.",
            "His panel involved interviewing a number of younger people \u2014 mid to older teens \u2014 about what they thought about privacy, privacy laws, artificial intelligence and data regulation, and it was fantastic. Their presentations were thoughtful, humorous, insightful and genuinely human. I'm going to enjoy watching from the sidelines as these individuals develop their careers.",
            "What was cool was that these young people stuck around for the entire day and as different presentations were made on the main stage, at each turn, they asked from their table in the audience \u2014 over the microphone so that everyone could hear \u2014 some pointed and difficult questions of the presenters. And these, I would add, were not planted questions.",
            "I thought it was particularly meaningful because the data protection authorities from the G7 countries were all listening and taking notes. I know from the final DPA remarks and the cocktail reception after the event that they were all influenced by the day's conversations and interactions. I shared quite a few details about the day in a LinkedIn post, so those who were not there could get a flavor of it.",
            "Youth privacy is a big concern today and I'm totally on-board with creating a better environment for them as they explore this new frontier. Some of my clients are social media companies and I can see from working with them that they want to do right by our planet's youth. One of my clients has me do a weekly scan of anything that might be relevant to them just in this space alone \u2014 it's that important.",
            "Late last week an opposition party member of Parliament introduced Bill C-216, a private-member's bill called \"An Act to enact the Protection of Minors in the Digital Age Act and to amend two Acts.\" Private member's bills rarely get through the legislative process. This one, however, may have some merit, so we will be watching it closely when Parliament resumes in the fall.",
            "Here is a quick summary of the proposed new law:",
            "Protection of Minors in the Digital Age Act",
            "Mandatory reporting of child sexual abuse material",
            "Criminal Code amendments",
            "To say the least, partisan politics aside, this issue is a pressing and important one. In fact, it is one of the most important of our generation and the world we leave our kids and grandkids. (The youngest just graduated high school this week. I'm not in a rush; just sayin'.)",
            "Let's collectively build on the momentum to figure out ways this can be done and done in a way that, as the young people said last week, respects their privacy but also their autonomy and ability to grow, explore, be creative and be human.",
            "Kris Klein, CIPP/C, CIPM, FIP, is the managing director, Canada, for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/navigate-2025-potential-eu-ai-act-pause-opens-new-questions-on-approach-to-global-regulation",
        "title": "Navigate 2025: Potential EU AI Act pause opens new questions on approach to global regulation",
        "location": "",
        "date_published": "26 June 2025",
        "keywords": [
            "AI Governance",
            "Enforcement",
            "Law & Regulation",
            "Risk Management"
        ],
        "description": "The increasing sentiment around artificial intelligence regulation is global policy makers are being left to put a square peg in a round hole given the speed at which AI development is proliferating. It begs the question whether regulation can be done \"right\" and what that looks like, especially with the EU looking more and more likely to stop the clock on implementation of the landmark AI Act with an eye toward reassessing its regulatory approach.",
        "content": [
            "The increasing sentiment around artificial intelligence regulation is global policy makers are being left to put a square peg in a round hole given the speed at which AI development is proliferating. It begs the question whether regulation can be done \"right\" and what that looks like, especially with the EU looking more and more likely to stop the clock on implementation of the landmark AI Act with an eye toward reassessing its regulatory approach.",
            "Speaking at the IAPP and Berkman Klein Center For Internet and Society's Digital Policy Leadership Retreat 2025, Irish Member of European Parliament Michael McNamara indicated all signs point to an AI Act pause because stakeholders simply \"need time and need to know what it is they have to adhere to.\" But he warned attendees about the potential perils of any sort of pause.",
            "\"The AI Act is very far from perfect, but I do think it was a welcomed attempt to govern in this area,\" McNamara said. \"I think a delay is acceptable, but there comes a point at which any delay, if it's for a long time, just kind of deprives (the regulation) of the momentum it needs to work. That would be a concern.\"",
            "The signs are clear, according to McNamara. Escalated pressures, notably led by the U.S., around perceived burdens brought on by EU digital regulation is one factor while a lag in providing essential deliverables for AI Act implementation is another.",
            "The chief concern around implementation derives from the European Commission stretching out the deadline to release the general-purpose AI code of practice, which aims to help AI Act covered entities better understand and prepare for the act's GPAI requirements to take effect 2 Aug.",
            "McNamara said the release of the code before the GPAI requirements take force \"looks ambitious now,\" making an implementation delay a logical option.",
            "\"It hasn't been finalized yet and the date it was expected to be finalized was 2 May. Obviously that's passed and we don't see any immediate finalization (coming soon),\" said McNamara, adding that covered entities are are focused on the code as a \"presumption of compliance.\"",
            "The EU is not alone in trying to find a regulatory balance on AI. Japan and South Korea offer recent examples of frameworks that divert from the AI Act while U.S. state-level legislation ranges from covering cross-sectoral AI development and use to more targeted legislation, including bills on automated decision-making and deepfakes.",
            "OpenAI Associate General Counsel for AI Policy and Regulation Ben Rossen, CIPP/US, told retreat attendees AI-specific legislation is in flux, but that does not mean companies do not have existing statutes in sight when they are developing and using new technologies.",
            "\"In some ways, there is a host of regulation that already exists. There's consumer protection law, tort law, product liability law and all these things that already exist to regulate AI,\" Rossen said. \"And yet, the very common perception is that AI is still largely unregulated.\"",
            "The application of new or existing laws remains a point of friction. Companies cannot be left uninformed, according to Guido Scorza, board member for Italy's data protection authority, the Garante, and enforcers must take seriously their responsibility to spell out the law clearly.",
            "\"The tension between innovation and regulation isn't new at all,\" Scorza said. \"We were, and probably still aren't, always able to to give industry legal certainty in time. That's our most important responsibility, because it's our duty to recognize if society is changing and needs a faster regulatory solution than in the past.\"",
            "The panel discussed the potential for more self-regulation among AI companies in the absence of hard rules.",
            "Rossen said context is important, as broad self-regulation over AI \"does not strike anybody in industry as a responsible way of regulation.\" However, he indicated a common \"preparedness framework\" currently adopted across large AI developers is creating foundational standards.",
            "While the framework isn't identical among companies, the aim to evaluate safe AI capabilities while emphasizing risk assessment is a common priority.",
            "\"There are huge incentives already for companies to take the challenge that AI poses extremely seriously, regardless of regulation,\" Rossen said.",
            "Scorza said he \"can't accept\" self-regulation, noting AI's inherent connection to fundamental rights, including speech and privacy, leaves \"no space\" for companies to police themselves. Instead, he pitched co-regulation where policy makers set a flexible framework aimed at closer cooperation with companies.",
            "Policy makers are left to regulate what is \"being deployed in the public space,\" according to McNamara, making self-regulation a measure for developers' internal practices.",
            "\"What people do in the privacy of their own labs is a different matter,\" McNamara said. \"That's when their own regulation, boards, etc., come into play. And quite frankly, it's relationships that they have with states and nation states because there are close links.\"",
            "Joe Duball is the news editor for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-iapp-europe-data-protection-and-ai-in-focus",
        "title": "Notes from the IAPP Europe: Data protection and AI in focus",
        "location": "Europe",
        "date_published": "26 June 2025",
        "keywords": ["AI Governance", "Enforcement", "Law & Regulation"],
        "description": "The end of June marks the wrap-up of Poland's six-month presidency of the Council of the European Union. Before it passes the baton to Denmark 1 July, Poland managed to bring to a close one of its priority files \u2014 a proposal for a regulation on additional procedural rules relating to enforcement of the EU General Data Protection Regulation. The council and the European Parliament reached a long-awaited provisional agreement on the file 16 June.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "The end of June marks the wrap-up of Poland's six-month presidency of the Council of the European Union. Before it passes the baton to Denmark 1 July, Poland managed to bring to a close one of its priority files \u2014 a proposal for a regulation on additional procedural rules relating to enforcement of the EU General Data Protection Regulation. The council and the European Parliament reached a long-awaited provisional agreement on the file 16 June.",
            "The proposed regulation aims to accelerate enforcement of cross-border cases, one of the most criticized aspects of the GDPR, by harmonizing some national procedural rules. The provisional agreement introduces binding deadlines for enforcement procedures and certain rights to both the complainant and the parties under investigation, such as the right to be heard during different stages of the procedure and the right of access to the case information. Without the final text, uncertainty remains surrounding resolution of some disputed topics, such as the European Data Protection Board's role in the dispute resolution mechanism.",
            "The European Commission tabled this proposal in the summer of 2023. As a previous European Parliament's \"unfinished business\" file, it was carried over to the new parliamentary term last summer. The new rules aiming to improve GDPR enforcement will enter into force after the official adoption of the text by both institutions, fine-tuning by lawyer-linguists and publication in the Official Journal of the European Union.",
            "Another development in the field of data protection: Receiving of Royal Assent last week, the Data (Use and Access) Act became law. This is an important moment in the evolution of the U.K.'s approach to data protection after Brexit, as the act introduces new data sharing rules, including on the access and use of health care information, consumer and traffic data, and rules on digital identity verification. According to the U.K. Government, the new legislation will \"unleash the power of data\" and make British people's \"day-to-day lives easier.\"",
            "It remains to be seen whether these changes in the U.K. data protection regime will affect the EU adequacy decisions allowing free flows of personal data between the EU and U.K., which are up for review by the Commission at the end of this year.",
            "Regarding the intersection between privacy and artificial intelligence, France's data protection authority, the Commission nationale de l'informatique et des libert\u00e9s, released new recommendations on development of AI systems. The advice focuses on the use of legitimate interest as a legal basis and includes an assessment that can be used to determine whether legitimate interest can be relied upon, specific cases in which it is allowed or not and examples of safeguards to be used, such as omitting the collection of certain data.",
            "With the next batch of the EU AI Act's implementation deadlines approaching in August, the Commission launched a public consultation to gather input on implementing the regulation's rules on high-risk AI systems. Until 18 July, stakeholders are invited to share practical examples of AI systems and identify issues they want to be addressed in future commission guidelines, including the classification of high-risk AI systems, high-risk requirements and obligations and responsibilities along the AI value chain.",
            "At the same time, the topic of possibly delaying the AI Act's implementation was widely discussed this month. Some believe that postponing the entry into application of certain AI Act rules would be appropriate, especially if relevant guidance and technical standards are not finalized. Head of Office and Digital Policy Adviser for MEP Axel Voss, European People's Party, in the European Parliament Kai Zenner and Resaro Chief Trust Officer Sebastian Hallensleben highlighted the risks of delaying the act's implementation and suggested certain next steps the Commission should take.",
            "At least some of the uncertainty is hoped to be clarified in the next digital simplification omnibus, but the question is if it will happen soon enough, as important implementation deadlines are just around the corner.\u00a0 \u00a0",
            "Laura Pliau\u0161kait\u0117 is European operations coordinator for the IAPP.",
            "This article originally appeared in the Europe Data Protection Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-asia-pacific-region-chinese-regulators-strengthen-ai-data-protection-governance",
        "title": "Notes from the Asia-Pacific region: Chinese regulators strengthen AI, data protection governance",
        "location": "Asia",
        "date_published": "26 June 2025",
        "keywords": [
            "AI Governance",
            "Data Security",
            "Enforcement",
            "Biometrics"
        ],
        "description": "China has been in a heat wave since we stepped into June, and for companies falling short on artificial intelligence and data privacy compliance, the regulatory climate is just as intense. As temperatures rise, so does the pressure on organizations to meet increasingly stringent legal and regulatory standards.",
        "content": [
            "China has been in a heat wave since we stepped into June, and for companies falling short on artificial intelligence and data privacy compliance, the regulatory climate is just as intense. As temperatures rise, so does the pressure on organizations to meet increasingly stringent legal and regulatory standards.",
            "In recent weeks, China's key regulatory authorities \u2014 including the Cyberspace Administration of China, the Ministry of Industry and Information Technology, the Ministry of Public Security, the People's Bank of China, the State Administration for Market Regulation and their regional counterparts \u2014 have launched a series of enforcement campaigns. These efforts are focused on a range of digital concerns, including mobile apps, generative AI technologies, internet fraud, cyberbullying, facial recognition systems, biometric data processing and cybersecurity risks.",
            "In Shanghai, the CAC identified that several generative AI platforms failed to conduct mandatory security impact assessments. This oversight led to the generation of content involving pornography, violence, money laundering and violations of personal data rights. As a result, some companies were required to carry out comprehensive corrective actions and their AI services were suspended pending review.",
            "Regulators in Beijing have requested AI companies and service providers strengthen compliance across the entire AI life cycle \u2014 including the filing of large language models, training data evaluation, content monitoring, regulating application programming interfaces, accountability of AI in health care and finance fields, and protection of children's information. Nearly 100 noncompliant AI accounts were recently shut down. With China's AI labeling rules set to take effect in October, the CAC is urging service providers to implement proper labeling for AI-generated content, including text, images, audio and video.",
            "Beyond AI-specific measures, Beijing regulators are also intensifying their focus on consumer-facing sectors such as smart parking, online food delivery, hotel booking, education, entertainment ticketing, online medical platforms and even digital fuel stations. A recent random audit of 197 mobile apps \u2014 affecting more than 50,000 business operators \u2014 revealed various issues, including failure to disclose privacy policies, unauthorized collection of personal information, lack of adequate security measures, and improper API authorization processes. In response, the CAC plans to conduct routine inspections and has introduced a whistleblower hotline. A public blacklist of violators will also be published periodically.",
            "Similar enforcement actions are underway in other major cities and provinces, including Tianjin, Guangdong, Zhejiang and Jiangsu, reinforcing a coordinated national approach.",
            "These developments indicate a clear and consistent trajectory: China's regulators are significantly strengthening governance around AI and personal data protection. This trend is expected to continue. It is vital for businesses to stay informed of regulatory trends and take timely actions to align with compliance expectations.",
            "Barbara Li, CIPP/E, is a partner at Reed Smith.",
            "This article originally appeared in the Asia-Pacific Dashboard Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/rebuilding-digital-trust-how-blockchain-is-making-privacy-a-default",
        "title": "Rebuilding digital trust: How blockchain is making privacy a default",
        "location": "",
        "date_published": "26 June 2025",
        "keywords": [
            "Identity & Verification",
            "Privacy Technology",
            "Personal Privacy"
        ],
        "description": "Today's digital world is chaotic and safeguarding privacy within it is even more complicated.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. \r",
            "Today's digital world is chaotic and safeguarding privacy within it is even more complicated.",
            "Every click, search, and casual scroll through an app contributes to a system that collects and analyzes user data. People's habits, preferences, and interests are often mapped, studied and can be exploited.",
            "The issue lies in the very systems our society has built. Centralized platformsthat form the backbone of today's internet are vulnerable because few hands hold a high concentration of data; thissystem makes data breaches unavoidable. Privacy, which should be a basic right, has become something people have to advocate for \u2014 bit by bit. Large-scale breaches and compromises of sensitive data are signs of a deeper problem with how centralized systems handle data.",
            "Nonetheless, a significant shift is happening in organizations' approach to privacy and trust. There is less reliance on centralized institutions, and more trust is being placed in technology itself.",
            "Blockchain is at the core of this transformation.",
            "While Bitcoin or other cryptocurrencies may first come to mind for many, blockchain is much more than that application. It is a fundamental rethinking of how trust, control and privacy is managed online. It ensures security through mathematics, cryptography and distributed consensus, rather than depending on central authorities to protect information.",
            "Zero-knowledge proofs are one of the most powerful ways blockchain reforms privacy. The cryptographic method is used to prove knowledge about a piece of data without revealing the data itself. An individual, for example, could prove they are over 18 without revealing their actual birth date or that their income falls within a certain range without providing tax returns.",
            "Users can authenticate themselves or verify claims without exposing any underlying personal sensitive data using zero-knowledge proofs. Instead of having to share personal information to participate in the digital world, blockchain technology allows individuals to maintain control over their data.",
            "This technology could be a game-changer for privacy and user autonomy.",
            "Decentralized identifiers are another powerful way to give individuals full control over their digital identity. Today, most individuals can be identified online through email addresses, social media accounts and/or government-issued IDs. These forms of identification are all created and controlled by others and can be taken away, misused, breached or changed without consent.",
            "In contrast, decentralized identifiers let individuals create and manage their own secure digital ID without relying on companies or governments. Individuals could have their own ID and decide how, when and with whom this information is shared and for how long. It's like a personal passport for the internet.",
            "Decentralized identifiers and zero-knowledge proofs enable a new identity model where users control their data and only reveal what is necessary through selective disclosure. With selective disclosure, individuals have granular control over data and the power to choose exactly what relevant information to share.",
            "Because blockchain systems are transparent yet pseudonymous by default, they support these privacy enhancements without compromising accountability or security.",
            "Blockchain is also open to everyone. There are no gatekeepers and no necessary permissions. That might sound contrary to privacy, but blockchain builds privacy rights and trust into its design and into the system itself, unlike traditional systems where access is controlled.",
            "As Web3, a decentralized internet where users own their data, identities and digital assets, approaches privacy must be more than a feature. It must be the foundation. Web3 is not about rebuilding the same systems with polished interfaces, but a fundamental reconsideration of how digital interactions should work and give individuals autonomy and sovereignty over their digital selves.",
            "Blockchain is not a magical solution. Like any technology, it can be poorly built, used carelessly or simply misunderstood. New threat actors and attack vectors will find emerging technologies like blockchain. So, privacy must be thoughtfully designed from the ground up. Especially in blockchain, where recorded data is permanent and can't be erased, tough questions must be asked, like how to protect people's privacy while still keeping systems accountable and how toensure transparency doesn't come at the cost of personal freedom.",
            "These are real challenges. On the other hand, the opportunity for improvement is exciting: a future where individuals don't have to trade their privacy to participate in the digital world nor have to give up control for the sake of convenience. It won't be easy, but the opportunity to reshape how we interact online is too crucial to ignore.",
            "In this new paradigm, privacy is not an add-on but present by design and default as protocol. Blockchain offers a blueprint for a world where an individual's digital identity is a reflection of their autonomy and sovereignty.",
            "The battleground for privacy has expanded beyond activists and technologists \u2014 it's now a mainstream concern for all who interact with the digital world. Blockchain isn't just another tool in the fight for privacy, it is reshaping the very ground on which the battle is fought.",
            "Sayali Paseband is cybersecurity engineering advisor at Verisk Analytics."
        ]
    },
    {
        "url": "https://iapp.org/news/a/global-ai-law-and-policy-trends-update",
        "title": "Global AI law and policy trends update",
        "location": "",
        "date_published": "25 June 2025",
        "keywords": ["AI Governance", "Law & Regulation"],
        "description": "The trend towards risk-based artificial intelligence legislation seems to have turned on its head. Instead of, or in addition to, focusing on managing risks to consumers, policymakers are trending to embrace AI as an economic engine of growth. This shift is evident in the EU, Japan and the U.S. where governments have reprioritized policies, proposed and rescinded legislation and increased AI-focused innovation funds.",
        "content": [
            "The trend towards risk-based artificial intelligence legislation seems to have turned on its head. Instead of, or in addition to, focusing on managing risks to consumers, policymakers are trending to embrace AI as an economic engine of growth. This shift is evident in the EU, Japan and the U.S. where governments have reprioritized policies, proposed and rescinded legislation and increased AI-focused innovation funds.",
            "The changing tides of policies globally, however, has a profound impact on how organizations consider their internal AI governance, especially for the higher risk AI systems. Consumer protection- and rights-focused approaches to policy, like those in some of the EU\u2019s applicable laws, may lead to more uniform governance measures. Co-regulatory approaches, such as those implemented in Singapore, arguably leave more room for organizations to decide how they can best govern AI use and AI systems.",
            "Various jurisdictions have or are contemplating national AI legislation. Brazil\u2019s senate has approved legislation that will now be deliberated in the lower chamber. South Korea passed and signed the AI Basic Act into law and will provide greater regulatory guidance in 2025. Both the South Korean and Brazilian laws will regulate AI based on risk, meaning that certain use cases will be banned and others will have stricter regulatory requirements, much like the EU AI Act. Read the IAPP's full analysis of the South Korean AI Basic Act and commentary around the future of AI legislation in Latin America.",
            "Japan recently passed the Act on the Promotion of Research and Development and the Utilization of AI-Related Technologies, which strikes a departure from previous iterations of wide-reaching AI legislation. Unlike previous bills, such as those in Colorado, the EU, or South Korea, it focuses more on spurring innovation through government support rather than consumer protections, marking a shift in global AI policy.",
            "The U.S. has also changed course with the new Republican administration and control of Congress. Overall, the new administration appears to be prioritizing innovation in its new AI policy. This shift can be seen in the name change of the AI Safety Institute to Center for AI Standards and Innovation as well as the new U.S. Office of Management and Budget memoranda that places a greater emphasis on innovation.",
            "A moratorium on the enforcement of state and local AI regulations has been debated as part of the One Big Beautiful Bill Act. One of the stated goals of the proposed moratorium is to increase innovation by simplifying the regulatory burden organizations are facing by only allowing enforcement of federal AI laws or, for example, technology-neutral consumer protection laws. The AI Diffusion Rule, which restricted the flow of the most powerful microchips under the Biden administration, has been scrapped in the name of boosting innovation. The government will instead include access to the same chips as part of their negotiated trade bills. Both examples indicate that U.S. policy is moving towards more relaxed regulations on AI use and development.",
            "Given the changing tides in AI policy in the U.S. and around the world, how are other countries responding? The Brussels Effect, or the influence the EU has outside of its borders through its internal policies, seems to have been challenged by growing geopolitical competition among aspiring leaders in AI development who desire to reap the economic rewards of succeeding in the AI development and deployment race. While there still is EU-inspired risk-based legislation popping up in U.S. states and South Korea, policies are shifting towards a greater emphasis on innovation and less on guardrails and consumer protection. Japan\u2019s new law is a good example of this shift.",
            "There have been instances of the EU itself forgoing legislation that might be harmful to AI developers, such as the AI Liability Directive, and focusing on finding ways to increase innovation in AI development in the bloc. The European Commission's AI Continent Action Plan is at the heart of their efforts to do so; it invests 200 billion euros in AI efforts, with 20 billion euros earmarked for AI gigafactories.",
            "The first wave of factories was designated in December 2024 and the second wave in March 2025. While the goal of this initiative is to strengthen their competitiveness, they also are providing organizations with services, such as the AI Act Service Desk, to help navigate the EU AI Act\u2019s requirements. Overall, it seems that Brussels is also shifting its policies to try to capture the economic benefits of AI, including by possibly delaying or watering down the AI Act.",
            "Behind the push to innovate is the expectation of economic gains. AI is broadly expected to boost global between USD7 trillion over 10 years up to USD25 trillion annually by some estimates. Japan sees AI as a path out of its economic slump, a goal reflected in its domestic actions like new light-touch regulations and exemptions that allow AI developers to use copyrighted material in their training datasets.",
            "The U.S. Congressional Budget Office recently released a report on AI and its potential effects on the economy and the federal budget. With only 5% of businesses and 9% of employees utilizing AI, the report shows the adoption by businesses remains limited. It highlights that AI's impact on the economy is generally positive.",
            "While a majority of employers have not seen AI as a factor for decreasing employment counts, almost all employees will see some level of automation in their work when AI is sufficiently integrated. AI will increase the productivity of workers and free up time for higher level tasks as it becomes more integrated. This effect will likely be felt over the next decade as the adoption figures rise.",
            "Even without factoring potential impacts to the economy through productivity gains or effects to the labor market, investors are already heavily funding AI and its supporting infrastructure, which will, by itself, make a huge mark on economic growth. To power further adoption and advancement in AI, more AI-powering chips will need to be produced, additional data centers built to house them and greater electric supply secured to power them.",
            "In 2023, it was predicted that AI investment could reach USD200 billion by 2025. In 2024, the U.S. saw more than USD109 billion invested in AI \u2013 with a wide gap in investment between the U.S. and the EU, which saw less than USD20 billion in AI investment overall. This disparity in investment might be driving the EU\u2019s fear of missing out on an economic growth engine and its rethinking of constraining AI development and deployment.",
            "Countries seem to be looking for ways to address AI's negative impacts while simultaneously trying not to discourage investment or development. Keeping an eye on the developments and trends is important because each country will have its own approach in an ever-changing environment. This tension between economic growth and individual rights or consumer protections is seen across the globe. A poll recently found that 77% of Americans \"want companies to create AI slowly and get it right the first time, even if that delays breakthroughs.\" For policymakers, the difficulty is to set up the conditions to ensure companies are making breakthroughs while insuring they get it right the first time.",
            "It is likely organizations will pursue AI governance, regardless of the official AI policies and threat of increasing regulation. Organizations will still need to internally align the use and development of AI with their stakeholders and pursue risk-minimizing strategies \u2014 all of which an effective AI governance program will do. Even more so, non-AI-specific laws will still apply to AI systems, such as those concerning non-discrimination, data privacy and rules around non-consensual sexual imagery; organizations would have to comply with these targeted areas of AI legislation.",
            "Despite the change of emphasis from AI risk in global AI policy in favor of innovation, AI governance inside organizations will likely see more relevance in the next few years.",
            "Richard Sentinella is the AI governance research fellow at the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/eu-model-contractual-clauses-for-ai-procurement-a-practical-guide",
        "title": "EU model contractual clauses for AI procurement: A practical guide",
        "location": "",
        "date_published": "25 June 2025",
        "keywords": [
            "AI Governance",
            "Frameworks & Standards",
            "Law & Regulation",
            "Risk Management"
        ],
        "description": "In late March, the Public Buyers Community of the EU published model contractual clauses for the public procurement of artificial intelligence, which are rapidly becoming a reliable source of best practice standards for private-sector AI contracting. An initiative by the Directorate General of Growth of the European Commission, the Public Buyers Community aims to advance economic growth, competitiveness and business development, particularly among small and medium-sized businesses.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "In late March, the Public Buyers Community of the EU published model contractual clauses for the public procurement of artificial intelligence, which are rapidly becoming a reliable source of best practice standards for private-sector AI contracting. An initiative by the Directorate General of Growth of the European Commission, the Public Buyers Community aims to advance economic growth, competitiveness and business development, particularly among small and medium-sized businesses.",
            "As companies implement third-party risk policies as a part of their AI governance programs, these MCC-AI may influence procurement functions and guide customers' purchasing processes. The clauses largely follow the requirements for high-risk AI systems as defined under the EU AI Act.",
            "It is critical to make a conscious risk-based decision grounded on a set of best practices as AI capabilities evolve and become more impactful. The MCC-AI, published in light and high-risk versions along with helpful commentary, demonstrate two risk tiers of complete model contractual clauses and represent a library of clauses that are useful to address specific risks.",
            "The MCC-AI can be beneficial to private sector companies in accomplishing several goals, including aligning standards for best practices in AI contracting, creating a blueprint for risk management, ensuring international compliance, demonstrating supply-chain due diligence and mitigating litigation risk. Private sector companies and public sector organizations are not legally required to use the MCC-AI.",
            "A comprehensive approach should future-proof the procurement process to be able to adapt to new and changing AI system capabilities. Purchasers should think about how the MCC-AI specifically meet the needs of their AI use cases. Vendors should examine existing privacy, security, AI governance and compliance measures and/or standard terms to identify the measures they can and cannot honestly provide \u2014 as well as which provisions would be irrelevant to their services.",
            "The MCC-AI-High-Risk are intended for procuring AI systems defined as high-risk under the AI Act, those that \"may pose a high risk to the health and safety or fundamental rights of persons.\" The MCC-AI-Light are for those not classified as high-risk, but still requiring \"transparency obligation or requirements for explanation of individual decision-making by the public administration.\"",
            "Both sets of clauses address:",
            "Only the MCC-AI-High-Risk contain provisions that require a quality management system, including a strategy for regulatory compliance and accountability; a conformity assessment prior to delivery of the AI system; and an AI register for public transparency and comprehensive audit details.",
            "Certain provisions of MCC-AI-Light are enhanced in the MCC-AI-High Risk, including the option to continue risk management provisions after the contractual term, enhanced transparency to require disclosure of detailed performance metrics, the option to specify documentation language, and enhanced supplier and third-party data provisions with two-way indemnification structure.",
            "The purpose of a contract is to allocate and understand risks and costs between parties. The use case for an AI system is fundamental and must be understood. The MCC-AI, therefore, cannot be a one-size-fits-all solution. In many cases, even the light version may be overkill.",
            "For example, despite the intimidating breadth of the AI Act, most consumer-facing AI applications don't need MCC-AI at all because they would be low or minimal risk under the AI Act. These use cases include AI features of video games, spam filters, basic content recommendation algorithms and content generation tools \u2014 excluding deepfake creators \u2014 as well as broad categories of low-risk productivity and entertainment applications.",
            "If a system is generating content for a marketing department, the risk relates to the effects of what the system will help create. If the content generation is not using personal data and the worst-case scenario is essentially poor campaign quality, then most of these clauses would either be irrelevant or redundant to provisions usually found in standard terms for an online service. Such a use case is minimal risk.",
            "On the other hand, if the system gathers personal information and constructs behavioral profiles, serving content or on a schedule personalized to the target, then using the MCC-AI to address specific risks makes sense. For example, both the MCC-AI-Light and MCC-AI-High-Risk are designed to mitigate privacy risks and comply with the EU General Data Protection Regulation. That said, a well-constructed data protection addendum \u2014 as already offered by many software-as-a-service providers \u2014 would likely already meet the same requirements.",
            "There could be a non-high-risk scenario that nevertheless poses serious AI risks to a business, such as a system intended to predict important business outcomes \u2014 like logistics or demand and/or inventory predictions. In such a scenario, the key risks would center around the accuracy and usefulness of the AI system.",
            "Therefore, much of the MCC-AI-Light\u2014 such as cybersecurity and data governance, integrity and accuracy \u2014 would be helpful from the buyer's perspective. Even some of the MCC-AI-High-Risk might be a good idea, such as pre-delivery conformity assessment.",
            "For vendors, these requirements don't necessarily mean the contract has to look like these MCC-AI. For example, cybersecurity requirements can be met with existing security terms and agreeing to maintain ISO 9001 certification can demonstrate a sufficient quality management system.",
            "Alex Wall, AIGP, CIPP/E, CIPP/US, CIPM, FIP, is principal attorney at Wall Law."
        ]
    },
    {
        "url": "https://iapp.org/news/a/what-brazil-s-anpd-expects-from-companies-using-generative-ai",
        "title": "What Brazil's ANPD expects from companies using generative AI",
        "location": "South America",
        "date_published": "25 June 2025",
        "keywords": [
            "AI Governance",
            "Law & Regulation",
            "Regulatory Guidance"
        ],
        "description": "With Brazil's artificial intelligence bill still under discussion in Congress, its data protection authority, the Autoridade Nacional de Prote\u00e7\u00e3o de Dados, has taken a proactive step by releasing Technology Radar No. 3.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. \r",
            "With Brazil's artificial intelligence bill still under discussion in Congress, its data protection authority, the Autoridade Nacional de Prote\u00e7\u00e3o de Dados, has taken a proactive step by releasing Technology Radar No. 3.",
            "Issued in late 2024, the publication outlines the DPA's perspective on generative AI and its alignment with the country's General Data Protection Law. While not legally binding, the document provides important guidance organizations should not overlook.",
            "Generative AI models, such as large language models, rely on large volumes of data for training, fine-tuning and use. The ANPD sees the data life cycle of these models as closely connected to the processing of personal data. This includes collecting, processing, sharing and deleting data. Each step involves specific privacy risks that must be managed in line with LGPD requirements.",
            "In the data collection phase, the ANPD highlights the widespread use of web scraping tools that gather content from across the internet \u2014 often without checking whether that content includes personal or sensitive data. These datasets are often used without proper filtering or anonymization. The ANPD reminds organizations that even publicly available information is still subject to LGPD principles, especially when it comes to necessity, transparency and good faith.",
            "During the processing stage, although training models usually hide raw data behind mathematical structures, there is still a risk of revealing personal data through techniques like model inversion or membership inference attacks. Moreover, AI models can generate synthetic content that looks very real, and in some cases, may affect individuals' reputation, privacy or rights.",
            "Data sharing further complicates things. People might enter personal data into prompts or upload documents with sensitive content. The AI's responses may also include details that resemble personal information. And when companies reuse or share pre-trained models, they might unknowingly carry forward risks hidden in the original dataset. These situations call for strong internal governance and clear agreements between developers, providers and users.",
            "When it comes to deleting data, the ANPD points out generative AI doesn't follow a simple beginning-and-end life cycle. Once data enters a system \u2014 through training, prompts or uploads \u2014 it might be reused later during model updates or refinements. Organizations need to rethink when data use should end, how long is reasonable to store data and whether user consent still applies as the system evolves.",
            "The ANPD links these risks to key LGPD principles, like purpose limitation, necessity, transparency and accountability. The DPA recommends companies adopt technical and organizational safeguards and keep documentation \u2014 including data protection impact assessments \u2014 to show they are responsibly handling personal data.",
            "Even without specific AI legislation, the ANPD's document helps fill in the gaps by showing how Brazil's current data protection rules apply to emerging technologies. For companies doing business in Brazil or handling residents' data, this is more than a policy note \u2014 it's a practical roadmap.",
            "Technology Radar No. 3 isn't a list of rules, but it reflects the thoughts of  Brazil's privacy regulator. This is a valuable early guide for compliance and a strongindicator of what may come next for companies using generative AI.",
            "In short, generative AI should be built with considerations to privacy and data protection from the start. According to the ANPD, innovation and regulation go hand in hand. In Brazil, doing both \u2014 responsibly and transparently \u2014 is already the expectation.",
            "Tiago Neves Furtado, CIPP/E, CIPM, CDPO/BR, FIP, leads the Data Protection and Artificial Intelligence Team and the Incident Response Team at Opice Blum Advogados."
        ]
    },
    {
        "url": "https://iapp.org/news/a/cross-border-data-transfers-in-fintech-navigating-post-gdpr-regulations",
        "title": "Cross-border data transfers in fintech: Navigating post-GDPR regulations",
        "location": "Europe, North America",
        "date_published": "25 June 2025",
        "keywords": [
            "Finance & Banking",
            "International Data Transfers",
            "Law & Regulation",
            "Frameworks & Standards"
        ],
        "description": "In the financial technology sector, cross-border data flows are fundamental to operations. From instant payment platforms to artificial intelligence-powered lending tools, personal and financial data must flow seamlessly across borders for fintechs to remain competitive.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. ",
            "In the financial technology sector, cross-border data flows are fundamental to operations. From instant payment platforms to artificial intelligence-powered lending tools, personal and financial data must flow seamlessly across borders for fintechs to remain competitive.",
            "However, strict regulatory scrutiny \u2014 particularly with the enforcement of the EU General Data Protection Regulation and the landmark Schrems II ruling \u2014 has introduced significant compliance risks for companies managing international data transfers.",
            "The GDPR imposes stringent conditions on the transfer of personal data outside the European Economic Area. These transfers are only lawful when the destination ensures an \"essentially equivalent\" level of protection to that provided within the EU.",
            "To achieve this level of protection, the GDPR provides several mechanisms, including adequacy decisions, where the European Commission recognizes that a third country offers sufficient protection, and standard contractual clauses or binding corporate rules, which establish enforceable safeguards through legal agreements.",
            "To determine whether these measures are effective, organizations must conduct a transfer impact assessment, which involves evaluating the legal and practical landscape of the recipient country, including laws on government surveillance and enforcement mechanisms, to determine whether supplementary safeguards are needed.",
            "While the adoption of the EU-U.S. Data Privacy Framework has re-established a formal adequacy pathway for transfers to certified U.S. entities, uncertainty remains. Indeed, recent structural changes to the U.S. Privacy and Civil Liberties Oversight Board and the Federal Trade Commission have raised legitimate concerns about the framework's durability.",
            "For fintech companies, this situation presents unique complications. These companies often operate on cloud-based, decentralized infrastructures, handling vast amounts of personal and financial data that needs to move fluidly across borders to maintain operational agility.",
            "Unlike traditional financial institutions, the architecture of fintech companies is modular; their services are real-time; and their third-party dependencies are extensive. Application programming interfaces link customer data to analytics engines, fraud detection tools, payment gateways and customer support platforms. Many of these are hosted or managed outside the EU, which results in a network of data flows that is not always fully visible to the business itself, let alone data subjects.",
            "Mapping these data flows is one of the most fundamental, yet most difficult, steps toward compliance. Without a clear view of where data is going, it is nearly impossible to choose the right transfer mechanism or apply appropriate safeguards.",
            "However, for startups and scale-ups, this task is often inhibited by limited compliance expertise and resource constraints. What complicates matters further is the divergence in global privacy frameworks. Fintechs with international user bases frequently find themselves navigating conflicting obligations, such as EU data export requirements, Asian data localization laws or U.S. cloud access mandates\u2014 all while trying to maintain a seamless user experience.",
            "In this context, it is critical to choose the right data transfer mechanism. SCCs remain the most widely adopted solution due to their flexibility and accessibility. The 2021 revisions to the SCCs introduced modularity, allowing them to better reflect real-world transfer scenarios, including processor-to-processor and processor-to-controller arrangements.",
            "However, SCCs are not ready to use as-is for fintechs, since they must evaluate whether the legal environment in the recipient country permits effective enforcement of these clauses. For this, they must be accompanied by TIAs and, in many cases, supplemented with additional safeguards.",
            "For larger organizations with multiple entities around the world, BCRs can provide a more sustainable and robust solution. They provide a unified framework for intra-group transfers but require approval from EU data protection authorities, making them resource-intensive to implement and maintain.",
            "When available, adequacy decisions are the easiest solution since they reduce the need for additional safeguards. However, only a limited number of countries currently wholly or partially benefit from these decisions and their future may be uncertain. New models such as industry codes of conduct and certification schemes may offer alternative routes to compliance in the future, but these remain in early development stages.",
            "Beyond the choice of mechanism, effective compliance depends on building a privacy-resilient infrastructure from the ground up. The cornerstone of GDPR compliance for international transfers lies in conducting comprehensive TIAs that are not only rigorous but also operationally grounded.",
            "These assessments must look beyond the formal legal environment to examine practical realities, including the likelihood of government access to data, the technical capabilities of local providers, and the enforceability of rights.",
            "Due diligence also involves vetting third-party vendors and subprocessors. This includes reviewing their data protection practices, contractual safeguards and incident response capabilities, ideally as part of a broader third-party risk management strategy.",
            "Technical safeguards play a key role in mitigating residual risks. Strong encryption at rest and in transit, pseudonymization and strict access controls can significantly reduce the risks associated with international data transfers. When effectively implemented, under the European Data Protection Board's guidance, these controls can mitigate risks that SCCs or BCRs alone cannot fully address.",
            "Transparency with users is equally important. Individuals want to know where their data goes, who has access to it and what their rights are. Fintechs should offer clear, accessible privacy notices and, where consent is used as a legal basis, ensure it is informed, specific and freely given. Tools that allow users to manage preferences or view where their data is stored can also help reinforce trust.",
            "As the fintech ecosystem continues to evolve, so too does the regulatory and technological landscapes surrounding cross-border data transfers. Staying ahead of these changes is not only a compliance necessity, but also a strategic advantage.",
            "Looking ahead, the landscape for international data transfers is likely to become more complex, as regulatory fragmentation continues to increase. While the GDPR has become a global benchmark, it is not the only privacy regulation. Jurisdictions around the world, from Brazil to India to Kenya, are enacting their own data protection laws \u2014 each with different rules on cross-border transfers and user rights.",
            "For fintechs operating internationally, this diversity in legal frameworks demands greater agility in governance and potentially localized compliance strategies.",
            "The EU itself is not standing still. The long-term viability of the EU-U.S. DPF is currently being tested and further refinements to SCCs and sector-specific codes of conduct are under discussion.",
            "However, technologies may offer privacy-enhancing solutions for cross-border compliance. Advances in confidential computing, secure multi-party computation, and federated learning allow data to be analyzed across jurisdictions without the actual transfer of data.",
            "Moreover, automated consent and preference management tools, risk assessment platforms, and compliance-as-a service models are gaining traction, particularly among resource-limited fintechs seeking scalable solutions. Forward-looking organizations will invest in both regulatory foresight and tech-driven privacy engineering, to ensure they are prepared for what is next.",
            "Cross-border data transfers are essential to fintech growth and innovation, but they pose significant regulatory and operational challenges.",
            "GDPR-compliant mechanisms, such as SCCs, BCRs or adequacy decisions, must be embedded within a broader strategy of governance with technical safeguards and clear user communication.",
            "Success depends on adopting a proactive mindset to anticipate changes, leverage technology and treat privacy not as a constraint, but as a cornerstone of trust and resilience.",
            "Paul Krasy is data protection officer for the Mentor Group. "
        ]
    },
    {
        "url": "https://iapp.org/news/a/from-compliance-cost-to-competitive-edge-how-privacy-leaders-can-command-the-executive-table",
        "title": "From compliance cost to competitive edge: How privacy leaders can command the executive table",
        "location": "",
        "date_published": "25 June 2025",
        "keywords": [
            "AI Governance",
            "Data Ethics",
            "Data Security",
            "Risk Management"
        ],
        "description": "Amid accelerating innovation, particularly in generative artificial intelligence and data-driven technologies, privacy leaders are being called to the executive table more often \u2014 but their voices aren't always fully heard.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. \r",
            "Amid accelerating innovation, particularly in generative artificial intelligence and data-driven technologies, privacy leaders are being called to the executive table more often \u2014 but their voices aren't always fully heard.",
            "The latest IAPP Privacy Governance Report shows more than 80% of privacy professionals now manage responsibilities far beyond traditional data protection, including AI governance, data ethics, cybersecurity and platform liability initiatives. Despite this expanded scope, privacy is still too often framed as a compliance cost rather than a strategic enabler.",
            "As technology continues to outpace regulation and nearly half of organizations identify AI governance as a top business priority, privacy has become the integrating force across emerging risks, placing leaders at the center of complex, high-stakes decisions that shape market trust and business growth.",
            "This is the moment to redefine the conversation and show how privacy drives responsible innovation, operational resilience and long-term value. And it starts by communicating evolving risks in business terms that command executive attention and reposition privacy as a critical investment in competitive advantage.",
            "In fast-moving sectors, speed is everything. Yet privacy is often perceived as a barrier to innovation, a function that slows down development in the name of compliance. This perception is both outdated and counterproductive.",
            "Leading technology companies demonstrate that when privacy is embedded early, it accelerates product development rather than becoming a last-minute hurdle. Engaging privacy teams during the design phase helps surface potential risks before significant resources have been spent, reducing costly rework and ensuring products enter the market with trust and confidence already built in.",
            "Standardized privacy frameworks, internal documentation and predictable review processes help organizations maintain their speed-to-market advantage. When engineering and product teams understand privacy expectations from the outset, they can design accordingly, reducing delays and eliminating last-minute surprises.",
            "The real unlock happens when privacy shifts from being perceived as a set of roadblocks to a source of clarity and confidence for innovative teams.",
            "For privacy leaders to command influence, they must speak the language of business strategy. Executives care about growth, market differentiation and customer loyalty \u2014 privacy must be positioned as a contributor to these very outcomes.",
            "Rather than focusing solely on regulatory risks, successful privacy leaders demonstrate how their work directly supports strategic priorities, accelerating digital transformation, reducing regulatory friction and strengthening customer trust.",
            "Influence grows from sustained collaboration, not isolated interventions. The most effective privacy programs foster deep, ongoing partnerships across product, engineering, marketing and sales teams. Privacy leaders who actively participate in shaping product strategies naturally position themselves as strategic partners, not compliance gatekeepers.",
            "Privacy risks often surface too late: when data protection agreements are finalized or products are ready to launch. By then, business flexibility is already compromised, leaving leaders to navigate rigid contractual terms or scramble to retrofit compliance.",
            "The most forward-looking organizations understand privacy creates the greatest value when embedded early in decision-making.",
            "In high-stakes industries like technology and financial services, this isn't just best practice, it's a competitive necessity. Privacy teams that work directly with commercial stakeholders before contracts are signed help preserve long-term market access and operational agility.",
            "Framing privacy terms as growth enablers, protecting against hidden costs of regulatory shifts and market barriers, makes privacy immediately relevant to leadership's bottom line.",
            "This approach helps organizations avoid the trap of short-term thinking. Companies that negotiate with evolving regulations and future market opportunities in mind position themselves to pivot quickly, rather than lose critical time and momentum when the landscape changes.",
            "One of the greatest challenges privacy leaders face is that a well-run program often makes its success invisible. No fines. No breaches. No headlines. And while that's the goal, it makes privacy's value less visible to leadership.",
            "The IAPP Privacy Governance Report reinforces this challenge \u2014 while privacy programs expand in scope, success metrics often lag behind. This makes it even more critical for privacy leaders to translate their work into measurable outcomes that resonate with executive decision-makers.",
            "Real-world examples of competitors facing regulatory penalties or reputational damage serve as powerful reminders of the risks avoided through proactive privacy programs. Operational metrics \u2014 such as faster vendor approvals, reduced negotiation times and lower incident response costs \u2014 help quantify how privacy drives efficiency and enables business agility.",
            "Above all, privacy must be positioned as a strategic investment that supports and grows revenue. Companies that integrate privacy into their brand narrative create meaningful market differentiators and earn lasting customer loyalty in a privacy-conscious world.",
            "Privacy by design must move from principle to practice, becoming a core operational standard that supports product innovation and business growth from day one.",
            "Organizations that excel in this area integrate privacy checkpoints directly into agile development cycles, treating privacy as a standard success metric alongside functionality and user experience. Cross-functional privacy champions identify potential issues early and ensure product teams have the tools and guidance needed to navigate them effectively.",
            "Automation also plays an increasingly critical role. Scalable privacy tools for data mapping, risk assessment and continuous monitoring allow organizations to stay ahead of compliance requirements without slowing innovation.",
            "Technology will always outpace regulation. Waiting for new laws to define what's permissible keeps organizations on the defensive. Instead, privacy leaders must act as strategic forecasters, anticipating emerging risks and preparing their organizations to navigate change before it arrives.",
            "Staying ahead requires continuous investment in technical literacy and global regulatory awareness. It also demands close collaboration across legal, compliance, product, and engineering teams to create resilient, future-proof privacy strategies.",
            "Above all, privacy leaders must position early action as a competitive advantage. Organizations that anticipate privacy risks before the market does are better positioned to lead in new industries, navigate regulatory uncertainty with confidence and build trust long before competitors.",
            "In a world where consumer trust is a defining currency of business success, privacy leadership is no longer just about compliance \u2014 it is a driver of growth, resilience and long-term value.",
            "The organizations that embrace this reality, and empower their privacy leaders accordingly, won't just survive the next wave of technological disruption. They'll define it and set new standards for how responsible innovation and trusted customer relationships shape the future of business.",
            "Basia Walczak is privacy and product counsel at Trulioo; Hussein Abdulghani, CIPP/E, CIPT, FIP, is a manager at Boston Consulting Group; Benjamin Kaplan, CIPP/E, CIPM, CIPT, FIP, is a privacy engineer at a leading technology company; and Melanie Selvadurai, CIPP/C, is privacy program manager at TikTok."
        ]
    },
    {
        "url": "https://iapp.org/news/a/don-t-abandon-our-values-why-the-eu-must-stay-the-course-on-ai-regulation",
        "title": "Don't abandon our values: Why the EU must stay the course on AI regulation",
        "location": "Europe",
        "date_published": "24 June 2025",
        "keywords": ["AI Governance", "Law & Regulation"],
        "description": "The European Commission is reportedly considering a pause to the entry into application of the Artificial Intelligence Act, citing challenges around technical standards, industry backlash and geopolitical tensions \u2014 including direct requests from the U.S. government. At first glance, this looks like prudent regulatory realism. But a deeper look suggests something else: a loss of nerve at the very moment Europe needs genuine leadership. The EU should address implementation challenges head-on \u2014 not by deferring ambition, but by doubling down on its digital strategy.",
        "content": [
            "The European Commission is reportedly considering a pause to the entry into application of the Artificial Intelligence Act, citing challenges around technical standards, industry backlash and geopolitical tensions \u2014 including direct requests from the U.S. government. At first glance, this looks like prudent regulatory realism. But a deeper look suggests something else: a loss of nerve at the very moment Europe needs genuine leadership. The EU should address implementation challenges head-on \u2014 not by deferring ambition, but by doubling down on its digital strategy.",
            "The AI Act is no ordinary piece of legislation. EU policymakers as well as international observers have celebrated the act as the flagship of the EU's claim to global leadership in shaping rules for emerging technologies. From the 2020 white paper \"On Artificial Intelligence - A European approach to excellence and trust\" onward, its purpose was not just to ensure safety, but to define a European path toward trustworthy, human-centric innovation in AI. A significant delay or full-scale modification of the law, even if framed as technical, would send the opposite message \u2014 that the EU no longer has confidence in its own ambitions.",
            "Yes, the AI Act's implementation is difficult. Member states are racing to staff national authorities. The AI Office is still being set up. Harmonized standards still need a lot of work. The Code of Practice for General Purpose Artificial Intelligence models remain mired in legal and political complexity, not least due to trans-Atlantic tensions. But none of these challenges justify throwing all of our AI plans into disarray.",
            "In a recently published policy paper, the \"European Way. A blueprint for reclaiming our digital future,\" our co-authors and us advocated for an EU that moves beyond fragmented policies or erratic actions and instead pursues a coherent values-based digital strategy across the entire technology stack \u2014 from e-commerce over data spaces to chips and quantum. The AI Act is one important element of this overall vision. Weakening or significantly delaying it now without a compelling rationale would not only prolong legal uncertainty for our European AI firms, but hollow out one of the EU's most ambitious regulatory projects.",
            "Let us be clear: simplification, clarification and even some recalibration of the AI Act are necessary. Giving the AI ecosystem a few more months to prepare for the application of the new, high-risk obligations might even be imperative. But that's not the same as deregulation. It would be a major strategic error to conflate the need for a sound preparation with a justification for the long-term suspension of the AI Act's enforcement. If anything, it would confirm what many critics have long warned: the EU is strong in drafting legislation but weak in its implementation and enforcement.",
            "Moreover, submitting to geopolitical pressure would be a self-inflicted wound. Washington has reportedly asked Brussels to stop the law's enforcement. The EU should not subordinate its regulatory autonomy to a negotiating chip in trade talks. While the EU must always remain strongly committed to the trans-Atlantic partnership, it must also defend its foundational values. After all, it is precisely the EU's insistence on fundamental rights, risk classification, accountability and transparency that distinguishes its AI approach from laissez-faire or state-driven models.",
            "The real lesson from this whole debate is not so much that the EU has overregulated the tech sector, but that it underestimated what an effective policy strategy really entails. The \"European Way\" policy paper fills this vacuum by developing a strong overall digital vision, complemented by a coherent policy roadmap. What does it have in store for the AI Act? Instead of retreating from the law, the Commission should use this moment to take three bold steps:",
            "First, it should consolidate the scattered efforts to support small and medium-sized enterprises. SMEs need support that is both authoritative and useful, not just an extensive patchwork of guides, some with questionable correctness, published by numerous public institutions, initiatives and private companies. The Commission could launch a comprehensive easy compliance package for SMEs, bundling legal guidance, flowcharts, checklists, and establish an ambitious EU one-stop shop, using regulatory sandboxes and giving financial incentives. Compliance should be a path to innovation \u2014 not a bureaucratic minefield.",
            "Second, it should reconsider whether AI Act enforcement should really be left to decentralized authorities, and whether it should really be separate from the enforcement of other digital regulation. One option would be to move towards a digital enforcement agency with a clear mandate to operationalize the AI Act and related digital laws, such as the EU Digital Services Act or EU General Data Protection Regulation. Decentralized or political enforcement by member states or the Commission risk divergence and regulatory hesitation. Strong central capacity is key to legal certainty and tech investor confidence.",
            "Third, it should roll out a comprehensive \"Digital Industrial Strategy\" focused on building sovereign digital infrastructure where it matters most: AI compute, AI quality with measurable indicators, resilient cloud, trusted connectivity and applied AI. This is not about replacing global partners, but about ensuring Europe can shape \u2014 and not just consume \u2014 tomorrow's technologies and make better use of our strengths as well as strategic advantages.",
            "Each of the three steps will face fierce resistance. None will be easy. But then again, neither was the creation of the single market, the launch of the euro, nor the EU's unified response to the COVID-19 or Russia's war against Ukraine. Every milestone in European integration began in doubt and debate \u2014 and ended as a defining moment of strength and solidarity. The EU now stands before another such moment. Let us not hesitate. Let us write the next chapter in Europe's story \u2014 one defined by purpose, not pressure.",
            "All expressed views are personal and do represent neither the position of the European Parliament nor of the EPP Group.",
            "Kai Zenner is head of Office and Digital Policy Adviser for MEP Axel Voss (European People's Party) in the European Parliament.",
            "Sebastian Hallensleben is chief trust officer at Resaro. He is also co-chair of the AI risk and accountability work at OECD and chair of CEN-CENELEC AI standardization group JTC 21."
        ]
    },
    {
        "url": "https://iapp.org/news/a/beyond-data-breaches-court-ruling-signals-broader-ccpa-liability-for-tracking-technologies",
        "title": "Beyond data breaches: Court ruling signals broader CCPA liability for tracking technologies",
        "location": "North America",
        "date_published": "24 June 2025",
        "keywords": [
            "Advertising & Marketing",
            "Enforcement",
            "Law & Regulation",
            "Litigation & Case Law",
            "Privacy Program Management"
        ],
        "description": "A March ruling from the U.S. District Court for the Northern District of California could significantly reshape the scope of consumer privacy litigation under the California Consumer Privacy Act.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. \r",
            "A March ruling from the U.S. District Court for the Northern District of California could significantly reshape the scope of consumer privacy litigation under the California Consumer Privacy Act.",
            "In Shah v. Capital One Financial Corporation, the court ruled claims can proceed based not on a data breach, but on the unauthorized disclosure of personal information via embedded tracking tools. This signals a growing judicial openness to interpreting the CCPA's private right of action more broadly to reach beyond security incidents.",
            "As plaintiffs' lawyers continue to push the boundaries of privacy enforcement, the ruling may mark a shift that expands litigation risk for companies that rely on analytics and adtech tools. The case also raises questions about how businesses approach consent, transparency and third-party data flows.",
            "In Shah v. Capital One Financial Corporation, plaintiffs alleged the company's website employed third-party tracking tools, such as Meta Pixel and Google Analytics, that collected and transmitted users' personal and financial information to advertisers without proper consent.",
            "The court denied Capital One's motion to dismiss several key claims, notably under the CCPA, California Invasion of Privacy Act, and the Electronic Communications Privacy Act. The California Invasion of Privacy Act, a California wiretapping statute, prohibits the unauthorized interception or recording of communications, and has increasingly been used in privacy litigation targeting website session replay and tracking technologies. The Electronic Communications Privacy Act, a federal law originally designed to protect against government surveillance, has similarly become a tool for plaintiffs challenging interception of electronic communications by private entities through embedded website tracking tools.",
            "Together, these statutes reflect a growing trend of litigation using older communications laws to address modern digital privacy harms.",
            "The court's decision clarified that the unauthorized disclosure of personal information through embedded tracking technologies can violate the CCPA, even absent a traditional data breach. Specifically, the court found that because the plaintiffs allege Capital One \"allowed third parties to embed trackers, such as Google and Microsoft, on its website and that these trackers transmitted Plaintiffs' personal information,\" their claims were sufficient under the CCPA.",
            "Additionally, the court upheld claims under the California Invasion of Privacy Act determining that intercepting and recording electronic communications through tracking tools without explicit consent could breach state wiretapping laws. Lastly, the court allowed claims under the Electronic Communications Privacy Act to proceed, finding that even a party to a communication may be liable if it intercepts electronic communications via tracking technologies without proper consent.",
            "The ruling underscores the necessity for businesses to reassess their data collection and sharing practices, particularly concerning third-party tracking technologies. For companies relying on adtech or other embedded third-party tools, the Shah ruling offers a reminder that compliance with privacy laws requires more than data breach response protocols.",
            "Businesses should take proactive steps to assess and address the legal risks associated with routine tracking technologies including:",
            "While this case does not establish a final ruling on the merits, it reflects a judicial willingness to entertain broader interpretations of what constitutes a data breach or unauthorized disclosure under state and federal privacy laws. The decision could encourage plaintiffs to frame privacy violations through the lens of passive data collection technologies, rather than requiring evidence of malicious hacking or theft.",
            "This shift comes amid increased regulatory scrutiny of data-sharing practices tied to behavioral advertising, analytics and cross-site tracking. Regulatory bodies, such as the U.S. Federal Trade Commission and state attorneys general, have signaled that lack of transparency around these practices may constitute unfair or deceptive conduct under consumer protection laws. Thus, litigation risk is only one side of the equation,; regulatory enforcement may also follow.",
            "As a result, businesses need to think beyond compliance checklists and adopt a more dynamic approach to data governance. This includes routine assessments of tracking tools, updates to cookie banners and consent flows and clear internal policies about data flows across platforms and partners. Legal, compliance and marketing teams should be aligned in reviewing how technology stacks impact user privacy rights under state and federal law.",
            "Jennifer Dickey, AIGP, CIPP/E, CIPP/US, CIPM, CIPT, FIP, is an attorney at Dykema."
        ]
    },
    {
        "url": "https://iapp.org/news/a/new-threads-in-the-patchwork-key-trends-in-us-comprehensive-state-privacy-law-amendments",
        "title": "New threads in the patchwork: Key trends in US comprehensive state privacy law amendments",
        "location": "North America",
        "date_published": "23 June 2025",
        "keywords": [
            "Advertising & Marketing",
            "Children's Privacy",
            "Data Subject Rights",
            "Law & Regulation",
            "Data Protection Obligations"
        ],
        "description": "As of 28 June, this year, the oldest comprehensive U.S. state privacy law \u2014 the California Consumer Privacy Act \u2014 will be old enough to enter the second grade. Even though U.S. state privacy laws are fresh-faced newcomers, they can still struggle to account for changes in the rapidly developing technological landscape.",
        "content": [
            "Editor's note: This article has been updated to reflect that Connecticut SB 1356 failed and not passed as originally indicated. ",
            "As of 28 June, this year, the oldest comprehensive U.S. state privacy law \u2014 the California Consumer Privacy Act \u2014 will be old enough to enter the second grade. Even though U.S. state privacy laws are fresh-faced newcomers, they can still struggle to account for changes in the rapidly developing technological landscape.",
            "To address shifting needs and new issues, lawmakers have proposed a flurry of amendments to the 19 comprehensive U.S. state privacy laws. While some amendments implement changes that mirror language in other states' laws, some respond to developments in public priorities or to highly public enforcement actions.",
            "Some commentators have said the law trails behind technology, but these amendments look forward, seeking to keep up with the times so legislation can be flexible enough to adapt alongside technology. Even if the bills fail, they can still signal legislators' values, priorities and the focus of their attention. Taken collectively, proposed amendments offer a window into the key trends shaping the future of U.S. state privacy legislation.",
            "Several proposed amendments aim to make exercising consumer privacy rights easier. The first way they do this is by introducing requirements around allowing consumers to use an automated tool to opt out of the sale or sharing of their personal information or to exercise similar privacy rights based on the consumer's jurisdiction. This idea goes by many names, including universal opt-out mechanisms, opt-out preference signals, consumer choice mechanisms or privacy preference tools. There are technical differences between these terms, but the general idea is the UOOM allows the consumer to automatically indicate their privacy preferences instead of clicking on cookie banners on a site-by-site basis.",
            "The most widely known UOOM tool is the Global Privacy Control, a protocol available as a browser extension or an option built into some browsers. To simplify, if a consumer has GPC enabled, their web browser automatically sends a signal with each website request that tells the site the consumer wants to exercise their privacy rights as given by their jurisdiction. If the site is configured to accept the GPC signal, then it can voluntarily choose to comply with the user's preferences. The IAPP has a resource page with more information about GPC.",
            "Most of the laws on the books implement UOOMs by allowing consumers to designate an \"authorized agent,\" which can be a person or a \"technology, including a link to an internet website, an internet browser setting or extension, or a global setting on an electronic device, that allows the consumer to indicate the consumer's intent to opt out of (personal information) processing.\" Slight variations on this wording appear in all of the state privacy laws and rules except for Indiana, Iowa, Kentucky, New Jersey, Tennessee, Utah and Virginia. Rhode Island mentions authorizing an agent but does not say whether the agent can be a technology. In states with this provision, businesses must comply with UOOM requests.",
            "Several amendments would incorporate or increase UOOM applicability in their respective laws. Tennessee's legislative session has ended, but Senate Bill 663 would have added the \"authorized agent\" provision into its law, mimicking the language seen across the other states' laws. California's Assembly Bill 566 would require all businesses that \"develop or maintain a browser\" to incorporate a UOOM setting, including mobile browsers. Texas House Bill 5495, which failed, would have added a similar provision requiring controllers that operate browsers to \"automatically recognize and comply with a consumer's global privacy control choices.\"",
            "Additionally, although Texas state privacy law already includes the \"authorized agent\" provision, HB 5495 would have added a section that defines \"global privacy control\" and requires controllers to \"treat the consumer's use of a global privacy control as a valid request submitted by the consumer not to sell, share, or disclose the consumer's personal data.\" Violators of that provision would be subject to civil penalties of up to USD5,000 per violation, with repeat offenders fined an amount that is \"sufficient to deter future violations of that section, as determined by the court.\"",
            "These amendments show lawmakers hear and understand their constituents' complaints that consent management for privacy choices is difficult and tedious. Around the world, users overexposed to repeated data processing consent requests have started to get consent fatigue, also called cookie fatigue. Some banners pop up in the middle of the screen and obscure the content the user was trying to view, which can cause frustration and lead to the user trying to click the option that makes the pop-up go away the fastest or sometimes exiting the page entirely. Other consumers don't read or don't trust promises not to process their information, so they may not indicate their actual preferences, which can tamper with marketing data or analytics.",
            "To combat cookie fatigue, the European Commission has coordinated a voluntary initiative to simplify the cookie consent process by, for example, allowing users to indicate their cookie preferences with a UOOM. These amendments take that concept a step further by imposing legal obligations on businesses to comply with the consumer's signals. As states refine how adults assert control over their data, they are also turning their attention to the privacy of younger users.",
            "Many of the U.S. state privacy amendments proposed this year would increase privacy protections for children. This reflects a broader trend in the privacy field; for example, this year the FTC published final amendments to the Children's Online Privacy Protection Rule, which went into effect 23 June 2025. At IAPP's Global Privacy Summit, Federal Trade Commissioner Melissa Holyoak explained in her keynote speech that COPPA amendments seek to give parents \"meaningful choices to protect their children, not mere fig leaves to insulate the operator from liability for design choices that expose kids to sexual predators, obscene content, violence or other such harms.\"",
            "State legislators are addressing concerns about children's privacy on social media platforms via amendments like Virginia's SB 854, now passed into law, which requires social media platforms to age-screen users and limit any minor's use of the social media to one hour per day by default, with parental consent needed to increase or decrease this limit. Connecticut's SB 1295, which also passed, requires social media platform operators to create an online safety center, a cyberbullying policy and a plan for mitigating or eliminating any heightened risk of harm to minors, which it defines expansively. It also requires platforms to refrain from using features to keep a minor scrolling as well as a setting that, by default, bars adults from sending unsolicited communications to minors.",
            "Other bills come at this from a different angle: they regulate collecting and processing children's data. Oregon's HB 2008, which passed, entirely prohibits controllers from selling a minor's data or processing their data for purposes of targeted advertising or to make legally significant decisions. It also raises the upper age limit from 15 to 16, similar to Iowa's failed Senate File 143, which would have changed the definition of \"child\" from those under 13 to those under 18. In Colorado, processors must obtain a parent or guardian's consent before processing a child's data, and a rider in SB 276 amends the Colorado Privacy Act to require consent before selling a child's data as well.",
            "In laws that regulate how controllers process a minor's data, there is a standard for when the controller can be liable that varies by jurisdiction. For example, the Montana Consumer Data Privacy Act has specific provisions that apply when a controller \"has actual knowledge\" that a consumer is a minor. Montana's SB 297 would expand that standard to when a controller \"has actual knowledge or willfully disregards\" that a consumer is a minor. Connecticut has passed SB 1295, which expands the standard even more; currently, the Connecticut Data Privacy Act encompasses when a controller \"has actual knowledge, or willfully disregards\" a consumer is a minor, but SB 1295 changes it to protect \"consumers whom such controller has actual knowledge, or knowledge fairly implied based on objective circumstances, are minors.\"",
            "Texas, which has positioned itself as a strong enforcer of its privacy laws, proposed a bill broadly limiting AI development and deployment that includes provisions to protect children. HB 149 prohibits developing or distributing an AI solely intended to produce sexually explicit deepfakes or child sexual abuse material. It also forbids intentionally developing or distributing conversational AI systems that can simulate or describe sexual conduct while impersonating or imitating a child.",
            "These are far from the only approaches legislators are taking to address increasing children's privacy. For example, some states have passed standalone age-appropriate design codes, social media addiction laws or laws strictly limiting the collection and processing of children's data. Kids aren't the only ones getting new layers of protection though; some amendments zero in on what kinds of data deserve special treatment.",
            "States are also expanding protection for sensitive data, with some specifically focusing on geolocation data. For example, Colorado's SB 25-276 expands the definition of \"precise geolocation data\" and adds precise geolocation data as a subcategory of sensitive data. This imposes additional obligations on collecting and processing geolocation data, including requiring consent before collection.",
            "Texas's HB 4636 adds \"real-time driving data\" to the definition of sensitive data. It requires controllers that sell precise geolocation data to include \"NOTICE: We may sell your precise geolocation data\" in its privacy notice. This bill follows in the wake of enforcement actions by Texas Attorney General Ken Paxton against vehicle manufacturers and insurance providers that allege widespread data collection about drivers.",
            "Similarly, Oregon's HB 3875, now passed, changes the current applicability of the law to specifically include \"motor vehicle manufacturer(s) and any affiliate of a motor vehicle manufacturer that controls or processes any personal data obtained from a consumer's use of a motor vehicle or any component of a motor vehicle\" regardless of their size. Moreover, HB 2008 from the same state would completely bar selling precise geolocation data. Oregon doesn't stop there, though \u2014 HB 3899 would forbid processing any category of sensitive data for the purpose of targeted advertising or for profiling for a legally significant decision \"whether the controller has the consumer's consent or not.\" It also proscribes selling sensitive data for any reason, with or without consent.",
            "Minnesota's failed SF 2940 would have taken a narrower approach by allowing processing and sharing sensitive data with consent, but it required that a controller acquire \"separate and distinct\" consent to process a consumer's health data. A controller would also have needed to obtain separate and distinct valid authorization to sell any category of personal data.",
            "Connecticut's SB 1356, which failed, would amend \"sensitive data\" to include similar categories as those found in California and Colorado: neural data, data revealing a disability or treatment, status as nonbinary or transgender, financial information data and government-issued ID numbers. Genetic and biometric data were already included in sensitive data, but the amendment would add information derived from genetic and biometric data.",
            "It would also significantly change the Connecticut Data Privacy Act's applicability thresholds. Instead of the law applying to entities that process the data of more than 100,000 consumers per year, SB 1356 would lower the threshold to 35,000 per year. Connecticut's law also applies to entities that process the data of more than 25,000 consumers per year and derive more than 25% of their gross revenue from selling personal data. SB 1356 would reduce that to 10,000 consumers per year and 20% of gross revenue. The bill would also add blanket inclusion for entities that control or process sensitive data or offer consumers' personal data for sale in trade and commerce.",
            "SB 1356 is just one of several amendments with the goal of tweaking what kinds of data the law protects, limiting access to that data or reducing what a controller may do with it. This current wave of bills signals a deliberate shift toward more granular and assertive data governance frameworks. Many proposals will fail, but their cumulative direction is clear: states are filling perceived regulatory voids with increasingly sophisticated privacy legislation.",
            "These laws are still relatively young, but some of them are clearly entering a new phase: refinement and maintenance. These amendments help the law grow to fit emerging technologies and priorities. Taking cues from the world around them, U.S. state privacy laws are maturing into more permanent but still evolving fixtures of the legal landscape.",
            "C. Kibby is a Westin Research Fellow for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/governor-signs-texas-responsible-artificial-intelligence-governance-act",
        "title": "Governor signs Texas Responsible Artificial Intelligence Governance Act",
        "location": "North America",
        "date_published": "23 June 2025",
        "keywords": [
            "AI Governance",
            "Data Subject Rights",
            "Employment Privacy",
            "Enforcement",
            "Law & Regulation"
        ],
        "description": "Texas became the fourth U.S. state to pass a cross-sectoral law regulating the use of artificial intelligence when Gov. Greg Abbott, R-Texas, signed House Bill 149, the Texas Responsible Artificial Intelligence Governance Act, into law 22 June.",
        "content": [
            "Texas became the fourth U.S. state to pass a cross-sectoral law regulating the use of artificial intelligence when Gov. Greg Abbott, R-Texas, signed House Bill 149, the Texas Responsible Artificial Intelligence Governance Act, into law 22 June.",
            "Amid the backdrop of a proposed federal moratorium on state governments' abilities to draft legislation regulating various applications of AI, Texas is forging ahead with some guardrails in place on the use of the technology, following on heels of AI governance-related laws in California, Colorado and Utah. The TRAIGA enters into force 1 Jan. 2026, one month before the Colorado AI Act.",
            "State Rep. Giovanni Capriglione, R-Texas, sponsored the TRAIGA in the House and identified notable differences between Texas' approach versus that of Colorado. He told the IAPP, while Colorado's law seeks to regulate high-risk uses of AI, Texas' law aims to prevent and respond to harms caused by misuse of AI systems.",
            "Capriglione opined the broader push among states to explore passing AI regulations was partly borne out of the recognition they were behind on passing consumer data privacy laws in the past. He said he wanted Texas to be proactive in attempting to get ahead of the rapidly changing AI ecosystem to have some baseline guardrails in place going forward.",
            "\"We didn't want to be overburdensome, and we wanted to try to do this in a way that is reasonable and protects people from some of the biggest harms,\" Capriglione said. \"We thought that we had to hit the very high-level issues, and that means looking at some of the outputs that are problematic, making sure there are some disclosure requirements, we were updating our privacy laws and that we were listening to industry.\"",
            "Key provisions of the TRAIGA include disclosure requirements for state agencies when citizens interact with AI tools a specific agency may be using, bans on capturing biometric identifiers without consent and AI developers are prohibited from creating systems designed to manipulate human behavior, make discriminatory decisions and produce deepfakes that exploit children.",
            "The TRAIGA also establishes a regulatory sandbox contained within the newly created Artificial Intelligence Council under the state Department of Information Resources for companies to test AI models without fear of violating the law.",
            "Capriglione said the TRAIGA will likely have different impacts on public entities and the private sector.",
            "Under the law, public-sector entities' use of AI will be more heavily scrutinized to ensure systems being used uphold citizens' rights. In the private sector, Capriglione indicated much of TRAIGA was written to prevent businesses from knowingly deploying AI systems that cause harm to consumers, he said.",
            "\"Making sure the government is restricted in how it uses AI is actually easier to get done because it's a public process,\" he said. \"Agencies are going to have to come up with acceptable use policies and ethics on how each individual agency may or may not want its employees to use AI based on the risk levels.\"",
            "Latham & Watkins Partner Robert Brown, CIPP/US, CIPM, PLS, said a key dynamic of the TRAIGA is its \"intent element,\" which means entities developing and deploying an AI model would have to have been found that they disregarded key requirements of the law while creating or using the model to be found in violation.",
            "\"Governmental agencies will feel the greatest impact, as many of the requirements under the final version of the bill apply exclusively to them,\" Brown told the IAPP. \"The impact on private companies will be more limited \u2014 the law prohibits them from developing or deploying AI systems for various illicit purposes, but critically, each of these prohibitions includes an 'intent' element.\"",
            "The TRAIGA empowers state agencies to issue fines up to USD100,000 to any licensed individuals or organizations for violations caused by misuse of their AI systems.",
            "Capriglione said the law, as written, allows for per-violation penalties similar to how the Illinois Biometric Information Privacy Act functioned prior to reforms passed in 2024 that removed the per-scan violations, due to in part to significant fines issued to businesses for noncompliance. If covered entities do not rectify a violation within a 60-day cure period, the attorney general may assess an administrative fine \"of not less than USD80,000 and not more than USD200,000 per violation,\" according to the statute.",
            "The per-violation nature of enforcement could prove costly. Capriglione outlined a hypothetical scenario where if an insurance company deployed an AI tool that evaluates homeowners' viability to receive a policy and wrongfully denied 5,000 of them insurance, that insurance company could be liable for each erroneous denial their AI tool rendered.",
            "However, he also said the intent of the TRAIGA is not to grossly penalize businesses using AI and includes provisions to ensure that good faith compliance efforts on the part of AI deployers resulting in unexpected violations do not receive major fines. Unlike the BIPA, the TRAIGA does not allow for a private right of action.",
            "\"We allow for an opportunity to cure (the unlawful activity),\" Capriglione said. \"We provide sufficient time for someone to go in and fix their violation. And that is a benefit to the business, which is as long as they fix the problem, they'll avoid penalties.\"",
            "Brown said much of how the TRAIGA's penalties may ultimately be decided on a case-by-case basis by the state attorney general's office.",
            "\"While we don't yet know how the Texas Attorney General will interpret TRAIGA, the prohibitions under the law apply to the development, deployment, and/or distribution of AI systems for certain purposes,\" Brown said. \"The law is to be 'broadly construed,' and the attorney general has not been shy about bringing enforcement actions centered on the use of AI technologies in recent years. It's also worth noting that unlike under BIPA, TRAIGA is exclusively enforced by the Attorney General and does not provide a private right of action.\"\u00a0",
            "Still, the prospect of Congress approving a 10-year ban on enforcing AI legislation raises uncertainty over TRAIGA's enforcement and other states' AI legislative work.",
            "Capriglione said the majority of the work on TRAIGA and its filing were completed before Congress floated moratorium in its reconciliation bill. He does not support federal lawmakers including the AI provision because the proposals so far are simultaneously too vague and too proscriptive. For example, he said the moratorium's lack of clarity could prevent municipalities from approving data centers being constructed.",
            "Regardless of what the final language of the moratorium may say, Capriglione said it will likely lead to \"thousands of court cases,\" if it passes.",
            "\"I appreciate all the federal government does, however they have not really been able to work on super complicated, technical things like this for a long time and actually get them passed,\" he said. \"I would make the case (Congress) is still quite a ways way from having something in place that will sufficiently protect my constituents here in the state of Texas.\"",
            "Brown believes the final iteration of TRAIGA was written with an eye toward the moratorium, although he doesn't think the law in any form will remain in place if Congress ultimately passes its reconciliation bill with the moratorium included.",
            "\"It's possible one of the goals of scaling back the law was to placate federal lawmakers enough to avoid a complete moratorium on state AI laws,\" Brown said. \"Given how broadly the proposed moratorium is drafted, there's really no version of this bill that could survive it.\"",
            "Capriglione also said while the TRAIGA is the first AI governance law passed in Texas, it is unlikely to be the last governing how the technology is used within the state.",
            "\"I've spent the last six years working on these policy issues, and it's important that we continue our work because the technology is just changing so quickly,\u201d Capriglione said. \"I'm happy to work with anybody, anywhere, any time on crafting really good AI policy.\"",
            "Alex LaCasse is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/a-view-from-dc-former-ftc-chair-khan-reflects-on-her-privacy-legacy",
        "title": "A View from DC: Former FTC Chair Khan reflects on her privacy legacy",
        "location": "North America",
        "date_published": "20 June 2025",
        "keywords": ["Enforcement", "Law & Regulation"],
        "description": "In the fields of battle and regulatory enforcement alike, the thoughtful accumulation of incremental victories matters a lot toward shaping final outcomes. Without strategy, there can be no lasting path to victory.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "In the fields of battle and regulatory enforcement alike, the thoughtful accumulation of incremental victories matters a lot toward shaping final outcomes. Without strategy, there can be no lasting path to victory.",
            "As Sun Tzu wrote, \"Victorious warriors win first and then go to war, while defeated warriors go to war first and then seek to win.\u201d",
            "A cohesive strategy matters just as much in the ongoing policy debates over how the U.S. Federal Trade Commission's consumer protection authorities should be used in the effort to influence our understanding of reasonable privacy and cybersecurity practices.",
            "As it happens, not all history is written by the victors. Exercising a solid attempt to shape how academics and practitioners remember her term at the FTC, former Chair Lina Khan has published a major feature in the Stanford Law Review. Alongside Samuel Levine and Stephanie Nguyen, her director of consumer protection and chief technologist, respectively, Khan seeks to explain the cohesive strategy behind the data privacy efforts she oversaw at the commission during her tenure.",
            "On reflection, the trodden path always looks clearer than the path before us. In reality, FTC enforcement always represents the coming together of many factors \u2014 from staff interest and expertise to commissioner buy-in and the strategic engagement of agency leadership \u2014 all of which evolve and iterate over time. Nevertheless, the authors' accumulated learnings and strategic thinking on privacy provides a meaningful reflection and will serve as an important contribution to the practice of privacy in the consumer protection context. Though echoing the public statements of the authors across their years at the agency, the analysis represents the first time that their final strategies have been so coherently revealed and described.",
            "Overall, Khan, Levine and Nguyen characterize their FTC privacy legacy as one that shifted the agency's focus from \"procedural\" enforcement of notice and choice to \"substantive\" interventions into the root harms of the privacy practices undergirding the modern \"commercial surveillance\" ecosystem.",
            "To illustrate this shift, they focus on four areas of \"Biden-era\" privacy enforcement priority.",
            "\"First, the Commission would examine and target the upstream drivers of data abuses, focusing on the underlying collection of data and the business models driving this unchecked surveillance. Second, the Commission would scrutinize how firms design online architecture, especially 'dark patterns' that manipulate people and cost consumers money or time. Third, the Commission would recognize children and teens as a distinct category of consumers requiring strong protections. Finally, responding to the failures of self-regulation, the Commission would focus on deterrence, crafting remedies that disincentivize lawbreaking rather than encourage it.\"",
            "To some extent, this may seem like a grab bag of policy achievements, but Khan and her colleagues are careful to explain how each of these four \"pillars\" relate to what they see as their overall privacy legacy. As they see it, \"The FTC's consumer protection work these last few years modeled a break from the laissez-faire framework that had largely persisted since the Reagan revolution. By pursuing an approach rooted in fidelity to the FTC's full suite of authorities and the market realities of the digital age, the agency set out a new paradigm for consumer protection.\"",
            "The primary tool toward achieving this shift \u2014 as I wrote about frequently during the Khan FTC \u2014 has been the expanded use of unfairness authority under the FTC Act. With this in mind, a large portion of the meaty analysis in the law review article is focused on the shifting philosophy around the use of unfairness and how it was applied to missteps throughout the data life cycle. The title of the piece, in fact, is \"After Notice and Choice: Reinvigorating 'Unfairness' to Rein In Data Abuses.\"",
            "Beyond these helpful contributions, the law review feature also spends much time contextualizing the Khan FTC's efforts against the backdrop of prior FTC history. It paints a stark picture of the unwillingness of many prior FTC commissioners to take an expansive view of the agency\u2019s authority over privacy practices, especially through the use of unfairness. One quote that was new to me: when in 2001 Commissioner Thomas Leary called concerns around online privacy \"a new hysteria.\"",
            "Overall, Khan believes one of the chief failures of prior FTC privacy philosophies was the \"narrow focus on downstream harms rather than upstream data practices.\" This is best illustrated by the Do Not Call registry and identity theft enforcement efforts, which the authors go so far as to say were a distraction from the potential to shape meaningful data collection and use practices at the outset, by instead focusing on the end harms of an increasingly predatory data ecosystem.",
            "Oddly, the article ignores some of the important precedent-building work for the expanding use of unfairness during the FTC of the 2010s \u2014 such as through the landmark Vizio enforcement \u2014 but it rightly highlights how the Khan FTC began to bring unfairness to its full potential as a tool to curtail harmful data practices when privacy notices alone are not enough for consumers to avoid injury.",
            "Finally and importantly, the article includes a number of reflections on how to build lasting enforcement capacity at the FTC. Of course, this comes at a time when the extent of privacy's future prioritization at the agency is subject to debate.",
            "Khan raises this uncertainty, even as she highlights the potential of the strategy she helped to oversee. As she succinctly puts it, \"The FTC's new strategy remains nascent \u2014 and its institutional durability remains an open question.\"",
            "Please send feedback, updates and legacy reflections to cobun@iapp.org.",
            "Cobun Zweifel-Keegan, CIPP/US, CIPM, is the managing director, Washington, D.C., for the IAPP.",
            "This article originally appeared in The Daily Dashboard and U.S. Privacy Digest,\u00a0free weekly IAPP newsletters. Subscriptions to this and other IAPP newsletters can be found\u00a0here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-iapp-canada-the-growing-need-for-collaboration",
        "title": "Notes from the IAPP Canada: The growing need for collaboration",
        "location": "North America",
        "date_published": "20 June 2025",
        "keywords": ["Children's Privacy", "Enforcement"],
        "description": "This was a big week for my hometown, Ottawa. A number of relevant events took place and it feels like the momentum keeps building, though I\u2019ve been saying that for about 25 years now.",
        "content": [
            "This was a big week for my hometown, Ottawa. A number of relevant events took place and it feels like the momentum keeps building, though I\u2019ve been saying that for about 25 years now.",
            "To kick things off, at the beginning of the week, the Organisation for Economic Co-operation and Development gathered academics, policy leaders, industry folks and government leaders to talk about the future of its work. I was out of town, but I\u2019ve heard the meetings were productive and that we can expect more news from the OECD in the near future.",
            "Quick history refresher: In 1980, the OECD published the model framework for the protection of personal information. That same year, \"Call Me\" by Blondie topped the charts, shoulder pads and acid wash were in \u2014 I'm confused, are they back in? \u2014 and phones were stuck to the wall instead of our hands. The OECD's model framework included eight principles and, at the time, were seen as near perfect. Many countries and jurisdictions, including Canada, used them as the foundation for their data protection laws. Well, it's 2025 and a lot has changed since 1980 \u2014 except acid wash apparently. I'm encouraged to see the OECD is willing to review and re-visit their work to try and keep it as relevant today as their thought leadership was back in 1980.",
            "On Wednesday and Thursday, the Office of the Privacy Commissioner of Canada hosted the data protection authorities as part of the G7 meetings held in Canada. To cap things off, there was a dinner hosted by Centre for Information Policy Leadership where our federal Privacy Commissioner, Philippe Dufresne, and Kate Jones from the U.K. Digital Regulation Cooperation Forum spoke about the future of regulatory enforcement and the growing need for meaningful collaboration.",
            "It was enlightening for me to learn that even in Canada, our provincial and federal offices face some barriers they're interested in breaking down. Some regulators in Canada have more generous budgets and resources than others, so wouldn't it be great if they could find ways to increase knowledge and resource sharing with those offices that, for example, can't have an in-house technology lab to keep on top of AI and cyber developments? \u00a0",
            "I think this issue is relevant way beyond our privacy regulator community and should be a consideration for any regulatory body dealing with industries involved in data \u2014 and who isn\u2019t? So, while some jurisdictions like Canada and the U.K. have started to build bridges and reduce barriers that exist with the competition, consumer protection, telecommunication and copyright regulators, there's still much work to be done. Aside from privacy, and while we're at it, I'd very much like to see the elimination of the trade barriers that prevent us from buying wonderful wines from different parts of the country. C'mon people. It's time to realize that these things are arbitrary, costly and anti-Canadian. Let's share our wealth in privacy and otherwise!",
            "A couple of weeks ago, I wrote about how I think our regulators would benefit from more direct exposure to better understand the motives, pressures and compliance obligations that some of my clients endure. I even volunteered to arrange lunch and learns with, for example, the companies hired to negotiate with organized crime syndicates to return or destroy personal information they've stolen.",
            "I got the sense from some of the proactive remarks at the CIPL dinner that workshops of this nature might be something industry and regulators would be willing to entertain, which I think is good progress. They do not want to be seen as having blinders on, they do want to learn, and they want their findings to carry weight. Let\u2019s see if this idea gathers more steam.",
            "And today, while this newsletter is hitting your inbox, I'll be attending an OPC Symposium organized on the heels of the G7 meetings, but this event is open to the public. We will be discussing the myriad of issues that our children and youth face in this era of exponentially rapidly changing technology that is almost all based on processing personal information.",
            "As someone who was born in the 1970s, I\u2019ve sometimes thought I\u2019m witnessing some of the most dramatic changes in human society in all of history. But I suspect my kids, and their kids, are in for even more. Time, as always, will tell.",
            "Kris Klein, CIPP/C, CIPM, FIP, is the managing director, Canada, for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/key-takeaways-from-ireland-s-dpc-annual-report",
        "title": "Key takeaways from Ireland's DPC annual report",
        "location": "Europe",
        "date_published": "19 June 2025",
        "keywords": ["Enforcement", "Law & Regulation", "AI Governance"],
        "description": "On 19 June, Ireland's Data Protection Commission released its Annual Report for 2024. The report focuses on data protection issues and the DPC's evolving role under the EU Artificial Intelligence act and other digital laws. The DPC is the lead supervisory authority for many of the world's major technology platforms, and this report provides a lens into the evolving nature of EU General Data Protection Regulation enforcement against some of the largest companies on the planet.",
        "content": [
            "On 19 June, Ireland's Data Protection Commission released its Annual Report for 2024. The report focuses on data protection issues and the DPC's evolving role under the EU Artificial Intelligence act and other digital laws. The DPC is the lead supervisory authority for many of the world's major technology platforms, and this report provides a lens into the evolving nature of EU General Data Protection Regulation enforcement against some of the largest companies on the planet.",
            "This year's report reveals significant developments across investigations, litigation, inter-regulatory cooperation and cross border enforcement. The report gives us high-level information on the DPC's decisions, inquiries and litigation matters, and includes summaries of each.",
            "A separate report setting out case studies has also been released, which covers topics that frequently arose in 2024, including access, deletion and rectification requests. It also includes details of the prosecution of a gym, clinic, fast-food company and Google for unsolicited marketing SMS messages and provides case studies of data breaches. The case studies on data processing are particularly useful and outline the importance of carrying out a legitimate interest assessment when relying on legitimate interest, and other fundamental data processing issues.",
            "The DPC concluded 2,357 formal complaints and resolved 8,418 cases through amicable means in 2024.",
            "The DPC concluded four large-scale cross-border inquiries, resulting in administrative fines totaling more than 652 million euros, demonstrating the commission's capability to undertake highly complex multinational investigations.",
            "Among the standout cases include the 310 million euro fine handed down to LinkedIn for violations of GDPR Articles 5(1)(a), 6(1), 13(1)(c) and 14(1)(c), with an accompanying order to bring its processing into compliance.",
            "Meta Platforms Ireland faced three separate decisions: a 91 million euro fine relating to data breach reporting failures per Article 33, an 11 million euro fine for other breach reporting failures, and a substantial 240 million euro fine for infringing Article 25 GDPR concerning privacy by design and default.",
            "The DPC also commenced three significant new inquiries: Google and the training of AI models using personal data, the Irish Health Service regarding the security of sensitive health data and Ryanair on its use of biometric data.",
            "At the end of 2024, the DPC had 89 active statutory inquiries, including 53 cross-border inquiries.",
            "The report found 34% of complaints received by the DPC are related to data access requests \u2014 by far the largest number of complaints. One note for data controllers is that, while redactions or restrictions are for the most part appropriately applied, many complaints stem from insufficient explanations by the data controller as to the reasons why they are being applied. The DPC warns it is not sufficient for an organization to merely itemize the exemptions, restrictions or relevant articles of the legislation. The reason the exemption is being applied should be clearly explained to the individual and documented, such as in a table.",
            "The DPC has long been an advocate for engagement with data controllers and processors and the positive use of data protection by design principles to achieve positive ex ante outcomes for data subjects. Its enforcement strategy goes beyond blunt financial penalties, although it clearly uses fines as a compliance tool when warranted in ex post scenarios. In 2024, the DPC continued this trend and issued eight enforcement notices, the majority of these addressing nonresponsiveness to data subject access requests. They also undertook enforcement under Ireland's 2011 ePrivacy Regulations, with 146 investigations concluded and eight companies prosecuted.",
            "While big fines attract headlines, under Irish law, judicial confirmation is required before they can be enforced. In 2024, the DPC collected 582,500 euros in fines. This seems to be a drop in the ocean compared to the eye-watering figures for the monetary value of the 652 million euro fines levied and is an indication the majority of big fines are appealed and may take years to recover.",
            "Another tool in the DPC's enforcement arsenal is to make an order setting out corrective measures that must be undertaken. The DPC will then monitor to ensure the measures are implemented. This was evident in the TikTok and Instagram decisions, where default privacy settings for children were enforced despite pending appeals.",
            "The DPC's Direct Intervention Unit handles cases that are particularly sensitive and where immediate intervention is necessary to safeguard the data protection rights of a large number of people. The report outlines some of its activities in 2024, including investigations into the processing of health data by organizations for purposes other than that for which it was originally processed, the processing of health data by nursing homes and lack of appropriate safeguards for vulnerable residents. The DPC also investigated organizations that requested excessive data for the provision of services to adults in vulnerable situations.",
            "The litigation section of the report includes an outline of the DPC's power to seek injunctive relief under the Data Protection Act. It was used for the first time in 2024 to prohibit the processing by social media platform X of personal data contained in the public posts of its EU/EEA users for the purpose of training its AI tool, Grok. This arose in the context of engagement with X during the development of the tool, when X shared a DPIA and legitimate interest assessment with the DPC.",
            "In July 2024, the DPC became aware that mitigations that had been identified had not been completed prior to the processing of X user data for training Grok. The DPC asked X to cease processing, but it refused to do so. Given the real risk to the rights freedoms of data subjects, the DPC formed the view that there was an urgent need to act immediately and made an emergency injunctive application to the court. Ultimately, X undertook to cease processing any EU/EEA X user data in scope and deleted the data set.",
            "In 2024, the DPC received 7,781 valid data breach notifications. This is an 11% increase on the data breach numbers in 2023. Approximately 50% of these notifications stem from correspondence being sent to the wrong recipient. Of the breach notifications received in 2024, 81% were concluded by end of year.",
            "The DPC has strategically enhanced its inter-regulatory function, in recognition of the convergence of data protection with broader digital regulation. In 2024, a deputy commissioner was appointed to lead on inter-agency collaboration, in light of the implementation of the EU Digital Services Act, the EU AI Act and the Political Advertising Regulation.",
            "The DPC remains a cornerstone of the GDPR's one-stop shop mechanism. In 2024, it concluded 145 cross-border complaints and submitted 115 notifications through the Article 60 GDPR mechanism.",
            "Since GDPR took effect in May 2018, the DPC has received 1,853 cross-border complaints, acting as lead supervisory authority for 87% or 1,612 of them. Notably, 63% of such complaints were first submitted to another supervisory authority before being transferred to the DPC under the one-stop shop mechanism \u2014 highlighting Ireland's centrality in EU data protection regime due to the establishment of many global tech firms here.",
            "The DPC continued its engagement and cooperation with other European Data Protection Board supervisory authorities in 2024. It handled 1,175 requests for mutual assistance, indicating deepening collaboration across Europe\u2019s data protection ecosystem. In recognition of the importance of this activity, the DPC created a head of EDPB/ International Affairs post at deputy commissioner level in October 2024 and has decided to continue with its Brussels attach\u00e9 position. This illustrates the importance of the DPC's role as lead supervisory authority for many large tech companies based in Ireland and demonstrates the need to work collaboratively across all cross-border matters.",
            "As well as the Grok case mentioned above, in 2024, the DPC requested Meta to pause the training of AI using EU/EEA personal data. There was an intensive period of engagement with Meta during 2024 which was still ongoing at the end of the year.",
            "The issue of training AI models on personal data is an issue that is common across all EU jurisdictions. In the absence of an established consensus, the DPC referred a set of questions to the EDPB, under the statutory scheme set out under GDPR Article 64(2) in September 2024.",
            "The request and contributions to the development of the opinion involved a cross-functional effort within the DPC and all supervisory authorities. The entire process, including a public consultation with industry and stakeholders was project managed by the EDPB secretariat. A formal opinion was adopted by the EDPB in late December 2024.",
            "Ireland's Data Protection Act requires government departments to consult the DPC on legislative or regulatory measures that will involve data processing. This is of particular importance when legislation is creating a new legal basis for the processing of personal data by public bodies or agencies. The DPC provided input on 56 legislative proposals in 2024. It has also engaged with stakeholders on issues such as body worn cameras, drone technology, facial recognition technology and CCTV, processing of children\u2019s data by sports organizations and webinars for the nonprofit sector.",
            "It was also involved in consultations in the education, retail, and health sectors and conducted a compliance sweep of the supermarket and convenience store sectors. It launched guidance including a data protection toolkit for schools and updated CCTV guidance to address surveillance in sensitive environments.",
            "The report outlines the DPC's activities in support data protection officers throughout the year, including engagement with DPO networks in the health research sector, public sector and pharmaceutical and medical device sector and notes that its team participated in various conferences.",
            "The DPC's 2024 budget was 28.126 million euros. This is an increase of 2.047 million euros on the 2023 budget. It onboarded 70 new staff members in 2024 bringing total staff numbers to 251 at the end of the year and it prepared to move into its new offices on Pembroke Street, Dublin.",
            "The 2024 DPC Annual Report demonstrates a mature regulator using engagement and support to improve outcomes for data subjects, while also using its enforcement powers as necessary. Its investigations yielded headline fines, but perhaps its strategic inter-regulatory engagement and collaboration signals future direction.",
            "With staffing increasing to 251 in 2024 and further expansion envisaged, ongoing governmental support is essential to maintain Ireland's role as Europe's leading data protection regulator.Kate Colleary, CIPP/E, CIPM, FIP, is IAPP country leader, Ireland, and director of Pembroke Privacy."
        ]
    },
    {
        "url": "https://iapp.org/news/a/ny-sends-ai-frontier-model-bill-to-the-governor-s-desk",
        "title": "NY sends AI frontier model bill to the governor's desk",
        "location": "North America",
        "date_published": "18 June 2025",
        "keywords": [
            "Technology",
            "AI Governance",
            "Audit & Assurance",
            "Law & Regulation",
            "Risk Management"
        ],
        "description": "As U.S. Congress weighs blocking state-level artificial intelligence law enactment and enforcement, New York is moving forward with potential landmark legislation to regulate frontier AI models.",
        "content": [
            "As U.S. Congress weighs blocking state-level artificial intelligence law enactment and enforcement, New York is moving forward with potential landmark legislation to regulate frontier AI models.",
            "The Responsible AI Safety and Education (RAISE) Act passed through the New York Senate 12 June on a near-unanimous vote, sending it to the governor's desk. The bill targets large companies developing AI models over specified computational cost and operations thresholds that carry the capacity to cause harm.",
            "Covered entities would be required to adopt safety and security protocols before a model is released and make the measures available to relevant authorities. The bill also compels developers to conduct annual safety reviews and disclose safety incidents.",
            "The office of Gov. Kathy Hochul, D-N.Y., told the IAPP she will review the legislation. Under New York state law, the governor has 10 days not including Sundays to sign, veto or allow to become law without her signature \u2014 after she requests a bill come to her desk, which can take some time.",
            "State Assemblymember Alex Bores, D-N.Y., sponsored the bill in the Assembly. He told the IAPP he views the bill as being aligned with New York's other AI efforts, including the Empire AI Consortium research efforts enacted in this year's budget. However, he had not heard from Hochul on whether she would sign the RAISE Act into law.",
            "According to Bores, the bill largely seeks to replicate many of the voluntary commitments several Big Tech companies made during former U.S. President Joe Biden's administration and during the AI Seoul Summit in 2024, such as the safety plans and red teaming of models. Several AI companies publish their safety plans online.",
            "\"Even though they made these commitments in the past, we saw behavior that didn't add up to those commitments,\" Bores said. \"We're holding them to even less than what they promised but establishing some baselines.\"",
            "The bill puts the onus on developers to anticipate whether their models could cause critical harm, defined here as the death or serious injury of 100 or more people or at least USD1 billion in damages; creating of chemical, biological or nuclear weapons; acts without meaningful human intervention or could help a person commit a foreseeable crime.",
            "Violating the law would allow the state's attorney general to seek a civil penalty of up to USD10 million for the first offense and up to USD30 million for subsequent infractions. The law is not intended to establish a private right of action, and it does not limit the application of other relevant laws.",
            "The RAISE Act would prevent a repeat of how social media's harms was handled by policymakers, where no significant legislation has been passed, said Adam Billen, vice president of public policy at Encode AI and a proponent of the bill.",
            "\"Today, by passing the RAISE Act, the legislature has shown that it is committed to proactively safeguarding New Yorkers from AI harms, rather than waiting until they\u2019re already here,\" he said in a statement to the IAPP.",
            "But industry advocates, including the AI Alliance Association, said it is impossible for developers to foresee every harm their products could be used for, something it argues will curb open-source development. Rather than create safer products, the group indicated advanced AI models will likely not be offered in New York instead.",
            "\"To the contrary, the NY RAISE Act would create a reporting and compliance bureaucracy that would distract from existing risk identification and mitigation efforts. The 'safety and security protocol,' defined in the Act as a reporting mechanism for transparency, introduces layers of busy work \u2014 without clear standards for satisfactory procedures and mitigations,\" the association, which includes IBM, Meta and Oracle among its members, said in a letter to New York legislative leaders.",
            "Caitlin Andrews is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/rwanda-charts-a-new-course-for-government-data-sharing",
        "title": "Rwanda charts a new course for government data sharing",
        "location": "Africa",
        "date_published": "18 June 2025",
        "keywords": ["Government", "Law & Regulation", "Enforcement"],
        "description": "In an increasingly data-driven world, governments are grappling with how to harness the power of information for the public good while safeguarding individual rights. Rwanda recently approved aNational Data Sharing Policy, taking a step forward in the privacy domain. ",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. \r",
            "In an increasingly data-driven world, governments are grappling with how to harness the power of information for the public good while safeguarding individual rights. Rwanda recently approved aNational Data Sharing Policy, taking a step forward in the privacy domain. ",
            "This policy crucially arrives as countries increasingly recognize data as a strategic national asset. It is a logical and vital progression for Rwanda, a country lauded for its ambitious digital transformation agenda. The National Data Sharing Policy between Government Agencies directly supports the country's overarching development blueprints, including the Second National Strategy for Transformation \u2014 particularly its goal of strengthening the capacity and service delivery of public institutions \u2014 and the long-term Vision 2050, a national development plan that aims to create \"accountable and capable state institutions\" and an improved economy.",
            "The policy aims to dismantle data silos, foster a culture of collaboration among government agencies and,ultimately, improve the delivery of citizen-centric services \u2014 all critical for achieving national aspirations.",
            "Supported by seven annexes that outline its operational aspects, from governance structures to technology platforms, the policy aims to transform how government entities share and use data and position Rwanda among African countries actively formalizing such comprehensive approaches.",
            "Kenya, for instance, also has a Data Sharing Code. Nigeria, Senegal and South Africa have also developed national data strategies or policies which often include ambitions for enhanced inter-governmental data sharing to improve public services and governance.",
            "These implementations collectively signify a growing momentum across Africa to formalize and improve intergovernmental data sharing for national advancement.",
            "The National Data Sharing Policy is designed to create a protected and well-governed environment for data exchange among government agencies. Its primary goal is to enhance decision-making, facilitate interagency collaboration and provide a robust foundation for fulfilling national policy objectives and advancing digital transformation for Rwandans' benefit.",
            "The policy aims to responsibly enable data sharing. It operates in concert with existing legal frameworks, most notably Rwanda's Data Protection and Privacy Law and the Access to Information Law. Together, this legislation ensures that while data flows more freely to generate insights, data protection and freedom of information principles remain paramount.",
            "Although they are related, it is important to distinguish this initiative from open data policies. While open data initiatives typically focus on making government data publicly available, Rwanda's Data Sharing Policy specifically governs the exchange of data, including potentially sensitive information, among government agencies or departments.",
            "However, the underlying objectives of transparency and accountability resonate with broader movements, such as the Open Government Partnership, by aiming to make government operations more efficient and responsive through better data use. The policy document itself acknowledges that all government data, whether internal or public, is subject to the same stringent governance and compliance requirements.",
            "The policy is built upon four guiding principles: regulatory compliance; protection, governance and oversight; secure, modern technological enablement; and adherence to data standards and quality. These principles are operationalized through several key components and institutional arrangements.",
            "Backed by a dedicated budget, the policy outlines a phased implementation plan extending from 2025 to 2029. Key milestones in 2025 include the crucial establishment of the data governance unit and its technical subcommittee, the definition of data standards essential for interoperability and the formal commencement of the data sharing platform project.",
            "Over subsequent years, the focus will be on the DSP's iterative development and enhancement, including an online portal for entity registration and data discovery, the rollout of robust monitoring and reporting mechanisms, and providing continuous technical assistance and education to participating government entities. A fundamental requirement throughout this period is for all government bodies to institute strong internal data governance, robust cybersecurity measures, and comprehensive privacy programs compliant with the DPPL.",
            "The Ministry of Information Communications Technology and Innovation will provide overarching policy guidance and oversight. The Data Governance Unit will be responsible for supervising data sharing activities, including approval of data sharing requests and ensuring compliance with agreed-upon protocols.",
            "While direct enforcement penalties are not heavily detailed in the policy, the Data Governance Unit's oversight, mandatory use of the DSP for all inter-governmental data sharing, and adherence to formal data sharing agreements will serve as primary mechanisms for ensuring compliance.",
            "The policy formalizes data sharing processes through mechanisms, such as data sharing application forms and legally binding data sharing agreements between participating institutions. This structured approach ensures clarity on the purpose, scope and conditions of data sharing. Furthermore, the policy champions the adoption of risk management frameworks, like the \"Five Safes\" framework, an internationally recognized model for managing disclosure risk.",
            "The successful implementation of Rwanda's National Data Sharing Policy promises far-reaching impacts. Enhanced evidence-based policymaking is a primary anticipated benefit that will allow the government to design more effective programs and respond adeptly to national challenges.",
            "Improved efficiency in public service delivery, reduced duplication of efforts and cost reduction are also expected as data becomes more accessible and interoperable across agencies. This directly contributes to the NST2's goal of transforming Rwanda into a knowledge-based economy.",
            "For citizens, this translates into more responsive and tailored services that align with Vision 2050's emphasis on improving quality of life. For instance, by combining anonymized health data with education statistics, Rwanda's government could identify areas needing targeted interventions. By overlaying transportation data with demographic information, urban planning could be significantly optimized. Similarly, the ability for different public health facilities to securely share anonymized data on infectious disease occurrences could significantly enhance national disease surveillance systems, allowing for quicker identification of potential epidemics and more coordinated responses to protect public health.",
            "With the policy serving as a driverfor innovation, new insights and solutions to complex development challenges can emerge. The National Data Sharing Policy aligns with Rwanda's ambition to be an innovation hub in Africa by facilitating government collaboration on data projects.",
            "Moreover, by proactively establishing clear guidelines for data sharing within the bounds of data protection law, the policy aims to build trust between government agencies and the public.",
            "While the journey will involve overcoming challenges such as ensuring consistent implementation across all government entities, building requisite technical capacity and fostering a sustained culture of data stewardship, the policy's phased implementation plan over the next four years and dedicated budget indicate a strong governmental commitment in Rwanda.",
            "Ridwan Oloyede, CIPP/E, CIPM, FIP, is the AI governance and technology policy lead at Tech Hive Advisory Africa and the director at the Center for Law and Innovation."
        ]
    },
    {
        "url": "https://iapp.org/news/a/eu-reaches-provisional-agreement-to-speed-up-cross-border-gdpr-enforcement",
        "title": "EU reaches provisional agreement to speed up cross-border GDPR enforcement",
        "location": "Europe",
        "date_published": "17 June 2025",
        "keywords": ["Data Subject Rights", "Enforcement", "Law & Regulation"],
        "description": "The European Parliament and the Polish Presidency of the Council of the European Union reached a provisional agreement 16 June on a long-awaited regulation aimed at improving cooperation between national-level data protection authorities when enforcing cross-border cases under the General Data Protection Regulation. The agreement also includes clarification of relevant procedures and rights as well as \"fleshing out of earlier provisions\" related to cooperation and dispute resolution procedures.",
        "content": [
            "The European Parliament and the Polish Presidency of the Council of the European Union reached a provisional agreement 16 June on a long-awaited regulation aimed at improving cooperation between national-level data protection authorities when enforcing cross-border cases under the General Data Protection Regulation. The agreement also includes clarification of relevant procedures and rights as well as \"fleshing out of earlier provisions\" related to cooperation and dispute resolution procedures.",
            "In emailed comments to the IAPP, Mark\u00e9ta Gregorov\u00e1,\u00a0Pirate Member of the European Parliament and rapporteur in Committee on Civil Liberties, Justice and Home Affairs, said, \"I'm proud that we've successfully negotiated a long-overdue GDPR enforcement procedures regulation that finally ends the years-long limbo citizens have faced in cross-border cases.\"",
            "She added, \"For the first time, we're setting clear, enforceable deadlines, alongside strong rights for both complainants and companies, including access to case files and the right to be heard. This will make the system faster, fairer, and more transparent.\"",
            "Poland's Deputy Prime Minister and Minister for Digital Affairs Krzysztof Gawkowski said, \"We have taken a big step towards improving cooperation between national data protection bodies when they enforce citizens' rights under the GDPR. This objective is to speed up the process of handling cross-border GDPR complaints filed by citizens or organizations.\"",
            "The provisional agreement still requires confirmation by the Council and Parliament, and the new rules will enter into force after final adoption. Notably, the law would create deadlines for procedures in order to speed up the investigatory and enforcement process.",
            "\"Once a lead supervisory authority has been established,\" a European Parliament press release states, \"it must finish the investigation and submit a draft decision within 15 months, unless the complexity of the case requires and extension of a maximum 12 months.\"",
            "Regarding the deadlines, Gregorov\u00e1 said, \"I personally pushed through a key change: data protection authorities will now have to close straightforward cases within 12 months, and even the most complex ones within 15 months, with the possibility of limited extensions when strictly necessary.\"",
            "At the time of publication of this article, the official text of the agreement was not yet released and likely will not be until after a final agreement is reached between the co-legislators.",
            "However, in a related analysis piece for the IAPP, representatives from Hogan Lovells offer a more in-depth look at the GDPR's cooperation and consistency framework, the procedural history and key elements of the provisional agreement and various considerations for businesses. They point out that the provisional agreement \"appears to incorporate elements\" from the European Commission, Parliament and Council, but some controversial elements remain, including the shorter deadlines for lead supervisory authorities.",
            "Privacy rights group NOYB's Max Schrems has been critical of the proposed regulation. In a post dated 20 May, NOYB said the rules would introduce \"excessively long deadlines and overly complex procedures.\" NOYB said it is reviewing options for potentially bringing an annulment procedure \"if the regulation passes in its current form.\" Schrems added, \"The regulation is so structurally flawed, that the Court of Justice of the EU may have to annul it.\"",
            "Wilson Sonsini Partner Yann Padova offered some background on the procedural history of the regulation, noting that the proposal \"took into account several requests from the European Data Protection Board,\" which were originally published in October 2022. Parliament's LIBE committee published its draft report in November 2023 and proposed \"substantial changes\" to the original text. He said the trilogue process \"took place based on substantial divergent views from the Parliament and Council.\"",
            "In its analysis for the IAPP, the Hogan Lovells team points out that there has been \"broad support for harmonizing cross-border enforcement procedures,\" though the devil is always in the details and \"its full impact will depend on how it is implemented in practice.\" They add that cross-border enforcement has \"sometimes been marked by delays\" but warn it \"is possible that streamlining procedures will lead to more enforcement of cross-border processing activities.\"",
            "For Gregorov\u00e1, the rapporteur for the regulation in the LIBE committee, the new rules \"will make the system faster, fairer and more transparent. Our deal also ensures that people receive the same strong protections no matter where in Europe their case is handled. Big Tech will no longer be able to hide behind procedural delays, and citizens, NGOs, and businesses alike will finally benefit from greater legal certainty.\"",
            "She added, \"This is a major win for digital rights.\"",
            "Jedidiah Bracy is the editorial director for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/23andme-fined-2-31m-gbp-after-uk-canada-data-security-probe",
        "title": "23andMe fined 2.31M GBP after UK, Canada data security probe",
        "location": "North America",
        "date_published": "17 June 2025",
        "keywords": [
            "Biometrics",
            "Data Security",
            "Enforcement",
            "Personal Privacy",
            "Data Protection Obligations"
        ],
        "description": "Global scrutiny of data protection and security standards at genetic testing company 23andMe is growing following results of a joint probe by the Office of the Privacy Commissioner of Canada and the U.K. Information Commissioner's Office. The company faces a 2.31 million GBP fine from the ICO for insufficient data security measures that led to a 2023 data breach impacting 6.9 million customers globally, including those in Canada and the U.K.",
        "content": [
            "Global scrutiny of data protection and security standards at genetic testing company 23andMe is growing following results of a joint probe by the Office of the Privacy Commissioner of Canada and the U.K. Information Commissioner's Office. The company faces a 2.31 million GBP fine from the ICO for insufficient data security measures that led to a 2023 data breach impacting 6.9 million customers globally, including those in Canada and the U.K.",
            "Specific to its data security claims, the OPC and the ICO alleged 23andMe \"did not have effective systems in place to monitor, detect, or respond to cyber threats targeting its customers\u2019 sensitive information.\" Additionally, the enforcers claimed the company had \"inadequate\" incident response, noting it \"failed to properly investigate signals that a breach may be occurring, including a credible claim that customer data had been stolen.\"",
            "\"People affected by this breach told us that they felt anxious about what it could mean to their personal, financial and family safety,\" U.K. Information Commissioner John Edwards said during a joint press conference with Privacy Commissioner of Canada Philippe Dufresne. \"As one of those impacted told us, unlike usernames, passwords and email addresses, you can't change your genetic makeup when a data breach occurs.\"",
            "The ICO indicated the data breach potentially involved \"names, birth years, self-reported city or postcode-level location, profile images, race, ethnicity, family trees and health reports.\" Approximately 320,000 Canadians and 155,592 U.K. residents were involved in the breach, according to the regulators.",
            "Dufresne said the impacts of the breach extended beyond the initial access. The investigation, which the OPC initiated in 2024, found hackers took stolen data and put it for sale online, risking further exploitation.",
            "\"Strong data protection must be a priority for organizations, especially those that are holding sensitive data,\" Dufresne said. \"Organizations must take proactive steps against cyberattacks. This includes using multi-factor authentication, strong minimum password requirements, compromised password checks and adequate monitoring to detect abnormal activity with data breaches growing in severity and complexity.\"",
            "According to Dufresne, the investigation is another example of the OPC \"leveraging international collaboration\" as a tool to combat its lighter regulatory powers. He said his office seeks to \"maximize\" its impact while unable to issue fines or direct binding obligations \u2014 it can petition for court-ordered remedies \u2014 under the Personal Information Protection and Electronic Documents Act.",
            "The enforcement work comes as 23andMe is wrapped up in U.S. bankruptcy proceedings, leaving many questions around the future security of the company's vast biometric database. Since the bankruptcy announcement, customers were given a data deletion option and 23andMe committed to ensuring a final sale partner would adopt the company's existing privacy notice and practices.",
            "Nonprofit TTAM Research Institute, led by former 23andMe co-founder and CEO Anne Wojcicki, has a USD305 million offer out to purchase the genetic testing company. Wojcicki was in her role at 23andMe during the 2023 breach, but the OPC and ICO are confident company commitments stemming from enforcement will hold through the sale.",
            "\"We've indicated in our report that we will be following this carefully,\" Dufresne said. \"The obligations should continue to apply to any new owner, and if there are any concerns, our citizens can reach out to us and we will take appropriate steps.\"",
            "In addition to investigation reports, the two regulators clarified legal requirements for the handling of personal information in their jurisdictions in filings to the trustee overseeing bankruptcy proceedings. The OPC added it will \"provide the purchaser of 23andMe's data holdings with the report of findings from their joint investigation to ensure that they are aware of their legal privacy obligations.\"",
            "Joe Duball is the news editor for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/eu-lawmakers-announce-deal-on-cross-border-gdpr-enforcement-procedures",
        "title": "EU lawmakers announce deal on cross-border GDPR enforcement procedures",
        "location": "Europe",
        "date_published": "17 June 2025",
        "keywords": ["Law & Regulation", "Enforcement"],
        "description": "On 16 June, the Council of the European Union and European Parliament announced a provisional agreement on the long-awaited General Data Protection Regulation Procedural Regulation \u2014 a key legislation aimed at harmonizing cooperation between EU member state data protection authorities in cross-border enforcement cases.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. \r",
            "On 16 June, the Council of the European Union and European Parliament announced a provisional agreement on the long-awaited General Data Protection Regulation Procedural Regulation \u2014 a key legislation aimed at harmonizing cooperation between EU member state data protection authorities in cross-border enforcement cases.",
            "The agreement marks a near-final step in the EU's legislative effort to formalize consistent procedural rules for the operation of the GDPR's cooperation and consistency framework.",
            "The procedural regulation supplements the GDPR by harmonizing procedural rules that apply when an investigation by a data protection authority involves processing activities affecting individuals in more than one EU member state \u2014 for example, cross-border processing.",
            "The GDPR's one-stop-shop mechanism, under Article 56, is designed to streamline supervision of cross-border data processing. When a controller or processor operates in multiple EU member states, or when its processing activities substantially affect individuals in more than one EU member state, a single lead supervisory authority \u2014 typically located where the controller or processor has its main establishment \u2014 is designated to lead the investigation.",
            "The LSA coordinates with other concerned supervisory authorities under Article 60, sharing information, consulting on draft decisions and resolving disagreements. If consensus cannot be reached, the matter may be referred to the European Data Protection Board under the consistency mechanism set out in Articles 63 to 65. The EDPB may issue binding decisions to ensure uniform application of the GDPR across the EU.",
            "While the framework is intended to reduce administrative burdens and promote consistent enforcement, the European Commission has noted that inconsistent application by DPAs, fragmented national procedures and limited resourcing have hindered its effectiveness in cross-border cases.",
            "The legislative process began in July 2023 with the Commission's proposal, which entered the EU's ordinary legislative procedure requiring agreement between Parliament and the Council. Parliament adopted its position in April 2024, followed by the Council's general approach in June 2024.",
            "Interinstitutional negotiations \u2014 the so-called \"trilogues\" \u2014 between the Parliament, Council and Commission commenced thereafter and concluded 16 June with a provisional political agreement reached under the Polish Presidency of the Council.",
            "The final text of the procedural regulation will be published following formal adoption by the Parliament and Council. However, based on their official announcements, the provisional agreement includes the following core elements:",
            "The provisional agreement appears to incorporate elements from the Commission, Parliament and Council drafts. However, several provisions remain controversial and their final form will likely influence how the procedural regulation is received. For example, the Parliament had proposed significantly shorter deadlines for LSAs to complete investigations and submit draft decisions.",
            "Some areas of divergence between the co-legislators were not addressed in the public descriptions of the provisional agreement, leaving uncertainty as to how they were resolved. These include: the allocation of decision-making authority between LSAs and CSAs, the potential expansion of the EDPB's role in dispute resolution under Article 65, and procedural deadlines at the early stages of enforcement \u2014 for example, acknowledging complaints, determining admissibility and assigning the LSA.",
            "While there is broad support for harmonizing cross-border enforcement procedures, views differ on how best to achieve this. Advocacy group NOYB, led by Max Schrems, has previously indicated it may challenge the procedural regulation through annulment procedures before EU courts, citing concerns over extended procedural deadlines that could weaken enforcement compared to some national standards.",
            "The procedural regulation is expected to streamline cross-border enforcement, but its full impact will depend on how it is implemented in practice. Until now, cross-border enforcement has sometimes been marked by delays and procedural inconsistencies. It is possible that streamlining procedures will lead to more enforcement of cross-border processing activities.",
            "Companies operating across multiple EU member states should assess how the revised cooperation and consistency framework may affect their enforcement risk. This includes:",
            "Joke Bodewits is partner, Julian Flamant, CIPP/E, is senior associate, Henrik Hanssen is counsel, and Julie Schwartz is counsel at Hogan Lovells."
        ]
    },
    {
        "url": "https://iapp.org/news/a/us-officials-question-23andme-s-ability-to-navigate-data-protection-during-bankruptcy",
        "title": "US officials question 23andMe's ability to navigate data protection during bankruptcy",
        "location": "North America",
        "date_published": "16 June 2025",
        "keywords": [
            "Health Care",
            "Technology",
            "Biometrics",
            "Customer Trust & Expectations",
            "Data Ethics",
            "Data Security",
            "Law & Regulation"
        ],
        "description": "Genetic testing company 23andMe's bankruptcy has unsettled users and officials, raising crucial concerns about what will happen to the sensitive biometric data collected by the company.",
        "content": [
            "Genetic testing company 23andMe's bankruptcy has unsettled users and officials, raising crucial concerns about what will happen to the sensitive biometric data collected by the company.",
            "23andMe filed for bankruptcy in March, following declining sales in its genetic testing kits and a large-scale data breach in 2023 that compromised the personal data of 6.9 million users. The company gave users the option to delete their data and claimed it would ensure any company that acquired 23andMe would adopt its privacy policy.",
            "Despite recently announcing biotech company Regeneron would purchase 23andMe, the company pulled back its bid after 23andMe co-founder and former CEO Anne Wojcicki\u2019s nonprofit TTAM Research Institute offered USD305 million.",
            "TTAM Research Institute is expected to acquire 23andMe and continue offering consumers insights into their health information and genetic makeup. Wojcicki said in a statement her nonprofit believes it is \"critical that individuals are empowered to have choice and transparency with respect to their genetic data and have the opportunity to continue to learn about their ancestry and health risks as they wish.\"",
            "The case has raised broader national security and data protection concerns as government officials question the potential misuse of genetic data if sold to foreign entities or provided to companies with inadequate safeguards.",
            "At a U.S. House Committee on Oversight and Government Reform hearing discussing 23andMe's bankruptcy, College of William and Mary Law School Professor Margaret Hu said U.S. legislation, including the Health Insurance Portability Accountably Act, should be updated to meet technology advancement with an \"overlapping regime that takes into account strong federal data privacy protections.\"",
            "The potential transfer of users' genetic profiles has drawn scrutiny from regulators who question if 23andMe can securely transfer sensitive data to a new organization with users' consent. While 23andMe allows consumers to delete their data, regulators, including a bipartisan coalition of 28 attorneys general, argued the company should not be able to sell users' biometric data during the acquisition.",
            "The consumer privacy ombudsman assigned to monitor the bankruptcy's privacy implications, Washington University of St. Louis School of Law Koch Distinguished Professor Neil Richards said in a report that 23andMe should receive affirmative consent from consumers before transferring the data.",
            "Richards' report also states consumers \"allegedly had difficulties accessing their accounts, deleting their genetic data, and requesting the destruction of their biological samples,\" despite the company's data deletion policies.",
            "23andMe Interim CEO and Chief Financial and Accounting Officer Joe Selsavage pushed back against claims the company had not obtained proper consent during a U.S. Senate Committee on the Judiciary hearing. Selsavage noted the company \"believes we have already obtained the consent from our customers, and when the customer signed up to the service, they have agreed affirmatively to consent to our privacy and terms of service, which specifically says that we, in the event of a bankruptcy sale, can actually transfer their data.\"",
            "According to Selsavage, 1.9 million users have deleted their data from the platform.",
            "Although 23andMe says consumers own their data, Cole Schotz P.C. Partner Luis Salazar said, if the terms are included in the organization\u2019s privacy policies, \"companies still have the legal right to use it and to even sell it under the right conditions. That doesn't deny that they, the consumers, may still have some kind of ownership interest or right to it.\"",
            "Genetic data is particularly vulnerable due to its sensitive and identifiable nature. This data is also essential for direct-to-consumer DNA testing companies when selling their assets.",
            "Salazar noted providing consumers with the ability to opt in to sharing their data would significantly lower the value of the company during bankruptcy proceedings. \"The data is critical to the value and everyone else involved, from employees to lenders, investors and even consumers,\" Salazar said. \"It's the fundamental basis of what you are basically saying is everyone's expectation, 'let's just erase that, and have people opt in.' That is going to diminish the value of the fundamental asset of this company, to the detriment of a lot of people.\"",
            "Growing tensions between the U.S. and foreign adversaries have highlighted concerns over cyber threats' impact on national security. U.S. Rep. John McGuire, R-Va., claimed \"foreign actors should not be allowed to gain access to millions of American sensitive data which can then be weaponized against them through surveillance or even the creation of a bio weapon.\"",
            "In 2015, 23andMe received a USD115 million investment from WuXi Healthcare Ventures, a company affiliated with the Chinese Communist Party and the Chinese People's Liberation Army. Selsavage assured he was \"very confident\" 23andMe would not be sold to a company with ties to China or Russia.",
            "University of Texas at Austin Robert S. Strauss Center for International Security and Law Director and Senior Lecturer Adam Klein claimed, if genetic information is provided to China, the data could be used as a means of \"tracking and identifying people,\" including government agents and active-duty military personnel.",
            "Klein noted as the U.S. and China race to lead AI innovation, large datasets with a \"genetically diverse population\" could be used to train AI models.",
            "Despite concerns about foreign interference, neither TTAM Research Institute nor Regeneron have connections with international governments.",
            "\"I think people all around the United States are now concerned with what happens to their very sensitive personal information,\" U.S. Sen. Ashley Moody, R-Fla., said. \"I think this is going to affect everything from data privacy to national security to potential biotech threats. We cannot overstate the threat to this nation and to people individually.\"",
            "23andMe's bankruptcy is currently pending following lawsuits filed by state attorneys general and ongoing privacy concerns. If the sale is allowed to proceed, TTAM Research Institute will acquire the company along with its database.",
            "Lexie White is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/a-view-from-dc-pride-coded-language-and-the-tragic-irony-of-a-private-life",
        "title": "A view from DC: Pride, coded language and the tragic irony of a private life",
        "location": "",
        "date_published": "13 June 2025",
        "keywords": ["Community & Careers", "Personal Privacy"],
        "description": "The history of queer identity is full of coded language and expression.",
        "content": [
            "The history of queer identity is full of coded language and expression.",
            "Navigating social norms, censorship and the threat of persecution, LGBTQ+ individuals have long found secret ways to communicate with one another. Like other marginalized groups, they adapted language and symbols to foster new modes of shared understanding, allowing for the discussion of sensitive topics related to identity, sexuality and lived experience while avoiding confrontation with the wider world.",
            "History is replete with examples.",
            "Oscar Wilde is said to have encouraged his friends to wear green carnations on the opening night of his play, Lady Windermere's Fan. Asked what the symbol meant, he is said to have replied, \"Nothing whatever, but that is just what nobody will guess.\" The unnatural colored flower may have been the author's subtle nod to a lifestyle seen as unnatural in the sensibilities of the time.",
            "From green carnations to the infamous \"gay earing\" to the elaborate \"hanky code\" that originated in 1970s gay leather culture, subtle signaling of shared subcultural identity has long been a part of the queer experience.",
            "Coded expressions, by their nature, are also a means of preserving privacy. Beyond mere signaling, queer culture has established entire linguistic codes in times of great persecution. Adopting an argot fosters solidarity and in-group identity while also serving as a means of collective resistance to countervailing societal pressures.",
            "Beginning in late 19th century London, a slang language called Polari emerged among performers and other iconoclastic circles that together made up what passed for the underground gay subculture of the time. Polari is a prime example of what linguists call an argot, \"cryptolect\" or \"cant\" \u2014 by any name a type of linguistic system that evolves explicitly to prevent outsiders from understanding. The jargon included a bizarre mixture of Cockney rhyming slang, Anglo-Romany and \"thieves' cant,\" which together made shared understanding nearly impossible except by those in the know. Supposedly, this cryptolect is the origin of quite a few English words including naff, butch and even the recently re-popularized zhoosh.",
            "Coded communication systems \u2014 from the simple to the sophisticated \u2014 have served as a vital survival mechanism in social environments that could be profoundly hostile to the queer experience. In a sense, they have functioned as a means of audience selection long before the days of the Instagram \"close friends\" story.",
            "The intense need for secrecy in explorations of queer identity has also sparked the creation of personalized cryptographies.",
            "Anne Lister, a notable early 19th century British landowner and diarist, meticulously recorded the intimate details of her daily life, including her romantic experiences with other women, in diaries using a complex personal code she termed \"crypt hand.\" Though she experienced an intense need to record and analyze what she thought of as the \"oddity\" of what today we would call her sexuality, her writings were never meant to be understood by anyone but herself and her most trusted lovers, with whom she may have shared the key to deciphering her writing.",
            "Crypt hand was a privacy preserving technology of the highest order, a private sanctuary for self-expression and identity affirmation when broader articulation was dangerous.",
            "Luckily, Lister made use of a simple substitution cipher that was easily decoded in later years. Her journals now represent a treasure trove of first-person accounting of a deeply personal queer experience, which has sparked academic analysis across a variety of fields.",
            "Lister's story highlights the importance of total privacy to the exploration of identity, the need for self-rhetoric as a means of exploring and reaffirming our individual journey. Perhaps there is nothing gayer than a privacy enhancing technology.",
            "But the existence of this story also highlights the tragic irony of those who must embrace lives of secrecy to avoid cultural taboos and preserve their own safety. The rich and ever-evolving cultural tapestry of LGBTQ+ life \u2014 whether expressed in the Victorian court, the timeless traveling circus, the underbelly of the dockyards or the bars and cafes of 20th-century cities \u2014 is largely lost to history. For every story that can be sung there are thousands more that never will be.",
            "In this way, a person's individual embrace of data hygiene, to \"data minimization\" of a kind, serves to preserve privacy, safety and autonomy while also dooming their story to obscurity. For queer folks, the tension between the desire to chronicle and preserve the richness of life and the need to live it unobserved and unmolested has frequently been overwhelming. This tension is reflected across hundreds of years of coded art and literature, from Shakespeare's \"fair youth\" to Gertrude Stein's \"husband.\" Art finds a way to reflect, even if it can't fully record.",
            "The unsung stories of queer life can be thought of as a testament to the successful protection of personal privacy. They also highlight inequities that persist today. Though the details may be lost to history, we hold on to the shadows of those who came before in the form of coded stories, new and old slang and the types of cultural traditions we honor each year during Pride.",
            "Please send feedback, updates and epistolary musings to cobun@iapp.org.",
            "Cobun Zweifel-Keegan, CIPP/US, CIPM, is the managing director, Washington, D.C., for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/ontario-s-ipc-works-toward-balancing-youth-safeguards-empowerment",
        "title": "Ontario's IPC works toward balancing youth safeguards, empowerment",
        "location": "North America",
        "date_published": "13 June 2025",
        "keywords": [
            "Education",
            "Children's Privacy",
            "Data Protection Obligations",
            "Data Subject Rights",
            "Enforcement"
        ],
        "description": "Digital regulators are attempting to thread the needle between meaningful safeguards for children's online safety and giving minors freedom within their online presence. The Office of the Information and Privacy Commissioner of Ontario is among the global enforcers putting a priority on finding that equilibrium.",
        "content": [
            "Digital regulators are attempting to thread the needle between meaningful safeguards for children's online safety and giving minors freedom within their online presence. The Office of the Information and Privacy Commissioner of Ontario is among the global enforcers putting a priority on finding that equilibrium.",
            "While the IPC wants companies that use children's data to be accountable, it has also spent recent years developing a collection of online safety initiatives and resources to support underage users. The aim is for the IPC to reach all stakeholders with its awareness campaign, educating organizations, parents and users under age 18 about data security risks and best practices.",
            "Information and Privacy Commissioner Patricia Kosseim said her office is working \"to try to balance enhanced protections of youth online but also empowering them to be active participants in the online digital world, so that they can grow and participate fully as digital citizens.\"",
            "The protection of children starts with regulatory compliance and required transparency. Kosseim said a clear window into how data is being handled and used is \"fundamentally important\" for kids, especially to maintain use for age-appropriate purposes.",
            "Privacy impact assessments are also key, helping businesses to identify and mitigate risks within their own systems and those of any third-party providers they partner with.",
            "But when compliance is not fully understood or met, regulators stand ready to act.",
            "Kosseim highlighted Canadian enforcers\u2019 joint resolution against deceptive design practices, which noted companies' increasing use of dark patterns to \"manipulate or coerce users into making decisions that may not be in their best interests, particularly children.\"",
            "\"I think it's important for institutions, in the public or private sector, to be held accountable for the personal information that they collect, and that means securing it safely and adopting reasonable safeguards, including best practices on protecting that information from potential cyberattacks or avoiding at all costs that it be used for other purposes that were not intended originally,\" said Kosseim.",
            "The IPC also advocated for Ontario's Bill 194, the Strengthening Cyber Security and Building Trust in the Public Sector Act, 2024. Bill 194 includes regulations for digital technology geared toward children and is currently awaiting final regulations for AI provisions.",
            "The IPC issued recommendations for the bill which were not included in the final text, though Kosseim said the IPC will continue to be active \"participants in the regulation-making process to make sure that those responsibilities are reflected.\"",
            "Regulation keeps companies in check, but the IPC is also prioritizing child and parent outreach.",
            "From a user perspective, many risks posed by noncompliant activities are avoidable if they can be identified. The IPC is bringing that educational component through its strategic priority, Children and Youth in a Digital World.",
            "Kosseim said the IPC believes it can have a significant impact on children\u2019s online safety by championing \"the access and privacy rights of Ontario's children and youth by promoting their digital literacy and expansion of their digital rights but also holding institutions accountable for protecting the children and youth that they serve.\"",
            "She also noted the importance for underage users to \"understand the commercial risks to their information, particularly when they're dealing with tools, platforms, social media and websites.\" Financial fraud, predatory behavior and unwanted data collection on social platforms are among the potential hazards the IPC tries to highlight in its public awareness work.",
            "The IPC keys in on the most pressing children's online safety issues through its Youth Advisory Council.",
            "Launched in 2023, the council features 10 members under age 25 who guide the IPC on emerging digital issues impacting their demographic. The group aided the creation of the IPC's Youth Ambassador Toolkit, another IPC youth privacy resource compendium.",
            "\"They really do help us be more relevant and more effective,\" Kosseim said. \"They serve as a sounding board for us, and so we run things by them. We solicit their ideas, their input, their feedback.\"",
            "To expand digital literacy, the IPC introduced its Digital Privacy Charter for Ontario schools. According to the IPC, the charter \"consists of twelve high-level commitments that codify current and emerging best practices, many of which are grounded in statutory requirements under the\u00a0Municipal Freedom of Information and Protection of Privacy Act.\"",
            "While educational institutions are required to comply with privacy regulations, the charter also helps schools keep privacy protections in mind when vetting educational technology providers.",
            "\"We urge schools and school boards to sign on in order to demonstrate their commitment to protect personal information of students,\" Kosseim said. \"There's also commitments to help empower children and youth to be able to navigate the online world in an informed manner.\"",
            "The IPC's efforts to engage with children in the classroom has also expanded with the use of its Privacy Pursuit lesson plans. Developed alongside nonprofit MediaSmarts, the lessons are geared toward developing a base knowledge for children in grades two through eight.",
            "Kosseim said the adoption and circulation of these resources are a \"way of showing leadership in their community, as a way of showing that they are serious about accountability and transparency, and as a way of building trust among their students, their parents, and the communities they serve.\"",
            "Lexie White is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-iapp-canada-regulators-should-better-understand-data-breach-complexities",
        "title": "Notes from the IAPP Canada: Regulators should better understand data breach complexities ",
        "location": "North America",
        "date_published": "13 June 2025",
        "keywords": ["Data Security", "Enforcement"],
        "description": "I suspect many reading this have experienced dealing with at least one data breach. They happen all the time and most are quickly contained, rectified and result in little nuisance apart from documenting everything properly.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "I suspect many reading this have experienced dealing with at least one data breach. They happen all the time and most are quickly contained, rectified and result in little nuisance apart from documenting everything properly.",
            "The Office of the Privacy Commissioner of Canada experienced a breach several years ago. The OPC was moving from downtown Ottawa to offices across the river in Gatineau. All hard drives were logged that were supposed to make the trip, but when the new office was unpacked, one \u2014 or some, I can't remember \u2014 hard drive(s) was/were discovered missing.",
            "It wasn't stolen \u2014 at least we don't think it was. It was simply misplaced. But it did contain personal information of hundreds of current and past employees. I was among them.",
            "It took them several weeks to figure out the details of what happened, and the OPC eventually felt confident enough to send notices to individuals whose personal information was lost \u2014 again, me being one of them. They did not offer credit monitoring or identity theft protection.",
            "After the OPC breach, I remember Chantal Bernier, who was serving as interim commissioner at the time, speaking at conferences about her experience with the breach and saying it was an unfortunate, humbling event that nonetheless gave the office some very useful perspective it didn't have prior to that very real experience.",
            "That was more than 10 years ago. And, as we all know, things change rapidly these days when it comes to our industry. So, while I don't wish any of our regulators in Canada to endure a breach, I think it would be helpful for them to get a deeper sense of \u2014 and actually see \u2014 what organizations do when something occurs. From the more innocuous breaches to the more egregious ones.",
            "Often, breaches are caused because there are organized and very sophisticated crime syndicates causing the havoc. They invest heavily in their illegal operations as though it was a legitimate business. They recruit the smartest and brightest technophiles and lure them with exorbitant salaries that law enforcement cannot compete with.",
            "When breaches occur, my experience is that Canadian regulators are well-meaning in their approaches to tackle the problems, but they generally lack useful experience and perspective to even better understand the vast complexities of the issues.",
            "To this end, I have, on a few occasions, voluntarily offered to set up educational meetings with the firms that do the forensic work and negotiations with the threat actors. And, when a breach involves jurisdictions outside of Canada, it would be helpful for our Canadian regulators to better understand all the hundreds, if not thousands, of issues involved when handling multiple jurisdictions in a crisis at the same time.",
            "So, this week, I'm once again raising the idea that regulators, lawyers, forensic firms and negotiators come together for a series of enlightening lunch and learns. If anyone reading this is interested pursuing the idea, let me know. I'll bring the pizza.",
            "Kris Klein, CIPP/C, CIPM, FIP, is the managing director for Canada for the IAPP.",
            "This article originally appeared in the Canada Dashboard Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/uk-parliament-advances-data-use-and-access-bill-awaits-royal-assent",
        "title": "UK Parliament advances Data (Use and Access) Bill, awaits Royal Assent",
        "location": "Europe",
        "date_published": "12 June 2025",
        "keywords": [
            "Government Access",
            "International Data Transfers",
            "Law & Regulation",
            "AI Governance"
        ],
        "description": "After a long and winding road, the U.K. Parliament passed the proposed Data (Use and Access) Bill, which reforms the existing U.K. General Data Protection Regulation and the Privacy and Electronic Communications Regulations.",
        "content": [
            "After a long and winding road, the U.K. Parliament passed the proposed Data (Use and Access) Bill, which reforms the existing U.K. General Data Protection Regulation and the Privacy and Electronic Communications Regulations.",
            "The passage, which now only needs Royal Assent, follows a month-long \"ping pong\" between the House of Commons and House of Lords. The main issue in this latest round of debate involved artificial intelligence and copyright, and calls from the House of Lords to include transparency obligations. Several high profile U.K. musicians \u2014 including Elton John, Paul McCartney and Dua Lipa \u2014 had weighed in on the debate, calling for stronger copyright protections. The House of Commons pushed back on the provision arguing that such requirements would be handled in another AI-based bill.",
            "According to Hunton Andrews Kurth, U.K. Parliament reached a compromise that \"includes provisions requiring the Secretary of State to, amongst other things, draft legislation containing proposals to provide transparency to copyright owners regarding the use of their copyright works as data inputs for AI models.\"",
            "The U.K. government applauded the DUA Bill's passage. A spokesperson for the Department for Science, Innovation and Technology said, \"This Bill is about using data to grow the economy and improve people's lives, from health to infrastructure, and we can now get on with the job of doing that.\"",
            "Last November, Bird & Bird's Ruth Boardman, Emma Drake and Laura Goold offered an in-depth analysis of what was in the reform package released by the Labour Party last October and how it changed from previous iterations.",
            "In comments to the IAPP, Taylor Wessing Partner Victoria Hordern highlighted the impacts of provisions for a new legal basis for data processing. She said the proposed \"recognized legitimate interests\" option will \"cover relatively discrete circumstances but may be useful for businesses, especially small and medium-sized businesses, that simply need reassurance in certain circumstances about whether they can use personal data in this way.\"",
            "IHG Hotels & Resorts Director and Privacy Counsel Federico Rossi, CIPP/E, told the IAPP he does not view the reform bill as means to simply modernize U.K. legislation. He stated the DUA Bill recognizes and addresses a necessary departure from trying to perfectly match with the EU General Data Protection Regulation.",
            "\"This has always been based on EU principles,\" Rossi said, \"and it may have been harder to digest in the U.K. environment taking into consideration that the U.K. has always had a more flexible business approach.\"",
            "Notably, the bill's passage comes as the EU-U.K. adequacy agreement is up for renewal. The original adequacy review deadline was moved from June to December to give U.K. lawmakers time to advance the reform package and allow EU officials to examine updated provisions.",
            "Taylor Wessing Senior Counsel Debbie Heywood offered insight into what the DUA Bill could mean for EU-U.K. data transfers. Though several EU-based civil society groups, including the Open Rights Group and European Digital Rights, recently sent an open letter to EU Justice Commissioner Michael McGrath raising concerns about the U.K.'s data protection standards, the U.K. government does not believe the agreement is at risk.",
            "\"The government insists that nothing in the DUA Bill jeopardises the EU adequacy decision,\" Heywood wrote in her blog post, \"and so far neither the (European Data Protection Board) nor the (European Commission) have rung serious alarm bells, despite underlining they will be paying close attention.\"",
            "Outside of the DUA Bill, a potentially bigger issue for EU adequacy would likely involve the U.K. Investigatory Powers Act and recent news that the government required Apple to circumvent its encryption protections for users.",
            "Jedidiah Bracy is the editorial director for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/a-view-from-brussels-is-europe-ramping-up-its-agenda-on-protecting-children-online-",
        "title": "A view from Brussels: Is Europe ramping up its agenda on protecting children online?",
        "location": "Europe",
        "date_published": "12 June 2025",
        "keywords": ["Children's Privacy", "Law & Regulation"],
        "description": "\"It is an ethical responsibility towards the next generation.\" Cyprus, Denmark, France, Greece, Slovenia and Spain are upping discourse on the protection of minors online.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "\"It is an ethical responsibility towards the next generation.\" Cyprus, Denmark, France, Greece, Slovenia and Spain are upping discourse on the protection of minors online.",
            "Digital, policy and artificial intelligence ministers from the countries recently shared a non-paper on \"Protecting Minors from Online harms and risks,\" which addresses age verification, age-appropriate design and a pan-European digital age of majority.",
            "\"Poorly designed digital products and services can lead to heightened anxiety, depression, and self-esteem issues as minors are constantly exposed to trivial or comparative contents, while excessive screen time can limit the development of critical skills, alter cognitive capacities, weaken human relationships, and diminish the ability to collaborate effectively,\" they wrote.",
            "This happens against the backdrop of multiple instruments in the EU digital rulebook that address the topic directly and tangentially, at least in part: the EU General Data Protection Regulation, the Digital Services Act, the AI Act, the European Digital Identity Framework, the General Product Safety Directive, the Audiovisual Media Services Directive and rules to prevent and combat child sexual abuse, to name a few.",
            "This 2024 compendium provides a comprehensive view of EU formal texts concerning children in the digital world, including those in force and proposed as well as non-legislative initiatives. This document does not reflect the European Commission's most recent initiatives \u2014 such as the anticipated Digital Fairness Act, which may have relevance for children's online experience \u2014 nor the jurisprudence and best practices developing in the space.",
            "It is also worth noting the implementation of some of these texts is still in progress. For example, the Digital Services Act has already been in force for two years, yet the European Commission is only now producing detailed guidance on how platforms should protect minors online.",
            "Greece, France and Spain highlighted three primary challenges for the European community: the absence of a digital-age majority for online social networks; the lack of \"proper and widespread age-verification mechanisms that are properly enforced\"; and the need for mandatory technical standards for safe, private, non-addictive interfaces in platforms by design.",
            "These three countries are promoting new approaches and tools at a national level. The ideas range from better informing parents about existing parental controls to mandating a legal and technical framework that conditions access to a service to a \"robust and privacy-compliant age-verification mechanism,\" or considering mandatory parental controls and digital education programs.",
            "The non-paper's authorial countries are calling for EU-level regulatory action to three specific objectives:",
            "Some voices in the industry are already cautioning against the quick development of new rules and suggest the EU should let rules play out, particularly at a time when legislation like the DSA is not fully implemented.",
            "Isabelle Roccia, CIPP/E, is the managing director, Europe, for the IAPP.",
            "This article originally appeared in the Europe Data Protection Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/italy-s-dpa-reaffirms-ban-on-replika-over-ai-and-children-s-privacy-concerns",
        "title": "Italy's DPA reaffirms ban on Replika over AI and children's privacy concerns",
        "location": "Europe, North America",
        "date_published": "11 June 2025",
        "keywords": [
            "AI Governance",
            "Children's Privacy",
            "Enforcement",
            "Law & Regulation",
            "Personal Privacy"
        ],
        "description": "Italy's data protection authority, the Garante, reaffirmed its ban on the generative artificial intelligence chatbot Replika, citing persistent violations of the EU General Data Protection Regulation and ongoing risks to minors and vulnerable users.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. ",
            "Italy's data protection authority, the Garante, reaffirmed its ban on the generative artificial intelligence chatbot Replika, citing persistent violations of the EU General Data Protection Regulation and ongoing risks to minors and vulnerable users.",
            "This latest enforcement action, detailed in the Garante's April 2025 decision, underscores the regulator's commitment to safeguarding children's privacy, fundamental GDPR principles, and concern for nascent generative AI technology deployment.",
            "Replika, developed by San Francisco-based Luka Inc., is a large language model chatbot designed to serve as an AI \"companion,\" offering users emotional support and conversational engagement. Replika describes itself as \"The AI companion who cares\" that is \"always here to listen and talk.\"",
            "In February 2023, the Garante issued an urgent measure, No. 39/2023, Reg. No. 18321/2023, restricting Replika's data processing activities in Italy pursuant to Article 58(2)(f) of the GDPR. The authority found Replika posed significant risks to minors, lacked effective age verification mechanisms \u2014 asking only for name, email address, and gender \u2014 and failed to comply with transparency obligations under Articles 5, 6, 8, 9 and 25.",
            "The Garante highlighted that Replika's processing of personal data was unlawful, as it could not rely on contractual necessity as a legal basis when dealing with minors, who are legally incapable of entering into binding contracts under Italian law. The DPA also began a fact-finding investigation that ran parallel to Luka's attempts at remediation.",
            "Subsequently, in June 2023, the Garante issued decision No. 280, temporarily limiting Replika's processing pending implementation of remedial and corrective measures \u2014 including updating Replika's privacy notice in several ways, adding an age-gate mechanism to the service's registration pages and implementing other measures designed to protect users.",
            "Despite the initial enforcement decision laying out in detail Luka's deficiencies and required steps for remediation, the April 2025 decision states Luka did not implement sufficient corrective measures to address the identified violations.",
            "Among other things, Luka's privacy notice remained deficient, lacking a sufficiently granular description of the legal basis for processing personal data in connection with Replika and failing to link valid legal bases for processing users' personal data with specific processing operations \u2014 including a failure to identify the development of the LLM that powered the chatbot until February 2023.",
            "Luka's privacy policy was also only accessible in English, including for minors in Italy, and contained a reference to compliance with the U.S. Children's Online Privacy Protection Act \u2014 irrelevant for operations in Italy \u2014 rendering its overall posture ill-suited for its audience.",
            "Furthermore, Replika's age-gating mechanism had significant implementation and assurance flaws, including the ability for users to circumvent the age gate by initially submitting a fake age over 18 and then subsequently editing their profile, without any oversight or secondary confirmation by Luka.",
            "As a result of these continuing deficiencies, the Garante found Luka's processing unlawful, required Luka to fix its privacy policy and age gating with respect to Replika within 30 days and pay an administrative fine of 5 million euros.",
            "Replika's issues have not been isolated to the Garante's enforcement actions. In January 2025, the Young People's Alliance, Encode and the Tech Justice Law Project filed a comprehensive 67-page complaint with the U.S. Federal Trade Commission. It alleged deceptive marketing and design practices in violation of the FTC Act related to claims about mental health, income and wealth growth, language learning and personal relationships.",
            "Perhaps most disturbingly, the complaint alleges Replika was designed to deliberately foster emotional dependence in users through its companion chat interactions and simultaneously attempted to entice and retain users with fabricated testimonials and the misrepresentation of scientific research about the app's efficacy.",
            "Replika's offering of AI companions that can assume emotionally charged roles such as \"boyfriend\" or \"girlfriend\" raises significant ethical concerns, especially when minors can access these features.",
            "In addition to these baseline concerns, Replika's design appears to encourage rapid emotional bonding by initiating conversations on topics such as love and affection, offering virtual gifts and sending frequent affectionate messages during extended user engagement. These features may amplify the emotional impact of the chatbot and heighten the associated risks, particularly for vulnerable users.\u00a0\u00a0",
            "These risks are not isolated to Replika but appear to manifest across the companion-app industry. Another recent companion chatbot case involved a Florida mother who filed a wrongful death lawsuit against Character.AI and Google after her 14-year-old son died by suicide. The lawsuit alleges the AI chatbot, impersonating a character from \"Game of Thrones,\" fostered an emotionally abusive relationship with the teen that included \"anthropomorphic, hypersexualized, and frighteningly realistic experiences,\" contributing to his mental decline.",
            "These cases highlight a growing and legitimate concern about AI chatbots, especially when marketed to or accessible by children, and the potential psychological harm they can cause, emphasizing the need for robust and adequately enforced age verification, transparency and ethical design to protect vulnerable users.",
            "The enforcement actions and complaints against Replika underscore the critical importance of robust AI governance frameworks, regulatory protections and the role of enforcement agencies like the Garante and FTC.",
            "Organizations developing or deploying AI applications \u2014 especially those which will be accessible to children \u2014 must prioritize transparency, compliance with legal requirements, internal and external accountability and ethical considerations to safeguard users' well-being.\u00a0",
            "Frederick Bingham, CIPP/A, CIPP/C, CIPP/E, CIPP/US, CIPM, CIPT, is vice president, technology and privacy counsel at Skydance Media. The views expressed in this article belong solely to the author."
        ]
    },
    {
        "url": "https://iapp.org/news/a/support-for-ai-act-pause-grows-but-parameters-still-unclear",
        "title": "Support for AI Act pause grows but parameters still unclear",
        "location": "Europe",
        "date_published": "11 June 2025",
        "keywords": ["AI Governance", "Law & Regulation"],
        "description": "A delay in enforcing parts of Europe's landmark artificial intelligence regulation looks more likely after member states and the European Commission's technology leader supported the idea during a recent ministerial meeting. But a division is likely on how far any changes to the rule should go.",
        "content": [
            "A delay in enforcing parts of Europe's landmark artificial intelligence regulation looks more likely after member states and the European Commission's technology leader supported the idea during a recent ministerial meeting. But a division is likely on how far any changes to the rule should go.",
            "Reports of the Commission considering a \"stop the clock\" proposition for the EU Artificial Intelligence Act came as major implementation deadlines loom at the end of the summer and a key set of guidelines on general practice AI have been delayed. Some countries have yet to establish a lead regulatory body to enforce the regulation, and the EU has been wrestling with how to manage its various interlocking digital laws, with criticism of the regulatory regime coming both from within the EU and the U.S.",
            "Executive Vice-President of the European Commission Henna Virkkunen has been upfront about her desires to simplify the EU's digital laws. She reaffirmed those ideas during a 5 June European Council Transport, Telecommunications and Energy Council meeting.",
            "\"If we see that the standards and guidelines are not ready in time, we should not rule out postponing some parts of the AI Act in the coming months,\" she said.",
            "But any possibility of a delay should not be seen as waffling on the implementation itself, Virkkunen added.",
            "\"It's very important now to give legal certainty for the industry because this discussion has already created much uncertainty,\" she said. \"And we also see there has been a negative impact on the willingness of companies to engage with the process because there is uncertainty.\"",
            "It is still unclear what course of action the Commission will ultimately pursue. Prohibitions on certain uses of AI and AI literacy requirements have been in place since February and obligations for general purpose AI model providers are still slated to go into effect this August. In emailed comments to the IAPP, a Commission spokesperson said the goal of the act remains unchanged \u2014 but the digital simplification omnibus is still in the works.",
            "\"In this simplification context, all options remain open for consideration at this stage,\" the spokesperson said.",
            "Participants of the 5 June meeting had ranging views on what should be done. Jan Kavalirek, Czechia\u2019s deputy minister of industry and trade, suggested all parts of the regulation not in place should be postponed by two years.",
            "\"We remain convinced that meeting the EI AI Act requirements, given the scale and complexity, requires more time, especially for private stakeholders,\" he said.",
            "Whereas Spain's Minister of Digital Transformation Oscar L\u00f3pez \u00c1gueda said Spain was supportive of simplification of the AI rules but added that should not be seen as supporting deregulatory efforts, noting the EU has measures such as sandboxes to help businesses get into compliance.",
            "\"It's not about stopping any clock, it's about synchronizing our clocks,\" he said.",
            "The idea has garnered support from the AI industry. The Computer & Communications Industry Association's EU arm told the Commission the August deadline for general AI rules is not enough time, given that a voluntary code of conduct and other guidelines are still missing.",
            "\"Additional time is needed to finalise the framework and ensure companies have a reasonable compliance window, in line with established EU rules,\" the association wrote on 5 June.",
            "Whatever the course of action the Commission takes, any changes to the act would have to go back through the legislative process, said Kai Zenner, the head of staff for German Member of European Parliament Axel Voss. Substantial revisions would likely take longer to hash out than, for instance, changing a word or two around enforcement dates.",
            "Zenner said it was hard to predict what the European Parliament would support and cautioned against taking the words of some vocal members as representations of the whole, and it is hard to get a bead on how the Commission itself feels, he said.",
            "\"They are talking with the press and then one EU Commission official is saying one thing, the other is saying another thing. They are talking among each other. They are talking with parliamentarians, with us, and so on and so on,\" he said. \"So, it means that the Commission is heavily divided and that there are indeed different camps in the Commission that are fighting against each other.\"",
            "Zenner also expressed frustration at the conversation around enforcement, saying his boss and others warned during the trilogue process that the act's deadlines did not give regulators and companies enough time to get into compliance with the technical standards for dynamic technology like AI. He said the regulation might not be perfect, but regulators should work to implement it as best they can and prevent uncertainty as to what they will ultimately do.",
            "\"I think the worst that could happen now is if the EU comes across as if \u2014 when there's just a little bit of opposition \u2014 we basically give up all of our values, all of our plans, and our AI strategy doesn't matter anymore,\" he said.",
            "The possibility of the Commission pausing enforcement would be unusual but not unheard of, said Eduardo Ustaran, AIGP, CIPP/E, a partner and co-head of Hogan Lovells' privacy and cybersecurity practice. He pointed to the two \"Schrems\"decisions which changed how international data transfers work as examples of data protection authorities giving businesses some time to adjust.",
            "\"It's not like the day after those decisions of the Court of Justice of the European Union, they were going after companies saying, 'Ah, we caught you. Now you don't have a mechanism to legitimate sector transfers,'\" he said. \"They said, 'Okay, well, you know what you have to do,' and there was a degree of tolerance to allow organizations find a way to comply.\"",
            "Ustaran said people should also not treat a potential delay as a catastrophe for the regulation, saying it will take time for regulators to adjust. He said a pause could be helpful for all parties \u2014 but cautioned against taking any delay as a sign to relax.",
            "\"There is an expectation that companies are still going to be working towards compliance, as opposed to saying, 'Now they're not taking this seriously so that we can ignore it,'\" Ustaran said. \"That would be unwise, I think.\"",
            "Caitlin Andrews is a staff writer at IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/meta-s-risk-assessment-updates-look-toward-holistic-approach",
        "title": "Meta's risk assessment updates look toward 'holistic' approach",
        "location": "",
        "date_published": "11 June 2025",
        "keywords": [
            "Technology",
            "Privacy Program Management",
            "Risk Management",
            "Strategy & Governance",
            "AI Governance"
        ],
        "description": "A reported shift toward artificial intelligence automation in Meta's risk assessment program sparked questions around trickledown impacts on the privacy and digital responsibility profession. According to Meta, the planned changes have nothing to do with replacing human reviews and focus more on building out systems to handle the growing digital governance ecosystem.",
        "content": [
            "A reported shift toward artificial intelligence automation in Meta's risk assessment program sparked questions around trickledown impacts on the privacy and digital responsibility profession. According to Meta, the planned changes have nothing to do with replacing human reviews and focus more on building out systems to handle the growing digital governance ecosystem.",
            "Meta Vice President of Policy and Deputy Chief Privacy Officer Rob Sherman joined IAPP Vice President and Chief Knowledge Officer Caitlin Fennessy, CIPP/US, for a LinkedIn Live to discuss what Sherman described as \"unfortunate mischaracterizations\" made by NPR regarding planned risk assessment changes.",
            "NPR said it obtained internal Meta documents showing the company's intention to automate 90% of its assessment work through the application of AI. The infusion of AI would reportedly extend to Meta's algorithm, safety features and changes to how content is shared.",
            "Sherman said the reporting generated an understandable wave of reactions from the public and Meta employees, but he indicated Meta is fully committed to keeping risk assessments under human control.",
            "\"Just to be very clear, AI is not making risk decisions at Meta,\" Sherman said. \"Humans are still very much in control of the process and driving the process.",
            "While the human element of risk reviews is intact, Meta is indeed planning to leverage AI to streamline aspects of the process.",
            "Sherman confirmed some of NPR's reporting about how AI is being implemented into reviews. The internal documents indicated product teams will submit a questionnaire to receive an AI-driven \"instant decision\" identifying risks and potential mitigation measures that must be addressed before a launch.",
            "\"We tried to look at the decisions we were making and figure out what parts we can write down ahead of time ... and have a system automate it rather than having people remember to do things,\" Sherman said. As an example, he pointed to a hypothetical pre-determined \"human-written\" set of automated data deletion rules a new product can be put through before reaching a final human review.",
            "The new process will initially apply in the areas of privacy, AI governance, youth protection, and safety and security. Sherman anticipates further expansion to accessibility, intellectual property and copyright as time goes on.",
            "The streamlining is targeted for assessment areas that do not require \"nuanced discussion about what's the right way to do it,\" according to Sherman. Issues flagged during an automated review \u2014 including areas that are unaddressed in automation \u2014 are sent for human intervention and assessment.",
            "The \"evolution\" toward automation is twofold.",
            "On one side, Sherman said Meta views AI \"at the forefront of what we are doing as a company\" and leveraging it will \"help speed up processes.\" On the other hand, the process changes acknowledge the need to broaden work to include an all-encompassing view of digital governance needs.",
            "\"We are a technology company. Our core bread and butter is not building governance programs but building technology,\" Sherman said. \"The real question was how can we use our skill within technology to solve some of these things and help make the risk review process more effective.\"",
            "Meta's privacy governance initiatives represent the foundation for the digital governance endeavor.",
            "Sherman said privacy reviews are \"the backbone of how we make decisions and build.\" Privacy alone \"continues to be really important\" to the company, he said, but the way privacy principles address risks offered a \"natural\" opportunity to expand the reach to other digital domains and aim for a \"one-stop shop.\"",
            "\"When you're thinking about privacy, that implicates issues of AI governance, youth protection. There is a give and take between those,\" Sherman said. \"Thinking about those things holistically is important if you want whatever your company is building to be a net-positive for the world, you need to think holistically.\"",
            "Joe Duball is the news editor for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/can-inferred-insecurity-about-physical-traits-be-regulated-as-sensitive-data-",
        "title": "Can inferred insecurity about physical traits be regulated as sensitive data?",
        "location": "",
        "date_published": "11 June 2025",
        "keywords": [
            "AI Governance",
            "Biometrics",
            "Law & Regulation",
            "Surveillance",
            "Regulatory Guidance"
        ],
        "description": "As machine learning models and recommendation algorithms become more sophisticated, so too do their abilities to make inferences about users, particularly in ways that reveal deep personal vulnerabilities.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. ",
            "As machine learning models and recommendation algorithms become more sophisticated, so too do their abilities to make inferences about users, particularly in ways that reveal deep personal vulnerabilities.",
            "One emerging area of legal and ethical concern is whether the inference of insecurity about one's physical appearance \u2014 facial asymmetry, acne, aging, weight or other aesthetic traits \u2014 can be classified and regulated as sensitive personal data.",
            "Under most data protection laws, sensitive personal data refers to categories of data that, if misused, could result in significant harm or discrimination. This includes data relating to racial or ethnic origin, political opinions, religious beliefs, health, sexual orientation and biometric or genetic data. Article 9 of the EU General Data Protection Regulation elevates the protection of these categories, requiring explicit consent or an enumerated legal basis for processing.",
            "However, inferred data \u2014 especially when it pertains to a user's self-perception, mental health or body image \u2014 exists in a gray zone. If a platform like TikTok infers a user is insecure about their nose, lips or weight based solely on behavior \u2014 like pausing on aesthetic procedure videos, interacting with cosmetic influencers, or frequently using face-slimming filters \u2014 does that inferred profile meet the threshold for legal sensitivity?",
            "The line between aesthetic interest and health-related inference is blurrier than it may appear. Inferring someone is insecure about their appearance may also suggest mental health vulnerabilities such as low self-esteem, depression or body dysmorphia. These are issues that fall under protected health categories in many jurisdictions.",
            "Under U.S. law, for instance, inferred health data may not be protected by the Health Insurance Portability and Accountability Act, which applies only to covered entities, but state-level laws such as the California Privacy Rights Act recognize \"sensitive personal information\" to include health data, precise geolocation and contents of communications. The CPRA further empowers consumers to limit the use of such information, even when it is not directly provided but deduced through profiling.",
            "If platforms are using inferred insecurity to tailor content, ads or experiences \u2014 such as directing users to cosmetic surgeons, diet products or anti-aging treatments \u2014 this creates a discriminatory risk. Platforms are essentially assigning vulnerability scores and monetizing them, often without transparency or consent.",
            "In this context, inferred data could be considered discriminatory profiling, particularly if the user is a minor, a protected demographic or struggling with mental health. As such, there is a compelling argument that inferred insecurity should be regulated similarly to biometric or health-related data.",
            "Another layer involves third-party tools linked via beauty apps, augmented reality simulators and booking platforms. These tools often justify their practices under the guise of \"masking\" or \"anonymizing\" user data before further processing or sharing. In theory, this masking is intended to prevent direct identification of individuals and, thus, lower the regulatory burdens associated with sensitive data.",
            "However, in practice, the effectiveness of such masking is deeply questionable. Behavioral signals \u2014 such as the type of procedures explored, the sequence of interactions and device fingerprints \u2014 can often be re-identified with startling ease, especially when aggregated with other data points. As a result, interest data, sometimes health-related, may be sold to advertisers or data brokers without transparent user consent or true anonymization.",
            "The narrative of \"masking\" provides a convenient cover for what remains fundamentally intrusive profiling. Thus, regulatory frameworks must critically evaluate not just whether data is \"anonymized\" in name, but whether it is genuinely irreversible and unlinkable in practice.",
            "Clearview AI scraped billions of facial images from social media and other online sources, claiming its database was used for legitimate security purposes. However, privacy advocates and regulators argued the technology enabled mass surveillance without consent, illustrating how easily supposedly \"public\" or \"anonymized\" data could be weaponized.",
            "In the now infamous Facebook scandal, Cambridge Analytica leveraged seemingly trivial user engagement data \u2014 such as \"likes\" \u2014 to build detailed psychographic profiles. This showed that even benign behavioral data can be reconstituted into powerful, identifiable intelligence about political leanings, insecurities and vulnerabilities.",
            "Both cases highlight that inferential profiling based on minimally sensitive or \"masked\" data can still yield highly sensitive, identifiable information \u2014 often without user knowledge or consent.",
            "The European Data Protection Board has already highlighted the need to regulate inferred sensitive data, noting that behavioral predictions and profiling can lead to unjust outcomes. In 2023, the U.K. Information Commissioner's Office expressed concern for online services likely to be accessed by children, aiming to protect their data and well-being. Naturally this includes the use of beauty filters and self-image manipulations that affect children's mental health. The ICO urges platforms to consider these implications when applying the U.K. Children's Code.",
            "In the U.S., the FTC has increasingly turned its focus to dark patterns, manipulative design and exploitative personalization \u2014 an umbrella that may soon include the inferencing of psychological vulnerabilities.",
            "To truly safeguard user autonomy and dignity in digital environments, regulators must expand the definition of sensitive data to explicitly include inferred data that pertains to:",
            "\u2022 Physical appearance insecurity.",
            "\u2022 Body dysmorphia or low self-esteem.",
            "\u2022 Behavioral indicators of mental health vulnerabilities.",
            "This does not mean banning all profiling, but rather demanding greater accountability and transparency:",
            "\u2022 Platforms must disclose when they are inferring insecurities or vulnerabilities.",
            "\u2022 Users should be able to access, challenge, and erase such inferences.",
            "\u2022 Where inferences relate to protected characteristics or health-related concerns, explicit consent should be required.",
            "In the digital age, what platforms guess about us can be more revealing \u2014 and more dangerous \u2014 than what we explicitly share. As platforms continue to infer and exploit aesthetic insecurities, it is imperative that the law evolves to recognize such inferred traits as sensitive personal data deserving of protection.",
            "The integrity of data privacy law depends not just on what data is collected \u2014 but on how it is interpreted, inferred and ultimately used against us.",
            "Li-Rou Jane Foong, CIPP/E, CIPM, FIP, is a Master's in Law candidate with a focus on privacy law and cybersecurity. Foong was previously a global privacy specialist at Rakuten Group in Tokyo and is a dual-qualified lawyer."
        ]
    },
    {
        "url": "https://iapp.org/news/a/the-final-days-of-grace-preparing-for-the-u-s-sensitive-data-rule",
        "title": "The final days of grace: Preparing for the U.S. sensitive data rule",
        "location": "North America",
        "date_published": "9 June 2025",
        "keywords": [
            "Government",
            "Data Processing",
            "Data Protection Obligations",
            "Enforcement",
            "Regulatory Guidance",
            "International Data Transfers"
        ],
        "description": "On 8 April 2025, the U.S. Department of Justice's rule on access to U.S. sensitive personal data and government-related data went into effect. Simultaneously, the DOJ announced that it would not enforce the rule through 8 July 2025 so long as a company is engaging in good faith efforts to comply or come into compliance. That clock is ticking. U.S. entities that collect data about Americans should be working now to understand and implement this complex new regulatory scheme, the Data Security Program.",
        "content": [
            "On 8 April 2025, the U.S. Department of Justice's rule on access to U.S. sensitive personal data and government-related data went into effect. Simultaneously, the DOJ announced that it would not enforce the rule through 8 July 2025 so long as a company is engaging in good faith efforts to comply or come into compliance. That clock is ticking. U.S. entities that collect data about Americans should be working now to understand and implement this complex new regulatory scheme, the Data Security Program.",
            "Adopted pursuant to Executive Order 14117, the rule is designed to protect Americans' sensitive personal data from exploitation by foreign adversaries. After years of nation-state cyber actors breaking into government and private sector systems to steal data about Americans, and after many efforts aimed at improving the cybersecurity of public and private information systems, officials in both the Trump and Biden administrations recognized that there was a loophole in their efforts: \u00a0foreign adversaries could simply purchase bulk personal data about U.S. persons and government employees or acquire it in commercial transactions. The DSP aims to close that loophole by restricting how U.S. data can be shared, transferred, or accessed in relation to \"countries of concern.\"",
            "To help organizations achieve compliance, the DOJ published a DSP compliance guide and an extensive FAQ. This guidance clarifies how the rule applies and offers a detailed picture of the DOJ's expectations and its enforcement posture. Moreover, during the grace period, the National Security Division, which will be enforcing the rule, is encouraging informal inquiries about the DSP and its guidance.",
            "The IAPP has published resources and primers that dive into the history, scope and some of the definitions of the rule. This article highlights key guidance for organizations to consider when developing their compliance practices, programs and controls.",
            "The DSP addresses\u00a0any transaction that involves any access by a \"country of concern\" or a \"covered person\" to any government-related data or bulk U.S. sensitive personal data\u00a0via data brokerage or through a\u00a0vendor, employment or investment agreement. \"Country of concern\" is clear: the rule currently designates China, Cuba, Iran, North Korea, Russia and Venezuela. With regard to entities, the DSP definition of covered person is focused on ownership. An entity is a \"covered person\" if it is organized or chartered under the laws of, or has its principal place of business in, a country of concern; or if it is 50% or more owned, directly or indirectly, individually or in the aggregate, by one or more countries of concern or persons otherwise fitting the definition of covered person.",
            "A company incorporated or headquartered outside a country of concern will still be considered a covered person \u2014 so long as it is not a U.S. person \u2014 if it is majority-owned by one or more covered foreign entities. This applies even if the ownership flows through multiple layers.",
            "Say for example that a foreign person living in China owns 50% of an Argentinian company. That Argentinian company owns 100% of a Brazilian company, and 100% of a Canadian company. The Brazilian company owns 20% of a Denmark company and the Canadian company owns 30% of the same Denmark company.",
            "Under the DSP, the Denmark company would be a covered person for two reasons. First, the Denmark company is indirectly 50% or more owned by the Argentinian company \u2014 20% through the Brazilian company and 30% through the Canadian company \u2014 which is 50% owned by a foreign person living in China. Second, the Denmark company is also directly 50% owned, in the aggregate, by the Brazilian and Canadian companies, each of which is a covered person because they are 50% or more owned by the Argentinian company, which is 50% owned by a foreign person living in China.",
            "See other examples in FAQ 60. Using these definitions and guidance, organizations must ask whether ownership of vendors or investors traces back to persons in a country of concern.",
            "Regulated transactions do not require the sale of data. Covered data transaction is defined as any transaction that involves any access by a country of concern or covered person to any government-related data or bulk U.S. sensitive personal data via data brokerage or through a\u00a0vendor, employment or investment agreement. This includes the ability to obtain, read, copy, decrypt, edit, divert, release, affect, alter the state of or otherwise view or receive, in any form, including through information systems, cloud-computing platforms, networks, security systems, equipment or software. For example, using a cloud provider that is owned by a covered person, even if the servers are within the U.S., is still covered under the rule if that provider can access the data. Organizations must evaluate the technical capabilities of their foreign tech vendors and outsourced infrastructure and services.",
            "Under the rule, some transactions are flatly prohibited, particularly those involving the sale \u2014 \u00a0brokerage \u2014 of sensitive data to a country of concern or covered persons, as well as data brokerage with a foreign person that is not a covered person, unless the U.S. person contractually requires that the foreign person refrain from onward sale with a country of concern or covered person. \u00a0See FAQs 16 and 18. Another key point: as Omer Tene emphasized in the IAPP LinkedIn Live data transfer and cybersecurity laws, there's no exception for anonymized, pseudonymized or de-identified data. See FAQ 22.",
            "The DOJ compliance guide states that some activities that might not be thought of in ordinary parlance as data brokerage may nonetheless fall under the DSP. For example, if a U.S. company maintains a website that contains ads with tracking pixels or a mobile application that contains a software development kit knowingly installed or approved for incorporation into the website or app by the U.S. company, it may constitute the provision of access to bulk sensitive or government-related data that could constitute data brokerage.",
            "Other transactions fall into the restricted category. Generally, restricted transactions may proceed if the U.S. person complies with security requirements set by the Cybersecurity and Infrastructure Security Agency.",
            "Merely hiring someone who is a national of a country of concern does not, on its own, trigger the rule. See FAQ 67. However, in a prior IAPP LinkedIn Live, Rush Atkinson explained how important it will be for companies to structure employee access to data, most notably by implementing the CISA security requirements to ensure that those covered person employees or vendors cannot access government-related data or bulk U.S. sensitive personal data.",
            "This places emphasis on the role and access level of employees, not just their citizenship or location. Organizations will need to reassess how they manage remote work, especially when granting sensitive data access to employees or contractors abroad.",
            "FAQs 78 through 93 provide explicit guidance on what organizations should be doing to achieve compliance, beginning with \"know your data.\" Specifically, that means that U.S. persons engaging in restricted transactions must develop and implement data compliance programs with risk-based procedures for verifying data transactions, including the types and volumes of data involved in the transactions, the identity of the transaction parties and the end use of the data. This could include revising or creating new internal policies and processes, identifying data flows, changing vendors or suppliers, adjusting employee roles or responsibilities, deploying new security requirements and revising existing contracts.",
            "Compliance is not a one-time task. Companies must continue to monitor their data flows and business relationships over time at a frequency appropriate for their organization. A vendor that was not covered in January could become covered in July if ownership or control changes. The DOJ expects companies to update their compliance analyses accordingly.",
            "The FAQs outline how the DOJ plans to enforce the DSP. Through 8 July 2025, the DOJ is focusing on outreach and education while maintaining the discretion to pursue enforcement for egregious, willful violations, including criminal enforcement in cases where individuals or entities willfully violate, attempt to violate, conspire to violate, cause a violation of, or engage in any action intended to evade or avoid the DSP's requirements.",
            "After the grace period ends next month, the DOJ expects full compliance. However, requirements related to due diligence, auditing and reporting don't become effective until 6 October 2025.",
            "Civil penalties for violations include fines up to USD368,000 or twice the amount of the transaction that is the basis of the violation, whichever is greater. Additionally, criminal penalties may apply in cases of willful noncompliance, including attempts, conspiracy or aiding and abetting. Criminal convictions can result in up to 20 years' imprisonment and a fine of up to USD1 million.",
            "The DSP represents a major shift in how the U.S. government views the cross-border movement of personal data. It reaches beyond formal sales to include remote access, cloud services, internal transfers and even employee access. The DOJ's guidance reveals how expansive and dynamic the DSP is intended to be while hinting at how aggressively this administration intends to enforce it.",
            "For organizations that deal with large-scale personal data, the message is clear: understand your data flows and vendor relationships and maintain a well-documented compliance process. The DOJ's expectations are detailed and public; the time to show good-faith efforts is now.",
            "Cheryl Saniuk-Heinig, CIPP/E, CIPP/US, is a research and insights analyst at the IAPP and Jim Dempsey is the managing director for the IAPP Cybersecurity Law Center."
        ]
    },
    {
        "url": "https://iapp.org/news/a/a-view-from-dc-double-toil-and-trouble-in-connecticut-s-privacy-amendment",
        "title": "A view from DC: Double toil and trouble in Connecticut's privacy amendment",
        "location": "North America",
        "date_published": "6 June 2025",
        "keywords": ["AI Governance", "Biometrics", "Law & Regulation"],
        "description": "As legislative sessions in the states wind down, policymakers are making mad dashes to finish concocting their privacy and AI governance brews for the year.\u00a0",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "As legislative sessions in the states wind down, policymakers are making mad dashes to finish concocting their privacy and AI governance brews for the year.\u00a0",
            "Many such potions will remain incomplete. It looks increasingly likely that 2025 may be a year without a new comprehensive consumer privacy law on the books. But across every other area, from kids\u2019 safety to AI sectoral privacy rules to AI, it has been a busy session. This includes quite a few significant tweaks to existing state privacy laws, informed by enforcement experience and comparisons with the evolving patchwork.\u00a0",
            "Connecticut has not disappointed in this regard. This active state for tech policy legislation sent a bill this week to its governor\u2019s desk that, among other things, modifies its existing comprehensive consumer privacy law.\u00a0",
            "Sections 5 through 14 of the bill, as passed by Connecticut\u2019s Senate and concurred by the House, would replace the current privacy law on the books. If signed by the governor, the changes to Connecticut's law will be effective as of 1 July 2026.\u00a0",
            "Sometimes in the world of data privacy, more is in fact more. Perhaps after reflecting on its relatively small state population, Connecticut is updating its threshold for processing personal data to 35,000 consumers instead of the current 100,000. The current rule puts it roughly in the middle of the pack of states, measured as a percentage of population, requiring that a business reach just under 3% of its residents before privacy requirements are triggered.\u00a0",
            "Moving forward, the amendment would give Connecticut a hair-trigger scope of less than 1% of the state's population. This threshold is stronger than every state except California and Maryland \u2014 not to mention Nebraska and Texas, which do not have thresholds.\u00a0",
            "Even more importantly for enforcement potential, the amendment would also add two more prongs to the scope determination. If a business offers any amount of Connecticut consumers\u2019 personal data \"for sale in trade or commerce\" or processes any amount of sensitive data from Connecticut consumers, it will be subject to the law. No volume threshold required.\u00a0",
            "But not so fast. The updated scope would also add exemptions to remove some highly regulated industries, including specific types of financial, insurance and health companies \u2014 plus political committees \u2014 from coverage under the law. And an exemption for data subject to the Gramm-Leach-Bliley Act would align Connecticut with the approach in most states.\u00a0",
            "As ever, policymakers cannot resist tinkering with the list of sensitive data types, which remains one of the most divergent areas between comprehensive state privacy laws. Connecticut would add to the patchwork with new covered data \u2014 largely contiguous with at least one other state \u2014 while also creating a new substantive requirement for when the processing of sensitive data is allowed.\u00a0",
            "The updated list of sensitive data types would also:\u00a0",
            "Modify health data to include treatment as well as disability status, in addition to the existing \"condition or diagnosis\" language, cobbling together language from a few states to make a relatively broad health data definition.\u00a0",
            "Broaden the knowledge standard for children's data to include any individual for whom the controller \"has actual knowledge, or wilfully disregards, is a child,\" rather than the existing \"known child\" language.\u00a0",
            "Drastically expand the biometric and genetic data categories, eschewing the existing purpose-based limitation to not only include this data regardless of its purpose of collection but also to include \"information derived therefrom,\" that is inferences created based on genetic or biometric data types.\u00a0",
            "Add neural data to the list, joining a small but growing list of states, including California and Colorado, with extra protections for this emerging frontier of personal data. In the amendment, neural data is defined as \"any information that is generated by measuring the activity of an individual's central nervous system.\" As the Future of Privacy Forum's Jameson Spivack has explained it, this is a narrower definition from the other states, which also include at least some level of peripheral nervous system data.\u00a0\u00a0\u00a0",
            "Add \"status as nonbinary or transgender,\" joining Delaware and Oregon in recognizing this data as sensitive.\u00a0",
            "Add financial data and government ID numbers to the list, not to be outdone by California.\u00a0",
            "On substance, if given effect, the amendment will require not only the consumer's consent to process personal data, but a minor data minimization element too: a showing that the processing is \"reasonably necessary in relation to the purposes for which such sensitive data are processed.\" The legislator considered and rejected stronger data minimization language in this draft bill, leaving us with this tweak as well as the addition of \"proportionate\" to the existing \"reasonably necessary\" requirement in the general data minimization provision.\u00a0",
            "If states are the laboratories of democracy, state Sen. James Maroney, D-Conn., continues to embrace a mad scientist image, crafting new creative compounds as he observes the trajectory of other states and the broader policy conversation.\u00a0",
            "His 2025 amendment would also incorporate some other notable tweaks, which often appear inspired by the legislative innovations in other states from recent years, including:\u00a0",
            "New privacy notice requirements, including a description of how consumers may appeal decisions about their requested exercise of data rights, disclosures about targeted advertising and data sales, and a \"statement disclosing whether the controller collects, uses, or sells personal data for the purpose of training large language models.\"",
            "New rights to review and question automated decisions based on profiling, reminiscent of language in Minnesota's privacy law. In the specific situation of a housing decision, the amendment also includes the ability to request a correction and re-analysis. The definition of automated decisions is also broadened slightly to include decisions impacting anyone, not just the specific consumer involved, and new impact assessment requirements are outlined whenever profiling provisions are triggered.\u00a0",
            "An Oregon-inspired, but much narrower, requirement to respond to consumer requests for a list of third parties to which a controller has sold personal information.\u00a0",
            "Aligning with many other states on the definition of publicly available data, adding \"widely available media,\" while exempting biometric data from inclusion.\u00a0",
            "Clarity on when privacy impact assessments are required, with a list of situations that trigger the \"heightened risk of harm\" to consumers standard.\u00a0",
            "It is also worth flagging that the legislative vehicle containing the amendment to Connecticut's privacy law also includes new rules for social media platforms as well as some tweaks to kids' safety requirements, but those are a subject for another day.\u00a0",
            "Please send feedback, updates and potion recipes to cobun@iapp.org.\u00a0\u00a0",
            "Cobun Zweifel-Keegan, CIPP/US, CIPM, is the managing director, Washington, D.C., for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/us-lawmakers-find-bipartisanship-in-opposition-to-uk-s-order-on-apple-encryption-back-door",
        "title": "US lawmakers find bipartisanship in opposition to UK's order on Apple encryption back door",
        "location": "",
        "date_published": "6 June 2025",
        "keywords": [
            "Data Security",
            "Government Access",
            "Surveillance",
            "Law & Regulation"
        ],
        "description": "Members of a U.S. House subcommittee have a bipartisan view on the need to address potential negative impacts of a proposed order from the U.K. government for Apple to create a back door to encrypted user data in its cloud database.",
        "content": [
            "Members of a U.S. House subcommittee have a bipartisan view on the need to address potential negative impacts of a proposed order from the U.K. government for Apple to create a back door to encrypted user data in its cloud database.",
            "The House Committee on the Judiciary's Subcommittee on Crime and Federal Government Surveillance held a 5 June hearing to promote further review of the U.K.-U.S. Clarifying Lawful Overseas Use of Data Act \u2014 otherwise known as the CLOUD Act. The hearing delved into the U.K.'s invocation of its Investigatory Powers Act to force backdoor access to Apple cloud data for law enforcement purposes, and how that access could impact the safety of U.S. data.",
            "Consensus among federal lawmakers on data privacy matters is not a simple task. However, House subcommittee Republicans and Democrats agreed the U.K. order is potentially problematic for U.S. data and could pave the way for other pervasive standards.",
            "Subcommittee Chair Andy Biggs, R-Ariz., indicated the U.K.'s requirement \"sets a dangerous precedent and if not stopped now could lead to future orders by other countries.\" Ranking Member Jamie Raskin, D-Md., added, \"Forcing companies to circumvent their own encrypted services in the name of security is the beginning of a dangerous slippery slope.\"",
            "Biggs went as far as proposing the U.S. invoke a 30-day termination clause on the sharing agreement and renegotiate terms in a way that halts potential unfettered U.K. backdoor access.",
            "The U.K.-U.S. CLOUD Act was enacted by Congress in 2018 and took force August 2022. It allows U.S. companies to hand over user data in response to legal requests from foreign jurisdictions subject to conditions around adequate security standards as well as necessity and proportionality.",
            "Biggs suggested the proposed order to Apple or any other U.S.-based cloud database could allow the U.K. to invoke the CLOUD Act to openly access U.S. consumer data through a back door. He said the U.K. is \"taking advantage of its authority\" with such a move while \"attacking data security and privacy.\"",
            "\"Efforts to weaken, or even breaking, encryption makes us all less secure,\" Biggs added. \"The U.S.-U.K. relationship must be built on trust. If the U.K. is trying to undermine this foundation of cybersecurity, it is breaching that trust. If companies are forced to build back doors, that simultaneously opens a back door to privacy rights and it's impossible to limit a back door to just the good guys.\"",
            "Raskin insisted he supports the premise of the CLOUD Act and the agreement itself is not the problem at hand. But he said back doors \"are only worthwhile to the U.K. because of the data made available through the agreement.\"",
            "Tufts University Professor of Cyber Security and Policy Susan Landau testified to the subcommittee on a perceived anti-encryption pattern the U.K. is developing.",
            "In addition to the backdoor order to Apple, Landau pointed to the absence of the U.K. on December 2024 joint guidance from the so-called \"Five Eyes\" alliance on securing digital communications infrastructure. The guide, supported by Australia, Canada, New Zealand and the U.S., implored network engineers and defenders make encryption foundational and use it \"to the maximum extent possible.\"",
            "\"By refusing to sign, the U.K. is a real outlier,\" Landau said. \"Apple's advanced encryption protects people's data. It's an important and needed technology. I urge you to ensure the U.K.'s efforts to improve its own investigatory capabilities do not come at its expense.\"",
            "Echoing Biggs' opposition to potential unintended access to encryption back doors, Raskin said a single exemption could lead to a flood of potential espionage, consumer fraud and ransomware. He added the \"deluge of ways governments spy on their citizens\" will only be exacerbated if privacy and security slip by the wayside.",
            "\"Some argue privacy is passe. ... Cookies monitor which sites we click on. Our devices already track every step we take. And data brokers take anonymized data and reidentify in portfolios available to the highest bidder.\" Raskin said. \"But I disagree with the idea privacy is no longer valuable or meaningful to the American citizenry. ... Americans' security from government intrusion has never been more urgent or important.\"",
            "Joe Duball is the news editor for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-iapp-canada-taking-meaningful-steps-to-protect-children-online",
        "title": "Notes from the IAPP Canada: Taking meaningful steps to protect children online",
        "location": "North America",
        "date_published": "6 June 2025",
        "keywords": [
            "Children's Privacy",
            "Data Security",
            "Law & Regulation",
            "Biometrics"
        ],
        "description": "Did you miss me? Anne-Marie and I were enjoying some time off in the South of France, but we kept on top of what was happening in our industry. Good thing too \u2014 things are heating up.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "Did you miss me? Anne-Marie and I were enjoying some time off in the South of France, but we kept on top of what was happening in our industry. Good thing too \u2014 things are heating up.",
            "I'm concentrating on children's issues this week, but it's worth noting there was plenty more going on, including a new and rather sweeping lawful access bill that could, if passed, circumvent privacy protections the Supreme Court of Canada thought were worth constitutional protection. I suggest you sip a \"noisette\" and enjoy a French baguette as you read what's top of mind today and catch up on the other privacy news in Canada.",
            "As children spend more time online, Canadian lawmakers and privacy officials are stepping up efforts to shield them from digital dangers. Two major recent developments to mention \u2014 the Senate's introduction of\u00a0Bill S-210 and the\u00a0Office of the Privacy Commissioner of Canada's 2024-2025 Annual Report \u2014 highlight a growing national commitment to protecting young people in the digital age.",
            "Introduced by Sen. Julie Miville-Dech\u00eane,\u00a0Bill S-210\u00a0aims to prevent minors from accessing online pornography. The bill would require adult websites to implement\u00a0robust age verification systems\u00a0to ensure only adults can view sexually explicit content.",
            "The intent is simple: bring the same protections that exist in the physical world, like age restrictions on adult magazines, into the digital space. Miville-Dech\u00eane emphasized that children as young as 9 or 10 are being exposed to explicit content online, which she called a\u00a0public health issue. The bill passed in the Senate and recently cleared a second reading in the House of Commons, with support from several opposition parties.",
            "However, the bill has sparked a bit of a debate. Some critics argue mandatory age verification could compromise user privacy and freedom of expression. Some worry about the lack of clarity around how age checks would work \u2014 whether through digital IDs, facial recognition or third-party services \u2014 and how user data would be protected.",
            "Personally, I think these concerns can be worked through. Age-estimation technology has and is evolving very quickly and many developers understand the need to do this ethically, in a pro-privacy way, and in compliance with laws.",
            "Despite the controversy, the bill reflects a growing international trend. Countries like France and the U.K. have already implemented similar laws, and Canada is now following suit.",
            "In parallel, this week the\u00a0OPC\u00a0released its annual report, which, among other themes, places a strong focus on\u00a0children's privacy rights. The report warns that kids are especially vulnerable to data misuse, as they often don't understand how their personal information is collected or shared online.",
            "The OPC is advocating for: Stronger privacy laws\u00a0that treat children's data with heightened sensitivity; clearer rules for tech companies\u00a0on how to handle minors' information; and international cooperation\u00a0to ensure consistent protections across borders.",
            "The OPC also highlighted the risks posed by emerging technologies like artificial intelligence, which can collect and analyze vast amounts of personal data, often without users' full awareness or consent.",
            "Together, Bill S-210 and the OPC's report show Canada is taking meaningful steps to protect children online. Whether it's shielding them from harmful content or ensuring their data is handled responsibly, the message is clear: kids deserve a safer, more respectful digital environment.",
            "As these initiatives move forward, they'll need input from parents, educators, tech companies, and privacy experts to strike the right balance between protection and privacy.",
            "Kris Klein, CIPP/C, CIPM, FIP, is the managing director, Canada, for the IAPP.",
            "This article originally appeared in the Canada Dashboard Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/a-view-from-brussels-where-does-brussels-stand-on-sovereignty-",
        "title": "A view from Brussels: Where does Brussels stand on sovereignty?",
        "location": "Europe",
        "date_published": "5 June 2025",
        "keywords": ["Data Security", "Law & Regulation"],
        "description": "Where does Brussels stand on sovereignty? The short answer is: it is hard to tell. A slightly longer answer might be: between a rock and a hard place.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "Where does Brussels stand on sovereignty? The short answer is: it is hard to tell. A slightly longer answer might be: between a rock and a hard place.",
            "In any case, Europe must reconcile its ambitions, ways to achieve them and the marketplace and geopolitical realities at play.",
            "The definition of sovereignty in Europe changes depending who you ask. European Commission Executive Vice-President Henna Virkkunen, who is responsible for tech sovereignty, security and democracy, has yet to voice her view on defining \"sovereignty.\" The mission letter she received at the start of her mandate from President Ursula von der Leyen explains Europe's ambitions, stating, \"We must exploit our strengths in order to maintain or attain leadership in strategic technologies, to establish essential assets for technological sovereignty and resilience, and to foster commercialisation of deep tech innovation.\"",
            "During the previous Commission mandate, sovereignty came up in various ways, more prominently in the cybersecurity certification space, data localization, cloud and software public procurement, telecommunications and critical infrastructure supply chain, and at times with a confrontational posture toward third countries such as China and the U.S.",
            "Virkkunen is known for her pragmatic, industry-friendly and geopolitically sensible approach. If this appears as a quiet-after-the-storm from the last mandate, it may not equate to a drastic change of direction from a policy standpoint. Indeed, we do see signs of robust posturing on sovereignty coming from some corners of industry, European Parliament, Commission services and member states alike.",
            "Exhibit A: The Cybersecurity Act which lays the framework for certification \u2014 including for cloud services \u2014 is currently undergoing a revision, happening in part in the context of the simplification agenda. The Commission's public consultation asks about nontechnical factors \u2014 foreign ownership.",
            "The certification process has been complex and politicized since its inception. The draft EU Cloud Certification Scheme, first discussed in 2020 has yet to be finalized five years on, amidst a mix of political, technical and trade considerations to untangle.",
            "In the context of the CSA review, the Commission may look at how to leverage the review to override the challenges pertaining to the certification scheme, not fully excluding going more directly toward mandatory certification in public procurement which could then include sovereignty requirements.",
            "Exhibit B: Sovereignty is also coming into play at a time when connectivity is key to the EU policy and competitiveness objectives. During a DigitalEurope event this week, Nokia CEO Justin Hotard asked how Europe can go from targeted areas of technology leadership to creating many more leaders in Europe in the artificial intelligence super-cycle. He offered three priority areas, which notably do not all reflect a common position across the European telecommunications industry:",
            "Exhibit C: The European Parliament is putting forward proposals designed to boost European technological sovereignty and digital infrastructure, led by the Europe of Sovereign Nations Group.",
            "A draft report states the EU \"depends on third countries for over 80% of its digital products, services, infrastructure and intellectual property.\" It sees the shift in the geopolitical landscape as \"an opportunity for European products and services.\"",
            "The draft report calls on the Commission to propose legislation addressing risks from high-risk vendors from third countries and to relocate the hosting of sensitive data to Europe among others. The draft report was adopted by the Industry, Research and Energy committee this week and will be debated in Plenary session soon.",
            "Isabelle Roccia, CIPP/E, is the managing director, Europe, for the IAPP.",
            "This article originally appeared in the Europe Data Protection Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/daa-s-self-regulatory-principles-undergoing-review-with-eye-toward-leveraging-iba-data-with-ai",
        "title": "DAA's Self-Regulatory Principles undergoing review with eye toward leveraging IBA data with AI",
        "location": "",
        "date_published": "5 June 2025",
        "keywords": [
            "Advertising & Marketing",
            "AI Governance",
            "Customer Trust & Expectations",
            "Data Processing",
            "Frameworks & Standards",
            "Targeted Advertising"
        ],
        "description": "On Wednesday, the Digital Advertising Alliance announced it is launching a review with stakeholders to determine if new guidance is necessary regarding the collection and use of interest-based advertising data with the rise of artificial intelligence systems that can leverage such data.",
        "content": [
            "On Wednesday, the Digital Advertising Alliance announced it is launching a review with stakeholders to determine if new guidance is necessary regarding the collection and use of interest-based advertising data with the rise of artificial intelligence systems that can leverage such data.",
            "The potential guidance would look to address how the DAA's Self-Regulatory Principles would be applied by advertisers to their business practices in the context of leveraging AI while using IBA data.",
            "\"As the advertising industry increasingly looks to AI tools and systems, it's vital that industry codes of conduct reflect that reality to serve companies and their consumers,\"\u00a0DAA President and CEO Lou Mastria said in a statement. \"This review will look at the steps companies can take to ensure they are providing appropriate information and control to consumers around the collection and use of IBA data by those systems, thus enabling responsible and sustainable consumer engagement and growth.\"",
            "According to the DAA, key issues it will consider are identifying the relevant industry participants, understanding current and anticipated cases for IBA data by AI systems, reviewing consumer expectations around the collection of IBA data, and analyzing existing regulatory gaps and overlaps if it were to issue subsequent AI guidance. \u00a0",
            "The review will be managed by the DAA's Principles and Communications Committee, which will convene stakeholder meetings with trade associations, advertisers, publishers, advertising technology providers and ad agencies.",
            "\"While the committee's work is just starting, it will likely include a review of the current state of play around AI collection and use of IBA data in the industry, including any current or anticipated use cases, before considering the details of any potential guidance,\" Mastria said in an email to the IAPP. \"We don't want to get ahead of that process, so it's too early to share specific plans, outcomes or timelines.\"",
            "In addition to the DAA's Self-Regulatory Principles, Loeb & Loeb Partner Jessica Lee, CIPP/E, CIPP/US, CIPM, said the AI revolution \"presents unique challenges to complying with several privacy frameworks.\" She questioned what issues like consumer choice mean in an AI context and if it could involve \"machine unlearning,\" for example, to ensure consumers' rights are respected in a potential corrective action.",
            "Any forthcoming DAA guidance on the use of AI, Lee said, could prove similarly valuable to the DAA's Best Practices for the Application of the DAA Self-Regulatory Principles of Transparency and Control to Connected Devices.",
            "\"I see the value in similarly providing best practices for the application of the DAA's principles to the use of AI,\" Lee said in an email. \"The U.S. is unlikely to have its own AI Act anytime soon, so if history repeats itself, we may see a number of organizations providing best practices and other frameworks that companies can look to demonstrate that they are using AI responsibly and those will become the industry norm until regulation steps in and takes the reins.\"",
            "The multistakeholder approach to review the DAA's Self-Regulatory Principles with an eye toward how AI advancements will impact the adtech industry is a sound move, according to Greenberg Traurig Shareholder Darren Abernethy, CIPP/A, CIPP/C, CIPP/E, CIPP/G, CIPP/US, CIPM, CIPT, FIP, PLS. He said advancements in AI should not have necessitated this DAA review in and of themselves, however, responding to issues, such as regulators' enforcement efforts surrounding the use of generative AI that could \"materially mislead a consumer as to a product\u2019s characteristics\" may require further DAA guidance.",
            "\"I agree with the approach announced by the DAA of inviting industry stakeholders to participate in the process of analyzing the existing self-regulatory principles, looking at the myriad uses \u2014 and potential abuses \u2014 of AI in advertising, and making a determination as to whether AI-related principles or guidance would be appropriate for this industry body to publish for potential implementation,\" Abernethy said in comments to the IAPP. \"It is likely that any analysis will take into account regulators' statements and enforcement in relation to deceptive statements and practices around AI in marketing, and potentially clarify some guardrails there as to what constitutes (un)acceptable practices.\"",
            "Abernethy said advertisers' mood regarding leveraging IBA data with AI can be described as \"cautious enthusiasm\" based on general conversations with clients.",
            "\"There is a recognition that the incorporation of AI into data-driven marketing practices is likely to have some macro effect on the labor force and current job roles within the ad industry, but this is balanced against the excitement and anticipation of using AI/ML for optimizing and refining campaigns, generating unique content, inferring hyper advanced analytics insights, realizing time savings and personalization,\" Abernethy said. \"In relation to the impact on the use of IBA data, when used effectively, AI can help expand the insights derivable from both first- and third-party datasets, which creates more possibilities whether a company has begun shifting away from outsized reliance on third-party cookies or is doubling-down on it.\"",
            "While it is too early to make any pronouncements of what guidance may be produced through the DAA's review, Lee said one result may be increased transparency requirements on the part of advertisers, whether it comes in the form of revised privacy notices, disclosures on websites or contained within the ads themselves. However, she said any new disclosure requirements should not be duplicative on top of any existing disclosures already being made.",
            "\"My concern is always whether we are helping consumers or confusing them,\" Lee said. \"My hope is that any guidance that is created allows companies to build on what they have in place today,\u00a0and focuses on addressing any net-new risks created by the use of AI, rather than adding new obligations that are already addressed elsewhere.\"",
            "Alex LaCasse is a staff writer at the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/ftc-forum-highlights-the-road-to-improving-childrens-online-safety",
        "title": "FTC forum highlights the road to improving children's online safety",
        "location": "North America",
        "date_published": "5 June 2025",
        "keywords": [
            "Advertising & Marketing",
            "Government",
            "Technology",
            "AI Governance",
            "Children's Privacy",
            "Data Protection Obligations",
            "Data Subject Rights",
            "Enforcement",
            "Law & Regulation"
        ],
        "description": "While potential harms from children's online presence are becoming more clear, mitigation tactics are not as cut and dry. The U.S. Federal Trade Commission remains committed to searching for the answers to best navigate those harms and prevent children's sensitive data from being collected.",
        "content": [
            "While potential harms from children's online presence are becoming more clear, mitigation tactics are not as cut and dry. The U.S. Federal Trade Commission remains committed to searching for the answers to best navigate those harms and prevent children's sensitive data from being collected.",
            "Concerns surrounding potentially addictive algorithms, data collection practices and predatory acts have been a key focus for the FTC's online safety efforts. Updates to the Children's Online Privacy Protection Act Rule\u00a0in January and upcoming enforcement of the recently signed TAKE IT DOWN Act covering nonconsensual deepfake images represent the agency's initiatives to combat some of the issues.",
            "At the FTC's recent children's online safety forum, Chair Andrew Ferguson said, \"We can make the internet a safe place for kids \u2026 We can do this while ensuring that America remains the world's beacon of innovation, and that we win the (artificial intelligence) race against our foreign rivals.\"",
            "Ferguson called for a revision of COPPA that would strengthen age verification systems to prevent \"unfettered access to online services on nothing more than an unverified, self-reported birthdate.\"",
            "He noted Congress should pass privacy legislation to bolster parental rights and allow children's guardians to \"erase any trace left by their children on these platforms, at all levels of granularity, from individual messages to entire accounts.\"",
            "The FTC's updated COPPA Rule implemented additional parental controls, including \"a separate consent requirement for non-integral disclosures to third parties, such as for third-party advertising, enhances transparency and enables parents to make more deliberate and meaningful choices.\"",
            "Ferguson said legislation protecting children's privacy online should be \"aimed at assisting parents in the exercise of their right to exert meaningful control over their child's activities online and the data generated by those activities.\"",
            "Despite highlighting the importance of parental consent, Ferguson said the FTC cannot let its \"zeal to assist parents in protecting their children online lead us to regulate too heavily and too broadly.\"",
            "U.S. policymakers are also looking to bolster online protection for underage users with the Kids Online Safety Act, which was recently reintroduced to Congress after being voted out of the Senate and the House Committee on Energy and Commerce in the 118th Congress.",
            "U.S. Sen. Marsha Blackburn, R-Tenn., is working to advance the bill in the face of ongoing concern from House Republican leadership over potential free speech violations the KOSA may bring. Blackburn highlighted the importance of the KOSA, noting it is \"past time that we put in place protections for our kids in the virtual space, and it is past time that we give parents and kids the ability to protect themselves in the virtual space.\"",
            "A primary concern for regulators is the use of children's data for advertising purposes. While COPPA requires parental consent to collect the data of children under age 13 for targeted advertising purposes, schools are allowed to consent on behalf of parents.",
            "Georgetown University Communication, Culture, and Technology Program Associate Professor Meg Leta Jones raised red flags on education technology providers and their collection practices. She warned against insufficient transparency between schools and parents regarding whether edtech companies are receiving affirmative consent and how opt-out consent is being offered.",
            "The FTC adopted a policy statement in 2022 committing to strong edtech oversight and enforcement, noting that \"even as companies across the economy become more aggressive in harvesting and monetizing individuals\u2019 data, edtech providers cannot do the same.\" The 2023 enforcement action against edtech provider Edmodo was the first case under the FTC's policy statement, ordering prohibitions around collection and establishing appropriate data retention schedules following allegations of nonconsensual collection.",
            "In addition to ensuring edtech companies comply with data protection obligations, the FTC has focused its efforts on protecting underage users from harmful and addictive algorithms.",
            "\"The big thing is holding these platforms to account for the promises they make,\" FTC Chief Technology Officer Jake Denton said. \"We have to really scrutinize the promises they've made and make sure that they're held accountable.\"",
            "Denton added that the use by social platforms of individuals\u2019 behavioral data can incentivize advertising companies to collect substantial amounts of user data. \"The ad revenue is the treasure, and these kids are essentially the casualties, the collateral damage,\" he said.",
            "The FTC will begin enforcing the TAKE IT DOWN Act in May 2026, expanding the agency's enforcement of children's online safety requirements.",
            "The new law, endorsed by first lady Melania Trump, will require social platforms to delete nonconsensual explicit images including AI deepfakes. The first lady issued a statement through her office Director of Policy Sarah Gesiriech. Melanie Trump indicated the legislation reflects the White House's efforts to protect individuals from harmful content online.",
            "The Trump administration will continue to \"work together to develop tools to empower parents and youth, and we will lean on tech executives in the private sector to do their part,\" Gesiriech said while reading the first lady's statement.",
            "As the U.S. maintains its focus in establishing itself as a leader in technological advancement, Ferguson said the \"purpose of innovation in a just society is to promote the flourishing and success of ordinary families in that society. We must keep this purpose in mind as we consider which tradeoffs we are willing to make for technological progress.\"",
            "Lexie White is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/age-assurance-and-privacy-regulatory-trends-in-youth-online-protection",
        "title": "Age assurance and privacy: Regulatory trends in youth online protection",
        "location": "North America, Europe",
        "date_published": "5 June 2025",
        "keywords": [
            "Children's Privacy",
            "Frameworks & Standards",
            "Law & Regulation",
            "Regulatory Guidance",
            "Biometrics"
        ],
        "description": "Lawmakers and regulators around the world are intensifying their focus on protecting children and teenagers online. Although the goal of protecting the privacy and safety of young people online is widely shared, approaches to achieving it vary significantly across jurisdictions.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. \r",
            "Lawmakers and regulators around the world are intensifying their focus on protecting children and teenagers online. Although the goal of protecting the privacy and safety of young people online is widely shared, approaches to achieving it vary significantly across jurisdictions.",
            "A pivotal point of debate is whether online service providers should be explicitly required to implement age assurance mechanisms to estimate, verify or confirm users' ages, and then tailor users' online experiences accordingly.",
            "The primary regulatory requirements for age assurance in the U.K. are contained in the Age Appropriate Design Code 2021 and the Online Safety Act 2023.\u00a0",
            "Age assurance plays a significant role in keeping children and their personal information safe online. It describes approaches or tools that help estimate or assess a child's age and, therefore, allows services to be tailored to their needs or access to be restricted where required.",
            "The U.K. AADC \u2014 the first-ever statutory code of practice for protecting children's data \u2014 mandates a risk-based approach to age assurance, requiring services to effectively apply standards to children and youth, and establish or estimate age with a level of certainty commensurate on risk. It is regulated by the U.K. Information Commissioner's Office and mandates 15 design standards to protect children's data.",
            "The Online Safety Act, which is overseen by Ofcom, requires \"highly effective\" age assurance for services that display or publish pornographic or other harmful content ensuring children are not able to access it. The ICO and Ofcom have published extensive guidance on what constitutes effective age assurance and make clear that age assurance is meant to provide flexibility and to be tech neutral, reliable and fair.",
            "Ofcom guidance suggests methods such as photo ID matching, facial age estimation, mobile network operator age checks, credit card checks, digital identity services and email-based age estimation as capable of being highly effective. Methods such as self-declaration of age are not considered effective.",
            "Several EU member states have enacted laws explicitly requiring online service providers to implement age assurance mechanisms to protect minors from harmful or inappropriate content, typically defined to include pornographic, violent or otherwise developmentally inappropriate material.",
            "For example, Ireland's Online Safety and Media Regulation Act 2022 requires covered video-sharing platform services to implement effective age assurance measures to prevent children from accessing \"adult-only video content,\" which encompasses pornography and content depicting extreme or gratuitous violence.",
            "Ireland's Online Safety Code stipulates that age assurance mechanisms must be robust and that self-declaration of age is insufficient. Acceptable methods include age verification and age estimation technologies that reliably determine a user's age without solely relying on user-provided information. The code also underscores the importance of ensuring these measures are designed with privacy safeguards appropriate to the sensitivity of the data and the potential risks to minors.",
            "As another example, France's SREN law, to secure and regulate the digital space, seeks to promote digital safety by mandating age verification to access pornographic content and requiring parental consent for minors under 15 to create social media accounts.",
            "Interestingly, France's data protection authority, the Commission nationale de l'informatique et des libert\u00e9s, has issued detailed guidance emphasizing the need to balance youth protection with privacy and data minimization. It calls for age verification systems to be structured around principles such as proportionality, robustness and the use of independent third parties.",
            "The CNIL discourages methods that involve direct identity collection by content publishers or reliance on biometric data unless specifically authorized by law. Instead, it favors privacy-preserving models \u2014 such as cryptographic proofs of age \u2014 that enable users to verify eligibility without disclosing their identity.",
            "For high-risk contexts such as access to pornographic sites, the CNIL has advocated for a double-blind architecture, where one entity verifies age and another grants access, preventing either from linking identity to browsing behavior.",
            "While acknowledging that current solutions remain imperfect and potentially circumventable, the CNIL encourages the development and certification of third-party systems that offer verifiable assurances without compromising user anonymity.",
            "The CNIL's approach highlights the degree to which effective age assurance must be integrated with core data protection principles rather than treated as an exception to them.",
            "Numerous U.S. states have implemented, or are trying to implement, explicit age assurance requirements. One example is Texas' Securing Children Online Through Parental Empowerment Act, which requires covered digital service providers to collect and register the age of every individual attempting to create an account.",
            "Although federal courts have enjoined enforcement of several substantive provisions of the SCOPE Act on constitutional grounds, including those related to content filtering, advertising restrictions and age verification for accessing certain materials, the age registration provision in Section 509.051 has not expressly been enjoined. As a result, while much of the statute is currently unenforceable, covered digital service providers may still be obligated to comply with the age registration requirement, unless and until a court rules otherwise.",
            "Another example is Louisiana's Secure Online Child Interaction and Age Limitation Act, which would require covered social media companies to use commercially reasonable efforts to verify the age of Louisiana account holders with a level of certainty appropriate to the risk posed by their data practices. Although the law is scheduled to take effect 1 July, it is currently the subject of a constitutional challenge seeking to enjoin its enforcement.",
            "Yet another example is California's Age-Appropriate Design Code Act, modeled after the U.K. AADC. This statute would have required covered businesses to estimate the ages of users and tailor their online experiences accordingly, or else treat all users as minors. However, a federal court enjoined the statute in its entirety on First Amendment grounds. The California Attorney General has appealed the decision.",
            "The court's ruling reflects broader concerns in the U.S. about the potential chilling effects of age-gating requirements on free expression, as well as unresolved tensions between age assurance mandates and user privacy expectations.",
            "Separately, some U.S. states may indirectly impose age assurance obligations on companies deemed to have willfully disregarded or failed to appropriately investigate users' ages. For example, the California Consumer Privacy Act imposes prescriptive requirements on knowingly selling certain minors' personal information or sharing it for cross-context behavioral advertising, and provides that a \"business that willfully disregards the consumer's age shall be deemed to have had actual knowledge of the consumer's age.\"",
            "As another example, Maryland's Age-Appropriate Design Code Act seeks to impose various data privacy requirements on controllers that \"should have known\" the user is under age 18. Although the law is scheduled to take effect 1 Oct., it is currently the subject of a constitutional challenge seeking to enjoin its enforcement.",
            "These statutory frameworks highlight how age assurance can serve as a trigger for broader privacy obligations, particularly where minors' personal data is involved.",
            "A patchwork of additional laws in around 20 states targets online access to obscene material by minors and requires covered operators to verify the ages of users before permitting them access. The constitutionality of some of these laws is now before the U.S. Supreme Court, which is expected to clarify the permissible scope of state-mandated age verification under the First Amendment.",
            "The outcomes of these constitutional challenges may further define the boundaries of permissible age assurance requirements under more general U.S. online privacy and safety laws. Until those decisions are issued, online service providers operating nationally face legal uncertainty not only about what mechanisms are permissible, but also how to calibrate them to minimize unnecessary data collection.",
            "Canada has not yet adopted statutory age assurance requirements for online service providers. However, the Office of the Privacy Commissioner of Canada has taken an active role in shaping the policy conversation, most recently through a 2024 exploratory consultation on age assurance.",
            "In that document, the OPC recognizes that age assurance can support child safety by enabling more tailored protections or limiting access to harmful content, but stresses any such measures must be developed with strong privacy safeguards. The OPC discourages broad deployment of identity verification systems for general-use services, warning that such practices risk normalizing intrusive data collection.",
            "Instead, the OPC urges organizations to consider alternatives such as applying child-appropriate protections to all users or empowering parental controls at the device level. The consultation also highlights risks related to data minimization, function creep and unintended exclusion, particularly for youth without access to government-issued ID or for whom biometric systems may be less accurate.",
            "The OPC's guidance reflects a cautious stance: any move toward age assurance must be both demonstrably necessary and rigorously protective of users' privacy and dignity. While Canada does not currently require online service providers to implement age verification or estimation measures, the OPC has signaled that it may issue further guidance, and encourages organizations to take a proportionate, privacy-by-design approach where age assurance is contemplated.",
            "Across jurisdictions, age assurance remains a fast-evolving and contested area of regulation, but a common theme is emerging \u2014 organizations are expected to assess risks contextually and calibrate their practices accordingly.",
            "Services that may expose minors to elevated safety or privacy harms are increasingly expected to demonstrate that they have implemented meaningful safeguards, including age assurance mechanisms that are proportionate to those risks. At the same time, regulators are signaling that indiscriminate or overly invasive age checks \u2014 particularly those involving biometric or identity data \u2014 may create new privacy and equity concerns of their own.",
            "Online service providers must therefore balance competing imperatives: protecting young users, complying with divergent legal frameworks, and upholding privacy-by-design principles.",
            "Organizations grappling with these issues should be prepared to revisit their age assurance strategies, particularly considering mounting enforcement activity and the prospect of new technical standards emerging in the months ahead.",
            "Those responsible for trust and safety, product or privacy functions will need to navigate not only the legal complexity but also the practical and ethical tradeoffs posed by different age assurance approaches, particularly as enforcement increases and international standards begin to take shape.",
            "Jonathan Tam, CIPP/C, CIPP/US, is a tech and privacy partner in Baker McKenzie's San Francisco office and chair of the San Francisco Bar Association's Cybersecurity & Privacy Law Section. ",
            "Elizabeth Denham CBE is international advisor to Baker McKenzies's data and technology practice, 5 Rights trustee, and chair of the Jersey Data Protection Authority.\u00a0"
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-asia-pacific-region-future-bright-for-global-cbpr-forum",
        "title": "Notes from the Asia-Pacific Region: Future bright for Global CBPR Forum ",
        "location": "Asia",
        "date_published": "5 June 2025",
        "keywords": ["International Data Transfers"],
        "description": "Last week, a group of us found ourselves on the \"little red dot\" that is Singapore, host of the Global Cross-Border Privacy Rules Forum's spring workshop.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "Last week, a group of us found ourselves on the \"little red dot\" that is Singapore, host of the Global Cross-Border Privacy Rules Forum's spring workshop.",
            "In place of the usual Monday blues, we found ourselves blended in with the lush greenery of Sentosa Island, before easel boards and sketched ideas for the launch of the Global CBPR certification programs.",
            "Chair of the Global CBPR Forum and U.S. Department of Commerce Director of Global Data Policy Shannon Coe held the brush, painting us a picture of the world's first voluntary, scalable, accountability-based certification scheme that would aid businesses in navigating cross-border data flows and the increasingly difficult compliance standards for protection of personal data internationally.",
            "The crayon box of CBPR Forum participants comprises a spectrum of vibrancy from Australia, Canada, Japan, Mexico, the Philippines, the Republic of Korea, Singapore, Taiwan and the U.S. The United Kingdom, Bermuda, Dubai International Financial Centre and Mauritius have also been embossed as associates. Thailand and Nigeria have traced in similar intentions to join the forum this year.",
            "The workshop canvas outlined new shades to the color palette of program requirements, including those on sensitive personal data, children's privacy and breach notification. Frequency of certification, and third-party processing, were also penciled in as fresh hues for consideration.",
            "With an imprint of commitment toward interoperability and network effects adding to the gradient and vibrant rainbow of participants from both states and businesses alike, the future of the Global CBPR system appears bright, and very rosy, indeed.",
            "Charmian Aw, CIPP/A, CIPP/E, CIPP/US, CIPM, FIP, is a partner at Hogan Lovells.",
            "This article originally appeared in the Asia-Pacific Dashboard Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/japan-passes-innovation-focused-ai-governance-bill",
        "title": "Japan passes innovation-focused AI governance bill",
        "location": "Asia",
        "date_published": "4 June 2025",
        "keywords": ["AI Governance", "Law & Regulation"],
        "description": "Japan is the latest country to greenlight artificial intelligence governance regulation, landing on a statute that supports innovation and development while acknowledging potential risks.",
        "content": [
            "Japan is the latest country to greenlight artificial intelligence governance regulation, landing on a statute that supports innovation and development while acknowledging potential risks.",
            "The Act on the Promotion of Research and Development and the Utilization of AI-Related Technologies passed the House of Councilors 28 May after making it through in the House of Representatives in April. The bill makes clear the legislature wants to see AI thrive in the country, stating up front that \"artificial intelligence-related technologies are fundamental technologies for the development of Japan's economy and society.\" It calls its structure \"basic\" and relies on business cooperation and current laws to regulate the technology rather than inventing a new structure.",
            "The bill still needs to be submitted to the Cabinet and approved by the emperor for the law to be promulgated. The bill's text states Articles 3 and 4, which handles research and development principles to be created by the government, must take effect no more than three months after enactment.",
            "Japan's law is another example of how members of the Asia-Pacific region, including Singapore and South Korea, are taking a more relaxed approach to AI governance for now compared to the EU.",
            "The nation has led some international efforts to find common principles for managing AI, including the Hiroshima AI Process, which was a Japanese-led initiative that produced an international framework on life cycle governance.",
            "Thong said the bill arose out of a desire to promote economic development through AI, something the Liberal Democrat Party emphasized in a white paper outlining its position on the technology, alongside public concerns about AI.",
            "Both Japan and South Korea's AI laws center around government-supported research and development. This could lead to others in the APAC region following suit, according to Future of Privacy Forum Asia-Pacific Managing Director Josh Lee.",
            "\"Whether this trend actually plays out, however, will depend on whether such regulatory innovation is in fact seen as driving AI innovation and digital growth in Japan and South Korea,\" he said.",
            "The bill has no penalties but gives the government the ability to advise businesses if they are using AI in a harmful way and to provide guidance on how to fix the situation. The government is also empowered to disclose when malicious actors are identified and rely on current laws regarding personal information protection or copyright to pursue enforcement.",
            "This is not unusual in Japan, where administrative penalties are often the last resort, said Lee, pointing to enforcement of the country's Act on the Protection of Personal Information as an example.",
            "\"Policymakers may thus believe that this should be sufficient to ensure broad alignment with existing AI guidelines published by the Japanese Government and a manageable level of AI risk,\" he said.",
            "And governance folks should be mindful that while the bill does not have a rules-enforcement mechanism yet, it empowers the government to develop one down the road, noted APAC GATES Managing Director Seth Hays.",
            "\"This is intentional and meant to set guardrails for firms to be responsible and adhere to soft law guidance already available, but not deter investment,\" he said.",
            "The bill presses for transparency from operators on how AI is developed and used by operators, noting AI can \"lead to criminal use, leakage of personal information, copyright infringement, and other situations that harm the peace of people's lives and their rights and interests,\" if used improperly.",
            "Hays said other effects from the bill will occur downstream, such as the formation of an AI strategy headquarters. A task force headed up by Prime Minister Shigeru Ishiba will create guidelines for businesses and companies to follow.",
            "And friction over some risks, like copyright infringement cases, might arise through social consensus. Hays pointed to the country amending its copyright rules in 2019 to include an exception for data training. Regulators encouraged disputes between creators and technology companies to be resolved through measures like licensing.",
            "\"Similar expectations might be found where AI innovation and disruption occur,\" he said.",
            "Future legislation may touch on areas where consensus around AI harms have been growing, such as deepfakes and explicit content. The Japan Times reported the Lower House Cabinet Committee attached a provision to the bill calling for stronger protections against these uses.",
            "Caitlin Andrews is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/congressional-pushback-on-proposed-us-state-level-ai-law-moratorium-increases",
        "title": "Congressional pushback on proposed US state-level AI law moratorium increases",
        "location": "North America",
        "date_published": "4 June 2025",
        "keywords": ["AI Governance", "Law & Regulation"],
        "description": "The inclusion of a proposed 10-year moratorium on state-level artificial intelligence law enactment and enforcement in U.S. Congress' reconciliation bill enjoyed narrow but mostly uncontentious support when it passed the House of Representatives 22 May. There are growing indications the moratorium will not encounter the same smooth sailing in the Senate, which is scheduled to take up its reconciliation work over the coming weeks.",
        "content": [
            "The inclusion of a proposed 10-year moratorium on state-level artificial intelligence law enactment and enforcement in U.S. Congress' reconciliation bill enjoyed narrow but mostly uncontentious support when it passed the House of Representatives 22 May. There are growing indications the moratorium will not encounter the same smooth sailing in the Senate, which is scheduled to take up its reconciliation work over the coming weeks.",
            "The Senate's work is expected to begin this week with draft text submissions from committees, according to Politico. It would be a surprise to see draft text emerge from the Senate Committee on Commerce, Science and Transportation without the moratorium, which Committee Chair Ted Cruz, R-Texas, floated as a concept during an 8 May committee hearing on AI before the House included it in reconciliation.",
            "\"I think it\u2019s terrific policy,\u201d Cruz told Privacy Daily ahead of Senate consideration. \u201cIt\u2019s something I have vocally advocated. It will surely be challenged under the Byrd rule, and it\u2019s not clear it would survive that challenge in the Senate or not.\"",
            "The Byrd Rule allows the Senate Parliamentarian to remove reconciliation bill provisions deemed \"extraneous\" and having no connection to the proposed budget.",
            "House consideration of the AI provision was spurred by unity among the Republican majority. That will not be the case in the Senate, as bipartisan opposition is already surfacing and jeopardizing the moratorium's odds of making it into the final bill.",
            "The public opposition in the Senate first came from Republicans, with U.S. Sens. Marsha Blackburn, R-Tenn., and Josh Hawley, R-Mo., speaking out in the hours before the bill advanced out of the House. Blackburn was specific with her criticism, citing the negative impacts the moratorium would have on her constituents that are covered under Tennessee's AI law pertaining to proprietary rights over voice and likeness.",
            "\"We certainly know that in Tennessee we need those protections,\" Blackburn said during a 22 May Senate committee hearing. \"And until we pass something that is federally preemptive, we can\u2019t call for a moratorium.\"",
            "Sen. Mike Rounds, R-S.D., told Privacy Daily he supports the policies in the AI provision, however, he is \"not confident\" the moratorium will survive the Byrd Rule and \"if the parliamentarian says it doesn\u2019t fit, then it doesn\u2019t fit.\"",
            "More recently, Senate Democrats have begun chiming in on the viability of the moratorium.",
            "The reconciliation bill requires a simple majority vote for passage in the Senate, meaning the Democrats are at a disadvantage even with expected unanimity among the minority. However, Sen. Jeff Merkley, D-Ore., offered confidence about a straight removal of the moratorium in a recent NPR interview.",
            "\"I think that's likely to come out as well. And we see that when Democrats have used reconciliation, the reverse has occurred,\" Merkley said, referring to a Republican challenge and subsequent block of insulin caps in a 2022 Democratic-led reconciliation bill.",
            "Sen. Ed Markey, D-Mass., took to the Senate floor 3 June to specifically call attention to the moratorium, characterizing it as \"quite shocking\" and means to \"tie the hands\" of governors and state legislatures from addressing potential AI harms in the absence of federal intervention.",
            "\"This provision would be devastating for our country,\" Markey said, alluding to the harms unregulated AI could bring to children, the elderly and other vulnerable groups. \"This is a recipe to repeat the failures from the last decade. Our failure to hold Big Tech accountable for its abuses.\"",
            "Markey also raised how the states themselves do not want their legislative power removed. He called attention to recent bipartisan opposition letters from 40 state attorneys general and 260 state lawmakers.",
            "\"They've moved to protect young people online, secure consumer privacy and confront algorithmic bias,\" Markey said. \"This provision in the bill would erase this progress. It would roll back years of hard-won protections and prevent future action just when it's needed the most.\"",
            "And while the bill sits with the Senate, the potential House Republican fragmentation could impact its fate.",
            "The Senate's planned revisions to the bill will require it to return to the House for concurrence. Sending the bill back to the lower chamber with the moratorium intact may prove costly now as Rep. Marjorie Taylor Greene, R-Ga., indicated she will not approve AI provisions after admitting she had no knowledge of the moratorium's inclusion in the bill when she voted 22 May.",
            "\"I am adamantly OPPOSED to this and it is a violation of state rights and I would have voted NO if I had known this was in there,\" Greene said on the social platform X. \"We have no idea what AI will be capable of in the next 10 years and giving it free rein and tying states hands is potentially dangerous.\"",
            "House Democrats remain steadfast in their opposition and are not likely to suddenly support the moratorium in a concurrence vote. House Committee on Energy and Commerce Ranking Member Frank Pallone, D-N.J., took time at a 4 June Energy and Commerce subcommittee hearing to reemphasize Democrats' stance and support for Congress to begin \"learning from what states are doing.\"",
            "\"This provision, included in the budget reconciliation, is nothing more than a giant gift to Big Tech,\" Pallone said. \"Republicans want to ban the enforcement of all these state laws with absolutely no national bill ready to go to address these concerns.\u00a0Instead of enriching Big Tech, we should be working towards strong federal legislation to govern and guide the development of these powerful AI systems, which are rapidly being incorporated into more and more aspects of our everyday lives.\"",
            "Joe Duball is the news editor for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/south-korea-s-pipc-flexes-its-muscles-what-to-know-about-ai-model-deletion-cross-border-transfers-and-more",
        "title": "South Korea's PIPC flexes its muscles: What to know about AI model deletion, cross-border transfers and more",
        "location": "Asia",
        "date_published": "4 June 2025",
        "keywords": [
            "Advertising & Marketing",
            "AI Governance",
            "Data Protection Obligations",
            "Enforcement",
            "International Data Transfers",
            "Law & Regulation",
            "Risk Management"
        ],
        "description": "South Korea's Personal Information Protection Commission has forged a robust privacy regime that reflects distinct domestic priorities while increasingly shaping the global debate.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "South Korea's Personal Information Protection Commission has forged a robust privacy regime that reflects distinct domestic priorities while increasingly shaping the global debate.",
            "A string of headline investigations \u2014 from Kakao Pay, Apple, Alipay to Meta, AliExpress and the Chinese AI start-up DeepSeek \u2014 shows the regulator marrying meticulous guidance with muscular enforcement. Most strikingly, it has ordered the destruction of an artificial intelligence model trained on unlawfully obtained data, an approach that puts South Korea at the leading edge of global privacy practice.",
            "Model deletion becomes real. The 2021 Scatter Lab case confirmed the Personal Information Protection Act's reach into AI training data, but the January 2025 Kakao Pay decision brought teeth. After finding the wallet provider sent 40 million users' data to Alipay, which in turn built \"NSF scores\" for Apple Pay without notice or consent, the PIPC not only levied KRW8.3 billion in fines \u2014 it ordered Alipay to erase the algorithm itself.",
            "Why does that matter? Because model deletion eliminates the very asset an AI developer hopes to monetize. While the U.S. Federal Trade Commission has occasionally required \"algorithm disgorgement,\" European data-protection authorities have so far focused on underlying data. South Korea's precedent shows regulators can, and will, go after the crown jewels when a dataset is poisoned at the source.",
            "Cross-border transfers draw the quickest blood. ThePIPA generally demands granular user notice and consent, or equivalent safeguards, before sending personal data overseas. In July 2024, the PIPC fined AliExpress KRW1.97 billion for routing South Korean shoppers' details to third-country sellers without disclosure, then ordered a top-to-bottom rewrite of its privacy policy and account-deletion flow.",
            "The Kakao Pay case raised the stakes. The regulator labeled the China-bound transfer outright illegal and used that breach to justify model deletion. The takeaway for multinationals is unmistakable \u2014 sloppy transfer governance can cost both cash and code.",
            "A live probe underscores the point. DeepSeek, a ChatGPT-style app developed in China, voluntarily withdrew from South Korean app stores in February 2025 after investigators detected silent API calls to ByteDance servers. In April 2025, the PIPC issued a corrective order requiring DeepSeek to halt unlawful cross-border transfers, delete previously exported data, publish a Korean-language privacy policy, designate a domestic representative and undergo follow-up compliance audits.",
            "Consent remains king \u2014 especially for behavioral ads. Record 2022 fines against Google and Meta for opaque third-party tracking did not close the chapter. In November 2024, Meta absorbed another KRW21.6 billion penalty after the PIPC found it inferred religious and political views from on-platform activity to power its \"ad topics\" engine \u2014 again, without separate explicit consent.",
            "The message is clear: bundled or pre-ticked permissions will not satisfy South Korean standards, particularly when sensitive data or off-platform signals are involved.",
            "Taken together, these cases paint a regulator intent on rapid, precedent-setting action. Organizations that build or deploy AI in South Korea \u2014 or merely touch South Korean personal data \u2014 should internalize three lessons.",
            "Prove your data pedigree. The era of \"collect now, figure it out later\" is over. Maintain auditable records that tie each input dataset to a lawful basis and geographic transfer mechanism.",
            "Treat voluntary guidance as mandatory. The PIPC's AI Privacy Risk Management Model and six-part AI guidance series are officially non-binding, yet enforcement orders routinely reward documented alignment. Embedding those checklists early is cheaper than retrofitting them under subpoena.",
            "Engineer for reversibility. Whether the threat is data-subject deletion requests, a transfer suspension or a full model-erasure order, systems should include kill switches that let engineers trace and retract specific training rows \u2014 or, in extreme cases, consign an entire model to the shredder. Boards increasingly ask for proof this is possible; regulators already do.",
            "South Korea hosts the Global Privacy Assembly in Seoul in October, just as its AI Basic Act and the EU AI Act edge toward implementation. Expect the PIPC to showcase its model-deletion precedent and court allies for coordinated cross-border probes.",
            "For privacy professionals, the upshot is opportunity as much as risk. South Korea offers a live test bed for governance techniques \u2014 pre-launch adequacy reviews, sandboxing, rich transparency dashboards \u2014 that could influence standards worldwide. Those who adapt first will not only avoid fines, they'll help write the next chapter of global AI and privacy law.",
            "Kyoungsic Min, AIGP, CIPP/E, is privacy counsel and Asia regional lead at VeraSafe. He is a dual-qualified lawyer in Korea and Washington, D.C., specializing in privacy, data protection and AI governance."
        ]
    },
    {
        "url": "https://iapp.org/news/a/el-reglamento-de-seguridad-privada-de-la-ley-n-21-659-y-la-protecci-n-de-datos-personales-en-chile",
        "title": "El Reglamento de Seguridad Privada de la Ley N.\u00ba 21.659 y la protecci\u00f3n de datos personales-en-chile",
        "location": "",
        "date_published": "3 June 2025",
        "keywords": ["Data Protection Obligations"],
        "description": "Nota del editor: la IAPP mantiene una posici\u00f3n neutral en cuestiones de pol\u00edticas. Publicamos art\u00edculos de opini\u00f3n y an\u00e1lisis de colaboradores para ofrecer a nuestros miembros una amplia gama de puntos de vista en nuestros \u00e1mbitos.",
        "content": [
            "Nota del editor: la IAPP mantiene una posici\u00f3n neutral en cuestiones de pol\u00edticas. Publicamos art\u00edculos de opini\u00f3n y an\u00e1lisis de colaboradores para ofrecer a nuestros miembros una amplia gama de puntos de vista en nuestros \u00e1mbitos.",
            "Con fecha 27 de mayo del 2025, se public\u00f3 el Reglamento de Seguridad Privada de la Ley N\u00ba 21.659, entendi\u00e9ndose por tales \"el conjunto de actividades o medidas de car\u00e1cter preventivas, coadyuvantes y complementarias de la seguridad p\u00fablica, destinadas a la protecci\u00f3n a la protecci\u00f3n de personas, bienes y procesos productivos, desarrolladas en un \u00e1rea determinada y realizadas por personas naturales o jur\u00eddicas de derecho privado\" (Art. 1\u00ba).",
            "Entre las actividades de seguridad privada, indica que se encuentra la vigilancia, protecci\u00f3n y seguridad de establecimientos; la instalaci\u00f3n y mantenimiento de aparatos, equipos, dispositivos, componentes tecnol\u00f3gicos y sistemas de seguridad electr\u00f3nica conectados a centrales receptoras de alarmas, entre otros indicados en el art\u00edculo 2\u00ba del citado reglamento.",
            "Uno de los aspectos interesante del reglamento, es la obligaci\u00f3n a las instituciones p\u00fablicas o privadas llamadas a ejercer seguridad privada deben a saber \"respetar y proteger los derechos humanos y libertades fundamentales, especialmente si se trata de personas en situaci\u00f3n de vulnerabilidad, ni\u00f1os, ni\u00f1as o adolescentes y personas en situaci\u00f3n de discapacidad\" (art. 3\u00ba, numeral 5). Esto se vincula directamente con un enfoque en que, diversas actividades que reconoce el citado reglamento implican actividades de tratamiento de datos personales y por ende, puede implicar un riesgo a los derechos y libertades de titulares de datos personales, por lo que, tiene una aplicaci\u00f3n directa la Ley N\u00ba 19.628 sobre protecci\u00f3n a la vida privada, modifica por la reciente publicada Ley N\u00ba 21.719 que crea la Agencia de Protecci\u00f3n de Datos Personales y que entra en vigencia el 1\u00ba de diciembre del 2026.",
            "Unido a ello, el reglamento refuerza la necesidad de transmitir, por parte de los sujetos obligados, de datos personales y placas de patentes \u00fanicas de veh\u00edculos que ingresen a recintos, previo requerimiento del Ministerio P\u00fablico o las polic\u00edas, se\u00f1alando inclusive que cuando es realizada de buena fe, no se considera a infracciones de confidencialidad (inciso final del art. 5\u00ba del reglamento), debiendo evaluarse a la luz de los principios de la normativa sobre protecci\u00f3n de datos personales. Finalmente, indica, que existir\u00e1 una plataforma que ser\u00e1 administrada por la Subsecretar\u00eda de Prevenci\u00f3n del Delito, que estar\u00e1 interconectada con las autoridades fiscalizadoras, y servir\u00e1 de apoyo en los procedimientos administrativos y en materia de seguridad privada (art. 115\u00ba).",
            "Analizando en detalle la regulaci\u00f3n, se\u00f1ala que los vigilantes privados, \"aquellos que realizan labores de protecci\u00f3n a personas y bienes dentro de un recinto o \u00e1rea determinada para portar armas, credencial y uniforme\" (art. 26\u00ba del Reglamento), como los guardas privados, es decir, es personal auxiliar que apoya las funciones de vigilancia y protecci\u00f3n (sin porte de armas) deber\u00e1n contar con un curso sobre privacidad y protecci\u00f3n de datos personales con \u00e9nfasis en la adecuada protecci\u00f3n, es decir, el comprender su rol en cuanto pueden capturar datos personales en situaciones propias de su labor, deben tener conocimientos asociados a las obligaciones que tendr\u00e1n en su rol de encargado del tratamiento, por ejemplo. Agrega, adem\u00e1s, que estos cursos ser\u00e1n aprobados por la Subsecretar\u00eda de Prevenci\u00f3n del Delito en cuanto y que los capacitadores de dichos cursos deber\u00e1n contar con requisitos espec\u00edficos, entre ellos (art 107\u00ba).",
            "En el mismo sentido y analizando algunas actividades propias de la seguridad privada, uno puede a primera vista identificar algunos usos de datos personales, tales como por ejemplo:\u00a0",
            "La vigilancia, protecci\u00f3n y seguridad de establecimientos; e instalaci\u00f3n y mantenimiento de aparatos, equipos, dispositivos, componentes tecnol\u00f3gicos y sistemas de seguridad electr\u00f3nica. (Art. 2 N\u00ba 4)",
            "",
            "Para todas estas actividades en que se capturan datos personales y por ende, se realizan diversos usos de acuerdos a los procesos se\u00f1alados en la reglamentaci\u00f3n, es indispensable, tener en consideraci\u00f3n, algunos principios descritos en la regulaci\u00f3n de datos personales, tales como la licitud del tratamiento - en que nos encontraremos usualmente ante la ejecuci\u00f3n o el cumplimiento de una\u00a0 obligaci\u00f3n legal- finalidad, proporcionalidad y seguridad de los datos (ej. en los controles de accesos y c\u00e1maras en establecimientos).",
            "Adem\u00e1s de ello, se debe permitir el total ejercicio de los derechos a los titulares de datos personales (acceso, rectificaci\u00f3n, supresi\u00f3n u oposici\u00f3n; portabilidad), salvo que exista alguna limitaci\u00f3n legal (ej. art. 23\u00ba de la Ley N\u00ba 21.719 que modifica la Ley N\u00ba 19.628).",
            "Asimismo, en los casos en que existan por ejemplo \u201ctratamiento que implique un observaci\u00f3n o monitoreo sistem\u00e1tico de una zona de acceso p\u00fablico\u201d (art. 15\u00ba ter Ley N\u00ba 21.719, letra b), deber\u00e1 realizarse evaluaciones de impacto, considerando aspectos tales como la descripci\u00f3n de las operaciones de tratamiento, la finalidad, la evaluaci\u00f3n de la necesidad y la proporcionalidad con respecto a la finalidad, y por ende, los riesgos y sus medidas de mitigaci\u00f3n.",
            "Tambi\u00e9n, nos indica que las instituciones bancarias y financieras de cualquier naturaleza y las empresas de apoyo al giro bancario deben incorporar un sistema de filmaci\u00f3n que les puedan generar registro de alta resoluci\u00f3n que permitan la grabaci\u00f3n de im\u00e1genes n\u00edtidas con indicaci\u00f3n de la hora, d\u00eda, mes y a\u00f1o de captura, permaneciendo en funcionamiento continuo. ",
            "Estas c\u00e1maras deber\u00e1n quedar ocultas o debidamente resguardadas de posibles intrusiones. Se mantendr\u00e1n almacenados por un per\u00edodo de al menos, 120 d\u00edas, salvo que la grabaci\u00f3n sea susceptible de formar parte de una causa o investigaci\u00f3n judicial o proceso administrativo, que deber\u00e1 almacenarse mientras dure la tramitaci\u00f3n corresponde; a su vez, aquellos que no fuesen requeridos por el Ministerio P\u00fablico, deben ser destruidos despu\u00e9s de 2 a\u00f1os desde su captura. (art. 46\u00ba numeral 4), por lo que est\u00e1 actividad tambi\u00e9n debiese cumplir principios tales como la proporcionalidad, finalidad y transparencia e informaci\u00f3n, sin que ello afecte el objetivo de la gesti\u00f3n.",
            "Como conclusi\u00f3n, el Reglamento dictado avanza en incluir, desde el enfoque de la protecci\u00f3n de datos personales, varios aspectos ya se\u00f1alados. Se hace especial consideraci\u00f3n a las actividades de tratamiento de datos personales propias de la seguridad privada, en donde el principio de licitud, proporcionalidad y medidas de seguridad, asociada a la transparencia e informaci\u00f3n, cobran relevancia en casos determinados y por ende, se vuelven aspectos cr\u00edticos para el cumplimiento de la normativa, especialmente para aquellas organizaciones que definan los medios y fines en el tratamiento; y por ende, en cuanto su rol como responsable, o tambi\u00e9n como proveedores de instituciones financieras o bancarias obligadas a implementar medidas de seguridad privada, actuando como encargados del tratamiento, por ejemplo; en que sin lugar a duda, instrumentos un Modelo de Prevenci\u00f3n de Infracciones y por ende, un registro de las actividades de tratamiento como un delegado de protecci\u00f3n de datos personales en la organizaci\u00f3n que lidere la implementaci\u00f3n de estas medidas organizativas y t\u00e9cnicas, ser\u00e1n tremendos diferenciadores al momento de implementar la Ley.Juan Pablo Gonz\u00e1lez Guti\u00e9rrez es abogado, Director de HD Group en materia de protecci\u00f3n de datos personales y ciberseguridad; y acad\u00e9mico."
        ]
    },
    {
        "url": "https://iapp.org/news/a/europe-must-drastically-adapt-enforcement-strategy-against-big-tech",
        "title": "Europe must drastically adapt enforcement strategy against Big Tech ",
        "location": "",
        "date_published": "3 June 2025",
        "keywords": ["Enforcement", "Law & Regulation"],
        "description": "It is possible to rein in Big Tech, but it will require us to get off our high horse on the superiority of EU legislation implementing human rights and European values.",
        "content": [
            "It is possible to rein in Big Tech, but it will require us to get off our high horse on the superiority of EU legislation implementing human rights and European values.",
            "There is extensive discussion in the media about whether the EU can win the battle to enforce its digital legislation against American Big Tech. The White House supports Big Tech by threatening additional tariffs if the EU does not stop fining tech companies for violating European digital regulations, including the Digital Markets Act. Earlier, U.S. Vice President JD Vance warned the U.S. could reconsider support for NATO if the EU continues to enforce against American social media.\u00a0",
            "The European Commission is now caught between a rock and a hard place. If it backs down on enforcement, it loses any meaningful regulatory leverage. This allows Big Tech to continue to operate in a manner that was the reason for enacting this legislation in the first place. If the Commission holds, it will aggravate the trade war.",
            "If the options are stated as binary as this, the Commission is involved in a zero-sum game, in which you either win or lose. Going along means EU legislation becomes just a bargaining chip, to be traded away against more urgent interests.",
            "I think it is possible to reign in Big Tech and at the same time avoid aggravating the trade war. This requires acknowledging that Big Tech has a point when it labels the USD30 billion in fines imposed as \"tariffs.\" This is because the EU and the U.S. have a diametrically opposite way of regulating. This has been creating frictions since the beginning of the digital era, dating back to well before the Trump administrations. Once you understand the differences, you also see why Europe's enforcement is counterproductive.\u00a0",
            "European legislation is based on fundamental rights and rooted in the precautionary principle: we try to prevent harm. In the U.S., regulation is harm-based, the market is left to its own devices, and the legislature only intervenes when new services cause unacceptable harm to consumers or businesses \u2014 that is, after damage has occurred.\u00a0",
            "Data protection is a simple example. Under the EU General Data Protection Regulation, it is a fundamental right of individuals and a key principle that personal data must be adequately secured to prevent damage when data is lost. In the U.S., there is no such general obligation to secure personal data. In 2007, when some massive data security breaches made American headlines, about all states introduced a legal obligation to report data breaches to victims.\u00a0  ",
            "As a European, I found it difficult to accept that American law did not have a general data security obligation. By now I have moved to thinking, maybe the American system is not all-encompassing, but often very effective. In my experience, the security of companies in the U.S. is on average better than in the EU. My point: there is no right or wrong, the systems are just different.\u00a0",
            "If legislators want to prevent harm from new technologies, they must first predict the harmful impact these technologies may have on individuals and society. Because this is notoriously difficult, the EU is introducing so-called risk-based legislation that obliges companies to regulate themselves through adequate risk management. This is reflected in the GDPR requirement to carry out a data protection impact assessment in the event of high-risk processing. In a similar vein, the EU Artificial Intelligence Act requires a conformity assessment to be carried out in the event of high-risk AI systems.\u00a0",
            "Though all valid legislation when you want to prevent harm, it is also very process driven. The rules prescribe how companies must organize themselves. American companies experience this legislation as extremely patronizing, because they prescribe how they should organize their risk management, instead of being punished if they do not do their job properly. Resistance to this type of regulation is also growing in the EU, because companies perceive it as an excessive administrative burden and therefore as \"over-regulation.\"\u00a0",
            "Where there are many process rules, you also get enforcement of violation of process rules. For supervisory authorities, it is easier to fine a company for not having a process document \u2014 such as a DPIA \u2014 than it is to prove that a practice itself is harmful.\u00a0\u00a0",
            "Where the EU has few tech companies of its own, most enforcement is against Big Tech and for lack of process documents. Big Tech experiences this as imposing a tax on U.S. companies doing business in the EU, hence the labelling as a \"tariff.\"\u00a0\u00a0",
            "Case in point is the 290 million euro fine imposed on Uber by the Netherlanddata protection authority, Autoriteit Persoonsgegevens, for the lack of having the EU standard contractual clauses in place for data transfers to the U.S., while at the time of fining, both data exporter and data importer where directly subject to the GDPR, the contract was no longer mandatory and there had been no impact on the privacy of citizens whatsoever. It would have been much more relevant if the DPA issued a decision on the merits, for example, whether Uber complies with data minimization requirements when sending all EU data to the U.S. in the first place.\u00a0\u00a0",
            "Europe is proud of its legislation, which often has effect far outside its territory \u2014 coined the \"Brussels effect.\" The mantra is that our laws are embodying fundamental human rights and values. This seemed to be true for the AI Act, when an executive order by then-U.S. President Joe Biden regulated AI on similar principles. When President Donald Trump annulled this executive order when he took office, it was condemned in the EU as a threat to EU fundamental rights and values, but is that really the case?\u00a0\u00a0",
            "The fact is AI is already regulated in the U.S. by existing legislation, such as laws on unfair commercial practices, data protection, discrimination and consumer credit. American supervisory authoritiesalready have the authority and use it to tackle AI if it gives discriminatory results, or if algorithms are trained on unlawfully collected data. While the EU was still debating the AI Act, U.S. regulatorswere already issuing orders to destroy unfair algorithms and the data used for their training. The U.S. Federal Trade Commission even started an enforcement sweep \"Operation AI Comply.\"\u00a0\u00a0",
            "Telling the U.S. that it does not have laws that implement fundamental rights and values is therefore not correct. The underlying values are essentially the same: no cheating, misleading or discrimination, no harm and no unfair competition. It is the way in which we regulate that differs.\u00a0",
            "Does this justify our moral superiority? Not as far as I'm concerned. So yes, I understand where Big Tech is coming from. At the same time, they try to use their understandable irritations to evade underlying material rules that really matter, and this is happening on both sides of the Atlantic.\u00a0",
            "In terms of enforcement against Big Tech, this means that we have to selectively pick our fights on topics which Big Tech will lose in the court of public opinion, also in the U.S. Remember, these days, politics are conducted as much via social media as by democratic institutions.\u00a0\u00a0",
            "This means that we must focus on practices that are unfair, harmful or discriminatory. These practices are also prohibited and enforced in the U.S.\u00a0",
            "In May, for example, Google agreed to pay USD1.4 billion in a settlement with the state of Texas over allegations it violated user privacy. Google allegedly continued to collect users' location and facial recognition data without consent. Previously, Google settled for USD391.5 million with 40 other U.S. states.\u00a0",
            "In the EU, too, public opinion is needed to mobilize our governments, businesses and citizens to vote with their feet. By switching to alternative digital platforms that comply with European rules \u2014 not only as a user, but also through advertising budgets. This hits where it hurts: in terms of numbers of users and advertising revenue. Therefore, we need to focus on stopping dark patterns that encourage users to give unwanted consent and addictive design techniques to keep visitors glued for longer.\u00a0",
            "The real power of Elon Musk and Mark Zuckerberg further lies in their ability to configure their recommender systems directing content to specific groups of users. A bizarre example to illustrate: when an X (formerly tweet) of Joe Biden attracted more attention than an X of Elon Musk, he rallied a team of roughly 80 engineers to reconfigure X's algorithm so his tweets would be more widely viewed than Biden's. This manipulation of X's algorithm also pushed his endorsements of German far-right party Alternative for Deutschland into millions of people's feeds right before the German elections.\u00a0\u00a0",
            "There was also great outrage in the EU about Zuckerberg's announcement to abolish Facebook's fact-checkers for content moderation. This is a total red herring. Content moderation is at the end of the pipeline. The real concern is in Zuckerberg's announcement that Meta will dial back on censorship of political content. This means the recommender system will unnaturally amplify far-right content as it triggers outrage and gets more attention \u2014 eyeballs.\u00a0\u00a0",
            "Meta knows very well that the real issue is the unnatural amplification by its recommender system and not the content moderation. Its leaked internal research is clear: \"Our algorithms exploit the human brain's attraction to divisiveness.\"\u00a0",
            "\"We are never going to remove everything harmful from a communications medium used by so many, but we can at least do the best we can to stop magnifying harmful content by giving it unnatural distribution.\"\u00a0\u00a0",
            "Enforcing against these harmful practices is quite possible under current EU law. This requires close cooperation between relevant supervisory authorities tasked with enforcement of data protection, AI, consumer protection and competition, as well as the establishment of joint technical teams that can properly understand and assess algorithms.\u00a0",
            "No country in the EU can do this alone. It requires coordination \u2014 not only within the EU, but preferably together with Australia, Canada and the U.K.\u00a0",
            "My appeal to the European Parliament is to stop submitting proposals for new regulations to curb Big Tech. We have all the laws we need, just like the U.S.\u00a0\u00a0",
            "My appeal to all European supervisory authorities is to stop enforcing process rules. This not only causes irritation for Big Tech, but also for our own companies. We must use the freed-up capacity to combat unfair practices by Big Tech, such as those that are also prohibited in the U.S. and where we will win in the court of public opinion.\u00a0\u00a0",
            "I call upon the EU media to widely cover the unfair practices and flag equivalent alternatives for EU compliant digital services.\u00a0",
            "And I call upon citizens and organizations to vote with their feet by moving to other digital platforms and redirecting advertising budgets.\u00a0\u00a0",
            "Lokke Moerel is Professor Global ICT Law at Tilburg University. This op-ed reflects the personal opinion of the author only.",
            ""
        ]
    },
    {
        "url": "https://iapp.org/news/a/los-medios-de-defensa-bajo-los-nuevos-marcos-de-protecci-n-de-datos-personales-y-transparencia-en-mexico",
        "title": "Los medios de defensa bajo los nuevos marcos de protecci\u00f3n de datos personales y transparencia en M\u00e9xico",
        "location": "North America",
        "date_published": "3 June 2025",
        "keywords": ["Law & Regulation"],
        "description": "",
        "content": [
            "",
            "El 20 de diciembre de 2024 fue publicado en el Diario Oficial de la Federaci\u00f3n el decreto mediante el cual se modific\u00f3 el art\u00edculo 6\u00ba constitucional, que extingui\u00f3 al \u00f3rgano constitucional aut\u00f3nomo encargado de garantizar la protecci\u00f3n y cumplimiento del derecho de acceso a la informaci\u00f3n p\u00fablica y a la protecci\u00f3n de datos personales en M\u00e9xico: el Instituto Nacional de Transparencia, Acceso a la Informaci\u00f3n y Protecci\u00f3n de Datos Personales.",
            "Respecto de esta reforma constitucional, el 20 de marzo de 2025 fue publicado en el DOF el decreto mediante el cual se expidi\u00f3 la nueva (i) Ley General de Transparencia y Acceso a la Informaci\u00f3n P\u00fablica, (ii) la Ley General de Protecci\u00f3n de Datos Personales en Posesi\u00f3n de Sujetos Obligados y (iii) la Ley Federal de Protecci\u00f3n de Datos Personales en Posesi\u00f3n de los Particulares.",
            "Con lo que se materializ\u00f3 la extinci\u00f3n del INAI (cuyo dise\u00f1o institucional llev\u00f3 m\u00e1s de 20 a\u00f1os de construcci\u00f3n), para ser \u201creemplazado\u201d\u2014en t\u00e9rminos generales\u2014por la Secretar\u00eda de Anticorrupci\u00f3n y Buen Gobierno, lo que ha generado un debate p\u00fablico por la posible influencia del Ejecutivo.",
            "En este art\u00edculo, comentaremos el nuevo escenario de los medios de impugnaci\u00f3n en materia de transparencia y protecci\u00f3n de datos personales derivado de estas reformas y especialmente analizaremos el fortalecimiento de los medios constitucionales de defensa como lo es el juicio de amparo.",
            "Antes de las reformas, el INAI era un OCA especializado en materia de transparencia, acceso a la informaci\u00f3n y protecci\u00f3n de datos personales (para el sector p\u00fablico y privado), colegiado, con plena autonom\u00eda t\u00e9cnica, y ten\u00eda facultades para resolver recursos de revisi\u00f3n y de inconformidad, sin embargo, la ley anterior no defin\u00eda un medio espec\u00edfico para controvertir las resoluciones del INAI, lo que gener\u00f3 diversos problemas desde la perspectiva de litigio. No obstante, el INAI al ser un OCA, estaba facultada para promover \u201cacciones de inconstitucionalidad\u201d y \u201ccontroversias constitucionales\u201d, lo que se pierde con las nuevas reformas.",
            "Y bien, a partir de las reformas antes se\u00f1aladas, se dota de facultades en materia de transparencia, acceso a la informaci\u00f3n p\u00fablica y protecci\u00f3n de datos personales (para el sector p\u00fablico y privado) a la Secretar\u00eda de Anticorrupci\u00f3n, quien ejercer\u00e1 sus facultades a trav\u00e9s de unidades administrativas (en lo que toca a la materia de datos personales, para sectores p\u00fablico y privado) y del \u00f3rgano administrativo desconcentrado denominado \u201cTransparencia para el Pueblo\u201d (en materia de transparencia, acceso a la informaci\u00f3n p\u00fablica\u2014dotado de autonom\u00eda t\u00e9cnica y operativa).",
            "Es decir, la Secretar\u00eda de Anticorrupci\u00f3n (incluyendo sus unidades administrativas o el \u00f3rgano desconcentrado) forma parte de la Administraci\u00f3n P\u00fablica Federal centralizada y est\u00e1 estructuralmente subordinada a la presidenta de la rep\u00fablica, por lo que, en teor\u00eda, deber\u00eda ser procedente el juicio de nulidad como medio de defensa contra los actos que \u00e9stas emitan.",
            "Como es de notar, la diferencia entre un OCA y una autoridad de la Administraci\u00f3n P\u00fablica Federal es grande y el cambio en la naturaleza de la autoridad no debe pasar desapercibido. Sin duda, una de las diferencias m\u00e1s relevantes es la no subordinaci\u00f3n de un OCA frente al poder ejecutivo. De hecho, en la doctrina los OCA han sido reconocidos como un \u201ccuarto poder\u201d (Cfr. Camarena Gonz\u00e1lez, Rodrigo, et al. \u201cDeconstruir para reconstruir: un an\u00e1lisis de los \u00f3rganos constitucionales aut\u00f3nomos en M\u00e9xico\u201d. Bolet\u00edn mexicano de derecho comparado, 2021, M\u00e9xico), otra diferencia importante son los medios de defensa que son procedentes contra los actos que emiten, lo que se aborda enseguida.",
            "Las leyes secundarias en materia de transparencia, acceso a la informaci\u00f3n y datos personales fortalecen\u2014extra\u00f1amente\u2014la procedencia del amparo como medio de defensa, incluyendo otras modificaciones relevantes a los medios de impugnaci\u00f3n, tal como se observa a continuaci\u00f3n:",
            "a.) Creaci\u00f3n de juzgados y tribunales especializados. El decreto de 20 de marzo de 2025 crea nuevos juzgados y tribunales especializados en materia de acceso a la informaci\u00f3n p\u00fablica y protecci\u00f3n de datos personales. Lo anterior es una buena noticia, puesto que esto permitir\u00eda que las decisiones del Poder Judicial Federal sean m\u00e1s efectivas.",
            "No obstante, la reforma trae consigo un defecto en el acceso a la justicia, en efecto, el transitorio Vig\u00e9simo establece la suspensi\u00f3n de plazos y t\u00e9rminos en juicios de amparo por 180 d\u00edas naturales, lo que se traduce en la paralizaci\u00f3n de la justicia federal en materia de acceso a la informaci\u00f3n p\u00fablica y protecci\u00f3n de datos personales por un m\u00ednimo de 6 meses.",
            "b.) Modificaciones a la LGTAI. Respecto a la LGTAI, ante la respuesta insatisfactoria de una solicitud de acceso a la informaci\u00f3n, una persona puede interponer un recurso de revisi\u00f3n ante la autoridad garante en la que present\u00f3 la solicitud o su unidad de transparencia. En contra de la resoluci\u00f3n del recurso de revisi\u00f3n procede el recurso de inconformidad o el juicio de amparo, igual que en la ley abrogada.",
            "Sin embargo, adem\u00e1s de aumentar las causales de reserva de informaci\u00f3n, la nueva ley limita la procedencia del recurso de inconformidad, considerando que solo proceden contra resoluciones vinculadas a solicitudes de informaci\u00f3n concernientes a recursos p\u00fablicos federales, cuando anteriormente permit\u00eda controvertir ante el INAI la ratificaci\u00f3n de una negativa de acceso a la informaci\u00f3n de los \u00f3rganos de transparencia locales.",
            "c.) Modificaciones a la LGPDPSO. En esta ley, tanto la Secretar\u00eda de Anticorrupci\u00f3n como los \u00f3rganos de transparencia locales est\u00e1n facultados para conocer de los recursos de revisi\u00f3n que se interpongan en contra de la respuesta de una solicitud de ejercicio de los derechos ARCO.",
            "A diferencia de la ley anterior (del mismo nombre), la nueva ley elimina la posibilidad de interponer un recurso de inconformidad en contra de las resoluciones de los recursos de revisi\u00f3n que emitan los \u00f3rganos de transparencia locales, lo que elimina un medio de impugnaci\u00f3n relevante que resolv\u00eda el INAI, previo a acudir al Poder Judicial Federal. Tambi\u00e9n se elimin\u00f3 la facultad de atracci\u00f3n de recursos de revisi\u00f3n que guardaran importancia y trascendencia, que ten\u00eda el INAI. Lo anterior deja como \u00fanico medio de impugnaci\u00f3n en contra de la resoluci\u00f3n de un recurso de revisi\u00f3n el juicio de amparo.",
            "d.) Modificaciones a la LFPDPPP. Finalmente, la expedici\u00f3n de la nueva ley marca la diferencia m\u00e1s clara en cuanto a medios de impugnaci\u00f3n analizada. A pesar de que la ley abrogada establec\u00eda c\u00f3mo medio de impugnaci\u00f3n expreso en contra de los actos del entonces INAI el juicio de nulidad, la Segunda Sala de la Suprema Corte de Justicia de la Naci\u00f3n determin\u00f3 que la v\u00eda para controvertir sus decisiones deb\u00eda ser mediante el juicio de amparo, por tratarse de actos emitidos por un OCA \u2013en lugar de una autoridad de la Administraci\u00f3n P\u00fablica Federal (ver Jurisprudencia: 2a./J. 31/2020 (10a.).",
            "Ahora, la LFPDPPP establece espec\u00edficamente que los particulares podr\u00e1n promover juicio de amparo contra las resoluciones de la Secretar\u00eda de Anticorrupci\u00f3n, generando mayor certeza jur\u00eddica en cuanto a los medios de defensa que son procedentes.",
            "Tal como se pudo observar durante la existencia del INAI, coexist\u00edan distintas alternativas de impugnaci\u00f3n, dependiendo de la materia y de la ley aplicable, como lo son el recurso de revisi\u00f3n, el recurso de inconformidad, el juicio de nulidad y el juicio de amparo. Ahora, pr\u00e1cticamente, despu\u00e9s del recurso de revisi\u00f3n, la v\u00eda para impugnar las resoluciones de las autoridades en materia de acceso a la informaci\u00f3n y protecci\u00f3n de datos personales ser\u00e1 el juicio de amparo, lo que podr\u00eda interpretarse como un mecanismo de protecci\u00f3n reforzado.",
            "Sin embargo, tambi\u00e9n elimina y restringe recursos que previamente conoc\u00eda y resolv\u00eda el INAI, con ello, la nueva configuraci\u00f3n puede generar problemas pr\u00e1cticos de aplicaci\u00f3n, en t\u00e9rminos del n\u00famero de autoridades o la saturaci\u00f3n de los nuevos juzgados especializados en la materia, as\u00ed como la utilizaci\u00f3n del verbo \u201cpodr\u00e1n\u201d, abre espacio interpretativo que podr\u00eda permitir tomar en cuenta como procedente el juicio de nulidad, lo que muestra una clara falta de t\u00e9cnica legislativa.",
            "Bajo el marco actual, se judicializan los medios de defensa y se fortalece el juicio de amparo como medio de impugnaci\u00f3n, lo que permite reforzar la protecci\u00f3n de los derechos previstos en el art\u00edculo 6\u00ba constitucional. No obstante, suprime v\u00edas de impugnaci\u00f3n adicionales y genera riesgos como la saturaci\u00f3n de los nuevos \u00f3rganos jurisdiccionales y la inseguridad jur\u00eddica derivada de la deficiente t\u00e9cnica legislativa.",
            "El tiempo confirmar\u00e1 si el juicio de amparo servir\u00e1 como refugio para la protecci\u00f3n de derechos humanos en materia de transparencia, acceso a la informaci\u00f3n y la protecci\u00f3n de datos personales, en el contexto de un dise\u00f1o institucional centralizado.",
            "Sebasti\u00e1n Lerdo de Tejada Desoche es un abogado mexicano especializado en litigio administrativo y constitucional en Creel Garc\u00eda-Cuellar Aiza y Enr\u00edquez.",
            "Dafne M\u00e9ndez, CIPP/E, es abogada especializada en privacidad, propiedad intelectual y tecnolog\u00eda."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notas-de-la-iapp-am-rica-latina-3-junio-2025",
        "title": "Notas de la IAPP Am\u00e9rica Latina, 3 junio 2025",
        "location": "Central America, North America, South America",
        "date_published": "3 June 2025",
        "keywords": [
            "AI Governance",
            "Community & Careers",
            "Law & Regulation",
            "Data Security"
        ],
        "description": "Como lo vemos todos los d\u00edas vivimos en un contexto de acelerada transformaci\u00f3n digital, la protecci\u00f3n de los datos personales se ha convertido en una prioridad en Am\u00e9rica Latina. Gobiernos, autoridades reguladoras, empresas y sociedad civil reconocen cada vez m\u00e1s la necesidad de construir marcos normativos s\u00f3lidos que respondan a los desaf\u00edos del entorno digital y, al mismo tiempo, salvaguarden los derechos fundamentales.",
        "content": [
            "Como lo vemos todos los d\u00edas vivimos en un contexto de acelerada transformaci\u00f3n digital, la protecci\u00f3n de los datos personales se ha convertido en una prioridad en Am\u00e9rica Latina. Gobiernos, autoridades reguladoras, empresas y sociedad civil reconocen cada vez m\u00e1s la necesidad de construir marcos normativos s\u00f3lidos que respondan a los desaf\u00edos del entorno digital y, al mismo tiempo, salvaguarden los derechos fundamentales.",
            "En esta edici\u00f3n se reunen diversas notas y an\u00e1lisis de expertos que versan sobre la evoluci\u00f3n del panorama normativo en la regi\u00f3n. Como se ha podido apreciar a lo largo del del a\u00f1o y anteriormente, pa\u00edses como M\u00e9xico, Argentina, Colombia, Chile, Per\u00fa, est\u00e1n reformando sus legislaciones, fortaleciendo (o no) los mecanismos de supervisi\u00f3n y participando activamente en los debates globales sobre derechos digitales, inteligencia artificial, neuroderechos, transferencia internacional de datos, derechos de menores, etc.",
            "Los art\u00edculos y notas presentados en esta edici\u00f3n abordan reformas legales, desaf\u00edos institucionales y, por supuesto, el impacto de est\u00e1ndares internacionales (sobre todo los Europeos) en las pr\u00e1cticas locales. Tambi\u00e9n analizan el papel de las autoridades de protecci\u00f3n de datos y c\u00f3mo pueden coadyuvar en el cumplimiento de la normativa y el respeto al derecho fundamental a la protecci\u00f3n de datos personales. Estos contenidos reflejan la diversidad de enfoques y la urgencia com\u00fan de consolidar la privacidad y la protecci\u00f3n de datos personales como pilar de la gobernanza y la innovaci\u00f3n en Am\u00e9rica Latina.",
            "Si tienes algo que compartir con otros colegas de la regi\u00f3n o buscas obtener retroalimentaci\u00f3n o ideas respecto a un desaf\u00edo/problema en particular, no dudes en contactarnos y hacernos llegar tus contribuciones. Con esta publicaci\u00f3n se busca informar, generar di\u00e1logo y promover el desarrollo de una cultura de protecci\u00f3n de datos basada en la \u00e9tica, la transparencia, la rendici\u00f3n de cuentas y el respeto por la dignidad humana en toda la regi\u00f3n.",
            "Rosa Mar\u00eda Franco, CIPP/US, es country leader para M\u00e9xico de la IAPP "
        ]
    },
    {
        "url": "https://iapp.org/news/a/novedades-legislativas-en-argentina-sobre-protecci-n-de-datos-personales-e-inteligencia-artificial",
        "title": "Novedades legislativas en Argentina sobre protecci\u00f3n de datos personales e inteligencia artificial",
        "location": "South America",
        "date_published": "3 June 2025",
        "keywords": ["AI Governance"],
        "description": "Nota del editor: la IAPP mantiene una posici\u00f3n neutral en cuestiones de pol\u00edticas. Publicamos art\u00edculos de opini\u00f3n y an\u00e1lisis de colaboradores para ofrecer a nuestros miembros una amplia gama de puntos de vista en nuestros \u00e1mbitos.",
        "content": [
            "Nota del editor: la IAPP mantiene una posici\u00f3n neutral en cuestiones de pol\u00edticas. Publicamos art\u00edculos de opini\u00f3n y an\u00e1lisis de colaboradores para ofrecer a nuestros miembros una amplia gama de puntos de vista en nuestros \u00e1mbitos.",
            "Durante los \u00faltimos meses, se han presentado ante el Congreso de la Naci\u00f3n Argentina diversos proyectos de ley orientados a actualizar el r\u00e9gimen de protecci\u00f3n de datos personales y a establecer una regulaci\u00f3n general de la inteligencia artificial. Estas iniciativas reflejan un creciente inter\u00e9s por armonizar el desarrollo tecnol\u00f3gico con la tutela efectiva de los derechos fundamentales.",
            "Actualizaci\u00f3n de la Ley de Protecci\u00f3n de Datos Personales",
            "Dos proyectos recientemente ingresados al Congreso \u2014uno impulsado por el diputado Pablo Carro y otro por el senador Mart\u00edn Do\u00f1ate\u2014 proponen una reforma integral de la Ley 25.326, que este a\u00f1o cumple 25 a\u00f1os desde su sanci\u00f3n. Ambos textos se inspiran en el anteproyecto elaborado por la Agencia de Acceso a la Informaci\u00f3n P\u00fablica (AAIP), que perdi\u00f3 estado parlamentario al terminar el a\u00f1o 2024, y procuran alinear la normativa argentina con est\u00e1ndares internacionales, como el Reglamento General de Protecci\u00f3n de Datos (RGPD) de la Uni\u00f3n Europea y la Ley General de Protecci\u00f3n de Datos de Brasil.",
            "Entre sus principales novedades respecto de la ley actual, los proyectos incorporan nuevos principios, como la responsabilidad proactiva y demostrada, la privacidad por defecto y por dise\u00f1o, y nuevos derechos para los titulares, como la portabilidad y la oposici\u00f3n a decisiones automatizadas que produzcan efectos jur\u00eddicos o afecten al titular negativamente. Tambi\u00e9n introducen otros institutos modernos en materia de protecci\u00f3n de datos, como la figura del delegado de protecci\u00f3n de datos y la notificaci\u00f3n de incidentes de seguridad, y se elimina el deber actualmente vigente de registrar bases de datos ante la autoridad de control.",
            "Una diferencia significativa entre el proyecto del senador Do\u00f1ate y aquellos presentados por el diputado Caro y la AAIP, es la necesidad de que la designaci\u00f3n del titular de la autoridad de protecci\u00f3n de datos personales sea aprobada por el Senado. Esta cl\u00e1usula podr\u00eda contribuir a reforzar la autonom\u00eda e independencia de la autoridad, en consonancia con los est\u00e1ndares internacionales en la materia.",
            "Si bien la actualizaci\u00f3n de la Ley de Protecci\u00f3n de Datos Personales resulta necesaria, no puede dejarse de lado el an\u00e1lisis del impacto regulatorio para el sector privado de ciertos puntos de los proyectos. Por ejemplo, el plazo improrrogable de diez d\u00edas h\u00e1biles para satisfacer los derechos ejercidos por los titulares puede resultar de dif\u00edcil cumplimiento. Mantenerlo condenar\u00eda a gran parte de las solicitudes a no ser respondidas en plazo. Establecer plazos m\u00e1s razonables, alineados con el RGPD, traer\u00eda mayor seguridad jur\u00eddica para los responsables, pero tambi\u00e9n para los titulares, que tendr\u00edan m\u00e1s probabilidades de recibir una respuesta a sus solicitudes sin la necesidad de recurrir a la v\u00eda judicial o administrativa.\u00a0",
            "Asimismo, ser\u00eda deseable que los proyectos legislativos contemplen un r\u00e9gimen diferenciado de cumplimiento para las micro, peque\u00f1as y medianas empresas, que preserve los principios fundamentales de la protecci\u00f3n de datos personales en beneficio de los titulares, sin incrementar innecesariamente la carga administrativa asociada a su implementaci\u00f3n y cumplimiento. Dados los recursos limitados con los que cuentan las MiPyMEs, resulta clave que los proyectos reforma no imponga exigencias desproporcionadas que puedan comprometer su competitividad o desalentar la innovaci\u00f3n. Las MiPyMEs son un pilar central de la econom\u00eda nacional, por lo que el ajustarse a su realidad contribuir\u00e1 tanto al fortalecimiento del ecosistema empresarial como a una aplicaci\u00f3n m\u00e1s efectiva de los derechos de los titulares de datos personales en el pa\u00eds. Este debate no es meramente local, ya que recientemente la Comisi\u00f3n Europea ha planteado preocupaciones similares respecto de las peque\u00f1as y medianas empresas de cara al RGPD.",
            "En este sentido, la Uni\u00f3n Europea est\u00e1 trabajando en una\u00a0reforma del RGPD para PyMEs\u00a0con el fin de reducir su carga administrativa, manteniendo intactos los principios de protecci\u00f3n de datos.",
            "Otra oportunidad de mejora desde la perspectiva del sector privado es el exiguo plazo de adecuaci\u00f3n que proponen los proyectos. Mientras que el RGPD y la Ley de Brasil establecieron un per\u00edodo de dos a\u00f1os para que las empresas se adapten a los cambios legislativos, los textos comentados solamente brindan seis meses.",
            "Regulaci\u00f3n del reconocimiento facial con fines de seguridad p\u00fablica",
            "En paralelo, el diputado Mart\u00edn Yeza present\u00f3 un proyecto de ley que establece un marco normativo para el uso de tecnolog\u00edas de reconocimiento facial con fines de seguridad ciudadana, prevenci\u00f3n del delito e investigaci\u00f3n judicial.",
            "El texto busca compatibilizar el uso de estas tecnolog\u00edas con el respeto por los derechos fundamentales, en particular el derecho a la protecci\u00f3n de los datos personales. As\u00ed establece que los sistemas de reconocimiento facial, que vayan a ser usados con fines de seguridad, deber\u00e1n estar sujetos, antes de su implementaci\u00f3n, a una evaluaci\u00f3n de impacto y a un proceso de autorizaci\u00f3n por parte de la AAIP. Adem\u00e1s, proh\u00edbe expresamente ciertos usos como la vigilancia masiva o el seguimiento rutinario de personas no sospechadas de haber cometido delitos, en l\u00ednea con los est\u00e1ndares de la Ley Europea de Inteligencia Artificial. Tambi\u00e9n prev\u00e9 la obligaci\u00f3n de una supervisi\u00f3n humana de las identificaciones autom\u00e1ticas que realicen estos sistemas.",
            "Aunque algunas disposiciones del proyecto pueden interpretarse como contrarias al principio de neutralidad tecnol\u00f3gica \u2014por ejemplo, al imponer la utilizaci\u00f3n de tecnolog\u00edas de registro distribuido como garant\u00eda de privacidad\u2014, se valora positivamente la incorporaci\u00f3n de conceptos vinculados a las Tecnolog\u00edas de Mejora de la Privacidad como mecanismo para salvaguardar los datos personales tratados por estas herramientas.",
            "En su presentaci\u00f3n del proyecto, el diputado Yeza destac\u00f3 la necesidad de contar con un marco legal adecuado para regular estos sistemas, tomando como antecedente el caso del Sistema de Reconocimiento Facial de Pr\u00f3fugos de la Ciudad Aut\u00f3noma de Buenos Aires, suspendido por el Poder Judicial local en 2022 a ra\u00edz de diversas presentaciones de organizaciones de la sociedad civil.",
            "Hacia una regulaci\u00f3n integral de la IA",
            "Tambi\u00e9n se han presentado en el Congreso propuestas para una regulaci\u00f3n general de la inteligencia artificial. Los proyectos de la Senadora Silvia Sapag y del Diputado Daniel Goll\u00e1n reconocen como principios rectores la transparencia, la explicabilidad, la seguridad y la protecci\u00f3n de los datos personales. Ambos textos clasifican los sistemas de IA en categor\u00edas de acuerdo con su nivel de riesgo: sistemas prohibidos, sistemas de alto riesgo y otras categor\u00edas con cargas regulatorias progresivamente menores. Entre los casos de uso prohibidos en ambos proyectos se encuentran la manipulaci\u00f3n del comportamiento que pueda inducir a una persona a poner en peligro su salud o seguridad y el establecimiento de sistemas de calificaci\u00f3n social que provoquen tratos perjudiciales desfavorables o negaci\u00f3n de derechos a los interesados. En la propuesta del Diputado Goll\u00e1n, esta \u00faltima prohibici\u00f3n se encuentra circunscripta al \u00e1mbito gubernamental.",
            "El proyecto de Goll\u00e1n tambi\u00e9n se distingue por habilitar a la autoridad de control a promover el desarrollo de sandboxes regulatorios para sistemas de IA, es decir, entornos controlados de prueba previos a su comercializaci\u00f3n. La participaci\u00f3n en estos espacios ser\u00eda limitada en el tiempo y estar\u00eda sujeta a una supervisi\u00f3n constante por parte de la autoridad de control.",
            "Reflexiones finales",
            "Estas propuestas legislativas se enmarcan en una tendencia creciente, tanto en Argentina como en la regi\u00f3n, orientada a regular las tecnolog\u00edas emergentes\u2014particularmente la inteligencia artificial\u2014y su interacci\u00f3n con derechos fundamentales como la protecci\u00f3n de los datos personales. Este contexto habilita discusiones particularmente relevantes: \u00bfes conveniente avanzar en regulaciones espec\u00edficas para determinados casos de uso, como propone el proyecto del diputado Yeza respecto del reconocimiento facial con fines de seguridad p\u00fablica? \u00bfO resulta m\u00e1s adecuado priorizar una regulaci\u00f3n general y transversal sobre protecci\u00f3n de datos personales o inteligencia artificial?",
            "Otro punto para debatir a ra\u00edz de los proyectos relevados es si la Ley Europea de Inteligencia Artificial es una gu\u00eda apropiada para adoptar como modelo en la actualidad. Diversos actores europeos han se\u00f1alado la necesidad de revisar el contenido de esta norma, dado que fue elaborada de forma previa a la masificaci\u00f3n en el uso de inteligencia artificial generativa, y por ende no regula correctamente esta tecnolog\u00eda.",
            "Estos interrogantes, entre muchos otros, ponen de manifiesto la necesidad urgente de construir consensos amplios. No solo en el plano pol\u00edtico, sino tambi\u00e9n entre los actores clave del ecosistema tecnol\u00f3gico: organismos reguladores, empresas, c\u00e1maras empresariales, academia, usuarios y organizaciones de la sociedad civil. Solo a trav\u00e9s de estos acuerdos ser\u00e1 posible avanzar hacia un marco normativo capaz de equilibrar de manera eficaz los derechos y libertades individuales con la seguridad, el desarrollo econ\u00f3mico y la innovaci\u00f3n tecnol\u00f3gica.",
            "Gabriela Szlak\u00a0es abogada, socia directora de la firma Lerman & Szlak y copresidente del cap\u00edtulo KnowledgeNet de la IAPP en Buenos Aires."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-iapp-canada-keeping-watch-on-federal-provincial-developments",
        "title": "Notes from the IAPP Canada: Keeping watch on federal, provincial developments ",
        "location": "North America",
        "date_published": "30 May 2025",
        "keywords": [
            "AI Governance",
            "Community & Careers",
            "Data Security",
            "Enforcement",
            "Surveillance",
            "Employment Privacy"
        ],
        "description": "What a week in Canada \u2014 King Charles came to town and opened the new Parliament.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "What a week in Canada \u2014 King Charles came to town and opened the new Parliament.",
            "It is not clear what lies ahead federally. Privacy was not mentioned in the Speech from the Throne, but there is now a Minister of Artificial Intelligence and Digital Innovation, Evan Solomon, and presumably, the Cross-Border Privacy Rules consultation is continuing.",
            "At the provincial level, there is action. Quebec's data protection authority, the Commission d'acc\u00e8s a l'information du Qu\u00e9bec, is ceasing publication of organizations that have reported data breaches. The CAI said the goal is to: minimize the risk of harm to citizens; avoid revealing the existence of vulnerabilities or cybersecurity issues; avoid interfering with the organization's management of the incident; and preserve the exercise of the commission's supervisory functions and powers, including ongoing and future investigations.",
            "In a recent decision, the CAI concluded that the collection of video surveillance images over a 14-day period inside Crane Supply delivery trucks passed the necessity and proportionality tests, but the company has not sufficiently minimized collection.\u00a0The CAI ordered the company to limit capturing to seconds before and after an incident, or failing that, to stop capturing the interior of the vehicles; stop rolling after the engine is shut down; and destroy footage unrelated to any incidents.",
            "The CAI also recommended the company revise its dash cam policy to reflect that images captured can only be accessed in the event of an incident.",
            "By the way, the IAPP Canada Privacy Symposium 2025 made it to the CAI's news page.",
            "In Ontario, the newly enacted Digital Platform Workers' Rights Act, 2022 is coming into force on Canada Day, 1 July. As the gig economy continues to expand, the legislation provides additional access rights to gig workers on digital platforms \u2014 for example, Uber drivers \u2014 such as: how compensation is calculated; if and how tips and other gratuities are collected; recurring pay period and pay days as established by the operator; factors used to determine whether work assignments are offered to workers and a description of how those factors are applied; and information about the performance rating system, where applicable.",
            "Gig workers' right to information is not new. It is already provided for under current privacy laws such as the Personal Information Protection and Electronic Documents Act. What may be a new obligation is that new types of information are prescribed. And there are fines \u2014 up to CAD500,000. For organizations that are still handling access requests manually, it may be worthwhile for the chief privacy officer to ask for a budget to implement self-service data subject access and gig worker requests. For organizations that already have automation in place, a change request may be in order.",
            "As privacy and data rights continue to evolve, organizations should keep an eye on both federal and provincial developments.",
            "Florence So, AIGP, is counsel at nNovation.",
            "This article originally appeared in the Canada Dashboard Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/vietnam-s-data-protection-laws-the-basics-and-beyond",
        "title": "Vietnam's data protection laws: The basics and beyond ",
        "location": "Asia",
        "date_published": "29 May 2025",
        "keywords": [
            "Data Protection Obligations",
            "Data Security",
            "Frameworks & Standards",
            "Law & Regulation",
            "AI Governance"
        ],
        "description": "Vietnam recently drew international attention because of its strategic position in the China-U.S. trade war and U.S. President Donald Trump's tariff policies. At the same time, the country is rapidly undergoing major internal changes from the top down, with mergers of major ministries and municipalities nationwide.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "Vietnam recently drew international attention because of its strategic position in the China-U.S. trade war and U.S. President Donald Trump's tariff policies. At the same time, the country is rapidly undergoing major internal changes from the top down, with mergers of major ministries and municipalities nationwide.",
            "With President L\u01b0\u01a1ng C\u01b0\u1eddng's military and public security background, the government is moving at an unprecedentedly fast pace to develop and enact new regulations. Several big data protection regulations have passed in the last three years, and at least five more are anticipated in 2025.",
            "Both multinational companies and local privacy experts are scrambling to keep up and make sure they're following all the new regulations.",
            "Navigating Vietnam's data protection legal framework is no easy task since the requirements are scattered in several legislations. Vietnam did not have its own comprehensive set of rules to regulate data protection until 2023's Decree 13 on Personal Data Protection. Given its status as a government's decree, previous National Assembly's laws still prevail over it, causing some confusion and inconsistency in the framework.",
            "Unlike the EU and many other countries, Vietnam does not have any independent data protection authority. Instead, the power to enforce data protection laws is currently divided among different authorities via different legislations.",
            "The Personal Data Protection Decree, 2024 Data Law and 2018 Cybersecurity Law are enforced by the Department of Cybersecurity and High-tech Crime Prevention within the Ministry of Public Security and the Ministry of National Defense.",
            "The 2023 Law on Protection of Consumer's Rights is enforced by the Vietnam Competition Commission, governed by the Ministry of Industry and Trade.",
            "The Ministry of Information and Communications enforces the Information Technology Law and the Law on Cyber Information Security. However, given the recent merger of the MIC into the Ministry of Science and Technology, the MIC's functions \u2014 with the exception of data protection \u2014 have been absorbed by the latter. The data protection requirements under these laws now have no clear enforcement authority.",
            "Other industry-specific regulations include the Law on Telecommunications under the purview of the Vietnam Telecommunications Authority and bank secrecy standards overseen by the State Bank of Vietnam.",
            "Local lawmakers have consistently maintained a good habit of referencing other countries' data regulations, usually those of the European Union, China, the U.S., and South Korea. Global concepts and requirements have been adopted, but never fully since lawmakers need to ensure harmony with domestic settings. The finished products give a telltale international vibe with various local twists.",
            "IT Law, 2006, and LOCIS, 2015. These laws were enacted before the EU General Data Protection Regulation set a global standard in 2018, so nothing locally unique should be expected here. Issued in 2006, the IT Law marked the country's first milestone in data protection with two provisions dealing with collection of personal information in cyberspace, bases for processing and information subject's rights.",
            "About 10 years after the IT Law, the LOCIS was issued to address various growing issues, including more detailed requirements for personal information processing and protection of information systems.",
            "Together these two laws provide a general framework for Vietnam to regulate \"personal information,\" laying the foundation for later data protection rules. However, these pre-GDPR laws should be rendered obsolete soon given the upcoming changes. The MIC \u2014 the main enforcer of both laws \u2014 has effectively ceased to exist;and the MPS recently announced its plan to merge the Cybersecurity Law and LOCIS into one unifying law, solidifying its position as the key cybersecurity regulator.",
            "2018 Cybersecurity Law. Enacted just one year after China's Cybersecurity law rolled out, Vietnam's Cybersecurity Law shares several similarities with its counterpart. Banned activities \u2014 such as posting fake news or content harmful to the national security \u2014 critical infrastructure, data localization, data protection and data breaches are covered under this law.",
            "The law is well known for its broad data localization requirement, applicable to virtually any domestic or foreign online service providers operating in Vietnam. Needless to say, this requirement was unwelcome to almost all foreign businesses in Vietnam, causing various industries and even the U.S. to heavily oppose it. The local government later conceded and issued a decree to narrow the requirement's scope to offshore providers of 10 specific types of service that meet a list of conditions.",
            "PDPD, 2023. As Vietnam's first comprehensive personal data regulation, the PDPD substantively mirrors the GDPR, with highly similar data protection principles, classification of relevant entities \u2014 controller, processor and third party \u2014 and data subject rights.",
            "However, the PDPD contains numerous local elements. Unlike the GDPR, the PDPD does not recognize the \"legitimate interest\" basis, but sets out limited legal bases for processing data without consent. It also stipulates troublesome consent requirements, namely granularity \u2014 data subjects can consent to specific uses of their data separately \u2014 potential partial consent by data subjects and a long list of mandatory information to be provided to the data subjects when obtaining consent.",
            "Most notably, many international companies struggle with the PDPD's unclear rules for preparing impact assessments of data processing and overseas data transfer, which are required to be submitted to the Department of Cybersecurity and High-tech Crime Prevention. The PDPD also introduces a new mechanism for data breach notification, which covers not only actual data breaches, but any violation of any requirements under the PDPD. The department serves as both the receiving authority of the data breach notifications, as well as the main enforcer of the PDPD.",
            "Consumer Law, 2023. A few months after Vietnam's government issued the PDPD, the National Assembly issued the Consumer Law, introducing a protection regime for \"consumer information\" \u2014 a term that covers not only a consumer's personal information, but also nonpersonal information related to the transactions between consumers and traders.",
            "What can be troublesome and confusing is that the Consumer Law contains numerous divergences from the PDPD, including:",
            "The Consumer Law generally requires companies to apply the same personal data protection standards to nonpersonal data. It ranks higher than the PDPD in the legislative hierarchy, so it prevails over the decree in case of inconsistencies. This makes it challenging for consumer-facing companies, as they struggle to ensure compliance with both regulations simultaneously.",
            "The scope of the Consumer Law is excessively broad. While the California Consumer Privacy Act's scope and applicability are limited to businesses meeting high thresholds, the Consumer Law applies to all and any companies that trade with consumers. This warrants local enforcers, notably the VCC and MOIT, the power to enforce the law against offshore service providers.",
            "Data Law, 2024. This is Vietnam's most recent law on data protection; its legislation process must be one of the fastest in the past five years. It only took nine months \u2014 from February to November 2024 \u2014 to be enacted, marking the country's major shift in quickly making laws.",
            "The Data Law appears to be Vietnam's direct and prompt reaction to the enactment of the EU Data Act. However, the Data Law and the EU Data Act differ in focus. Vietnam's lawcovers both personal and nonpersonal data and emphasizes the protection of national security, and interests and rules for unregulated services and products.",
            "Particularly, it: recognizes ownership of data, for the first time ever; provides the basis for the government to impose a licensing mechanism when it comes to transferring \"core data\" and \"important data\" across Vietnam's borders' justifies governments' data requests in cases of emergency, threat to national security, etc.; and lays out the groundwork to regulate data-related services, namely data floor, data intermediary and data synthesis and analysis \u2014 artificial intelligence-related.",
            "The law deals with basic issues of data protection, including access, collection, quality, classification, storage, management, publication and encryption. The Data Law's requirements are generic, as they are drafted in a way that gives the government and MPS ample flexibility to elaborate in subsequent guiding instruments. The law's key regulators are the MPS and MND.",
            "Since last year, Vietnam lawmakers have been actively finalizing various data protection laws and are determined to meet the deadlines of their ambitious schedule.",
            "Three regulations are on track to be enacted by the end of June.",
            "Law on Personal Data Protection. The MPS has long planned for the development of the PDPL, which will serve as an upgraded version of the PDPD, and more importantly, takes precedence over existing legislation as a law. Compared to the PDPD, the PDPL introduces more requirements for certain sectors and a basis to apply GDPR-like fines against offenders.",
            "Law on Digital Technology Industry. The DTI Law, for the first time, provides general rules for artificial intelligence and AI-related subjects. The law will also contain several requirements on digital data.",
            "Guiding Instruments for Data Law. This law simply lays out a foundation without elaborating any substantive requirements. The MPS contemplated such elaborations to be provided under several decrees, notably a decree to guide important and core data issues, a decree to regulate data-related products and services, and a prime minister's decision on core and important data. All these instruments are set to be issued soon to meet the Data Law's effective date of 1 July 2025.",
            "Alex Do, CIPP/E, is an IPTech executive cum patent coordinator at BMVN International, in alliance with Baker McKenzie Vietnam."
        ]
    },
    {
        "url": "https://iapp.org/news/a/gdpr-matchup-australias-privacy-act-1988",
        "title": "GDPR matchup: Australia's Privacy Act 1988",
        "location": "Europe, Oceania",
        "date_published": "29 May 2025",
        "keywords": ["Law & Regulation"],
        "description": "The Privacy Act (cth) is the foundation of Australia's national privacy regulatory regime. Its genesis lies in the 1980 guidelines issued by the Organisation for Economic Co-operation and Development. Since it came into force in 1988, the Privacy Act has undergone four key rounds of amendments: the expansion of the application of the act to private sector businesses in 2000, the extensive updates to the act in 2014 following a comprehensive review by the Australian Law Reform Commission and a significant expansion to the civil penalties available under the act in 2022.",
        "content": [
            "Editor's note: This article was originally published 11 Oct. 2017 as part of a series that matched laws from across the globe to the EU General Data Protection Regulation. This article has been updated to include the latest developments to Australia's Privacy Act in December 2024. ",
            "The Privacy Act (cth) is the foundation of Australia's national privacy regulatory regime. Its genesis lies in the 1980 guidelines issued by the Organisation for Economic Co-operation and Development. Since it came into force in 1988, the Privacy Act has undergone four key rounds of amendments: the expansion of the application of the act to private sector businesses in 2000, the extensive updates to the act in 2014 following a comprehensive review by the Australian Law Reform Commission and a significant expansion to the civil penalties available under the act in 2022.",
            "More recently, in 2024, the first tranche of amendments following a lengthy review process commenced in 2021. This first tranche included amendments to the powers of the regulator, new rules around overseas disclosures, and new transparency requirements. A second tranche will be required to implement the bulk of accepted reform proposals, however, this has not yet been scheduled at publication time.",
            "The Privacy Act is intended to provide a basis for nationally consistent privacy regulation, facilitate the free flow of information outside of Australia while ensuring that individual privacy is respected, provide a complaint mechanism, and to implement Australia's international privacy obligations. Most of these objectives are achieved by the Australian Privacy Principles, set out in Schedule 1 of the act. The APPs impose obligations regarding the collection, use, disclosure, storage and disposal of \"personal information\" about individuals, as well as obligations relating to access and correction and credit reporting.",
            "The APPs apply to APP entities\u00a0\u2014 that is, Australian, Australian Capital Territory and Norfolk Island government agencies and private sector businesses. Individuals and small business operators\u00a0\u2014 businesses with an annual turnover of less than AUD3 million, are exempt from the operation of the act. Unlike the EU General Data Protection Regulation, the Privacy Act does not distinguish between data controllers and data processors\u00a0\u2014 any APP entity that holds personal information must comply with the APPs.",
            "APP 1: Open and transparent management of personal information",
            "This first Australian Privacy Principle requires APP entities to manage personal information in an \"open and transparent way,\" including taking reasonable steps to ensure that they comply with the APPs.",
            "APP 1 is similar in effect to GDPR Article 5 Principle 2, which requires controllers to be able to demonstrate compliance with the obligations set out in Principle 1. Principle 1(a) also requires data processing to be done in a \"transparent manner.\"",
            "APP 1.3 and 1.4 also require APP entities to have a clearly expressed privacy policy that deals with specified matters.\u00a0GDPR Article 7 discusses obtaining consent from an individual in the context of a \"written declaration,\" and Articles 12\u201314 address similar matters to those specified in APP 1.3 and 1.4. Articles 13\u201314\u00a0also require additional information to be provided; this includes information about how long personal data will be stored, the enhanced personal rights under the GDPR (such as data portability, the right to withdraw consent, and the right to be forgotten), and any automated decision-making including profiling.\u00a0",
            "APP 2: Anonymity and pseudonymity",
            "APP 2 requires APP entities to give individuals the option of not identifying themselves, or of using a pseudonym unless a listed exception applies.",
            "There is no direct analog to this provision in the GDPR. However, it should be noted the GDPR may apply to pseudonymous information per Recital 28.",
            "APP 3: Collection of solicited personal information",
            "APP 3 outlines when an APP entity can collect personal information it has asked for. In particular, this APP requires organizations only collect personal information where it is reasonably necessary or directly related to their functions or activities, and by \"lawful and fair means.\" Higher standards are applied to the collection of sensitive information; specifically, sensitive information may only be collected with consent or where a listed exception applies.",
            "A comparison can be drawn here to GDPR Article 5, which requires data collected for \"specified, explicit and legitimate purposes\" and be processed \"lawfully (and) fairly\" (Principle 1(a) and (b)).",
            "APP 4: Dealing with unsolicited personal information",
            "APP 4 requires APP entities to destroy or de-identify unsolicited personal information that they could not have otherwise collected under APP 3.",
            "There is no direct analog in the GDPR; however, it should be noted that the GDPR does not permit collection of personal data without a specified, explicit purpose.",
            "APP 5: Notification of the collection of personal information",
            "APP 5 requires APP entities to notify individuals, or otherwise ensure they are aware, of specified matters when they collect their personal information, such as, by providing individuals with a collection statement.",
            "Again,\u00a0Articles 13\u201314 also impose requirements for the provision of privacy information that is substantially similar to the matters specified in APP 5, as well as additional obligations, see APP 1 above.",
            "APP 6: Use or disclosure of personal information",
            "APP 6 outlines the circumstances in which an APP entity may use or disclose personal information that it holds. Where an APP entity has collected personal information for a specific purpose and wishes to use it for a secondary purpose, APP 6 provides entities may not do so unless the individual has consented, it is within their reasonable expectations, or another listed exception applies. Exceptions include circumstances involving health and safety and law enforcement.",
            "GDPR Article 6 similarly requires that personal data may only be processed where the data subject has consented to one or more of the specific purposes of the processing, or another listed scenario applies. For example, where the processing is necessary to perform a contract or comply with a legal obligation.",
            "APP 7: Direct marketing",
            "APP 7 provides that an organization that is an APP entity may only use or disclose personal information for direct marketing purposes if certain conditions are met. Direct marketing messages must include a clear and simple way to opt out of receiving future messages and must not be sent to individuals who have already opted out. Sensitive information about an individual may only be used for direct marketing with the consent of the individual.",
            "GDPR Article 21 provides individuals with, among other things, the right to object to the use of their personal data for direct marketing.",
            "APP 8: Cross-border disclosure of personal information",
            "APP 8 requires an APP entity, take reasonable steps to ensure that the recipient does not breach the APPs in relation to that information, before it discloses personal information to an overseas recipient. Personal information may only be disclosed when the recipient is subject to a regulatory regime that is substantially similar to the APPs, where the individual has consented, or another listed exception applies. APP entities may be liable for the acts and practices of overseas recipients in certain circumstances per Section 16.",
            "Notably, the 2024 reforms to the Privacy Act provide the Governor General will outline a list of countries with adequate privacy protections and enforcement mechanisms that are deemed safe to execute cross-border data transfers with. This list will be developed and implemented through regulations \u2014 but this has not happened at press time. This is substantially like the approach taken in GPDR Article 45 where transfers of personal data to third countries are permissible where those countries are deemed to provide an \"adequate level of (privacy) protection.\"",
            "Chapter 5 of the GDPR provides that transfers of personal data outside of EU jurisdiction may only be made where the recipient jurisdiction has been assessed as \"adequate\" in terms of data protection, where sufficient safeguards, such as a binding contract or corporate rules, have been put in place, or a listed exception applies. The European Commission has not, to date, assessed Australia as adequate.",
            "APP 9: Adoption, use or disclosure of government related identifiers",
            "APP 9 provides that an organization that is an APP entity may not adopt a government related identifier of an individual as its own identifier, or use or disclose such an identifier unless a listed exception applies. There is no direct analog to this provision in the GDPR.",
            "APP 10: Quality of personal information",
            "APP 10 requires APP entities to take reasonable steps to ensure the personal information it collects, uses or discloses is accurate, up-to-date and complete.",
            "Accuracy\u00a0and\u00a0currency of the information are mentioned in Article 5 of GDPR (Principle 1(d); \"every reasonable step must be taken\" to ensure that inaccurate personal data is \"rectified without delay.\"",
            "APP 11: Security of personal information",
            "APP 11.1 requires APP entities take reasonable steps to protect the personal information they hold from misuse, interference and loss, and from unauthorized access, modification or disclosure. These steps must include \"technical and organisational controls\" per APP 11.3 \u2014 that is, APP entities are expected to have both governance controls such as policies and procedures, as well as technical cybersecurity controls, such as firewalls, access controls, encryption. This provision is a frequent focus of investigations into APP entities conducted by the Australian information commissioner.",
            "GDPR Article 5 similarly requires that data processing be undertaken in a manner \"that ensures appropriate security of the data\" (Principle 1(f)). Further, Article 32, requires the data controller and the processor to implement appropriate technical and organizational measures to ensure a level of security appropriate \u2014 taking into account the state of the art, the costs of implementation and nature, scope, context and purposes. Those measures must also address the confidentiality, integrity and availability of the data.",
            "APP 11.2 provides that APP entities must also take reasonable steps to destroy or de-identify personal information that they no longer require for a lawful business purpose.",
            "GDPR Article 5(1)(e) imposes a similar storage limitation \u2014\u00a0personal data may \"kept in a form which permits identification of data subjects for no longer than is necessary for the purposes for which the personal data are processed\" (Principle 1(e)). However, the GDPR also explains that \"personal data may be stored for longer periods insofar as the personal data will be processed solely for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes in accordance with Article 89(1).\"",
            "These reasonable steps must include, but are not limited to, \"technical and organisational controls\" under APP 11.3. That is, APP entities are expected to have both governance controls such as policies and procedures, as well as technical cybersecurity controls, such as firewalls, access controls and encryption, and technical controls to enable defensible identification of over-retained personal information, deidentification or destruction.",
            "APP 12: Access to personal information",
            "APP 12 requires APP entities to give an individual access to the personal information about them that the entity holds, on request by that individual. This APP imposes procedural requirements around access and includes limited exceptions.",
            "Article 15 of the GDPR imposes a similar right of access, with additional rights to know information about the collection and envisaged the use of the data, such as recipients or potential recipients, likely storage period, and safeguards for overseas transfers.",
            "APP 13: Correction of personal information",
            "APP 13 requires APP entities take reasonable steps to correct personal information they hold about an individual, on request by the individual. This APP also imposes procedural requirements and includes limited exceptions.",
            "GDPR Article 16 imposes a similar but stronger right; data subjects have the absolute \"right to obtain \u2026 without undue delay the rectification of inaccurate personal data concerning (them).\"\u00a0",
            "Comparison Table",
            "",
            "Topic",
            "",
            "The Privacy Act is still subject to an ongoing review process. At press time, the Australian government has not specified when the second tranche of reforms can be expected.",
            "If implemented, the second tranche of reforms will provide further significant changes to Australia's privacy protection framework. These are expected to include, but are not limited to:",
            "See the Government's Response to the Privacy Act Review Report.",
            "",
            "Tim de Sousa, AIGP, CIPP/E, CIPM, FIP, is managing director, technology, privacy, information governance and tech ethics at FTI Consulting."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-asia-pacific-region-nz-opc-calls-for-doing-privacy-well-",
        "title": "Notes from the Asia-Pacific region: NZ OPC calls for 'doing privacy well'",
        "location": "Asia",
        "date_published": "29 May 2025",
        "keywords": [
            "AI Governance",
            "Biometrics",
            "Community & Careers",
            "Data Security",
            "Enforcement",
            "Law & Regulation",
            "Risk Management",
            "Regulatory Guidance"
        ],
        "description": "Privacy Week 2025 in Aotearoa New Zealand is now done and dusted. It was a great week that\u00a0included an incredible program of webinars hosted by the Office of the Privacy Commissioner.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "Privacy Week 2025 in Aotearoa New Zealand is now done and dusted. It was a great week that\u00a0included an incredible program of webinars hosted by the Office of the Privacy Commissioner.",
            "Keeping with tradition, IAPP members had the pleasure of hearing from Privacy Commissioner Michael Webster at a 13 May Auckland\u00a0KnowledgeNet event. In a keynote address, Webster\u00a0generously shared his reflections on the state of privacy in Aotearoa, outlined the OPC's key areas of focus for the next year and gave his perspective on areas of emerging privacy risk.",
            "Webster notably featured statistics in his keynote, telling us quite a bit about the state of privacy in Aotearoa. In the last financial year, the OPC responded to over 6,000 privacy inquiries (over 100 a week) from members of the public, received over 1,000 privacy complaints \u2014 a 15% increase on the previous year \u2014 and received over 800 privacy breach reports (of which over 400 were serious).",
            "Interestingly, while human error was the primary cause of privacy breaches in previous years, Webster noted the majority of serious breaches over the past year were caused by intentional or malicious activity, including employee browsing.",
            "The OPC's 2025 privacy survey Research on Privacy Concerns and Use of Personal Information found that 82% of New Zealanders want more control and choice over the collection and use of their information; 67% would consider changing service providers due to poor privacy practices; 67% are concerned about the privacy of children; 77% think the OPC should have the power to issue large fines for serious privacy breaches; and 62% are concerned about government or business use of artificial intelligence to make decisions.",
            "Webster suggested the survey results might prompt privacy professionals to ask how organizations can improve to address these concerns and what smart privacy regulation might look like in 10 years' time.",
            "On the topic of smart regulation, Webster remains concerned about the state of New Zealand's Privacy Act 2020, noting it runs the risk of \"losing alignment with like-minded countries,\" missing key obligations, rights and powers that are being implemented overseas to address new technologies. He said he will continue to advocate for modernization of the Privacy Act; we already know his views on the need for meaningful financial penalties \u2014 something the privacy survey shows the public strongly supports.",
            "The survey also reinforced the importance of seeking and listening to a te ao M\u0101ori perspective on privacy. While 47% of New Zealanders are concerned about privacy, this figure rose to 53% for M\u0101ori. A staggering 79% of M\u0101ori respondents revealed that protecting personal information is a major concern, compared with 66% overall.",
            "The figures were similarly higher for M\u0101ori respondents in relation to the use of facial recognition technology. The OPC has recently established a\u00a0M\u0101ori Reference Panel\u00a0to better understand and address the te ao M\u0101ori perspective.",
            "The OPC will be advancing several significant initiatives over the coming year, including its inquiry into the use of facial recognition technology by Foodstuffs North Island, the development of the Biometrics Processing Privacy Code, guidance on the upcoming indirect notification obligation \u2014 known as Information Privacy Principle 3A \u2014 playing its part in the implementation of the Customer and Product Data Act and investigating referrals received from the Public Service Commission related to data misuse allegations at Manurewa Marae.",
            "All these initiatives align with the OPC's three key areas of strategic focus for the year to come. First, it will provide guidance to support the implementation of legislative and regulatory privacy initiatives. Second, it will engage with organizations to build their privacy capability and empower New Zealanders to assert their privacy rights. Third, it will focus its activities on the technological and digital innovations being adopted by organizations, including the use of AI tools.",
            "Returning to the \"Privacy on Purpose\" theme, Webster closed with a call for privacy professionals to re-frame the language of privacy, breaking the false dichotomy narrative. \"In the language we use, in the way that privacy officers explain things, in addressing complex public policy problems, in developing new business strategies, we need to own and communicate that making privacy part of the discourse is not an either/or. It's an 'and' or a 'while.' It's doing privacy well,\" he said.",
            "Let's all head into the next year with that call to action front of mind.",
            "Daimhin Warner, CIPP/E, is the country leader, New Zealand, for the IAPP.",
            "This article originally appeared in the Asia-Pacific Dashboard Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/italy-updates-national-cybersecurity-and-data-protection-framework",
        "title": "Italy updates National Cybersecurity and Data Protection Framework ",
        "location": "Europe",
        "date_published": "29 May 2025",
        "keywords": [
            "Data Security",
            "Frameworks & Standards",
            "Law & Regulation"
        ],
        "description": "Italy published an enhanced iteration of its National Framework for Cybersecurity and Data Protection that, while described as national, closely follows the U.S. National Institute of Standards and Technology's Cybersecurity Framework 2.0.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "Italy published an enhanced iteration of its National Framework for Cybersecurity and Data Protection that, while described as national, closely follows the U.S. National Institute of Standards and Technology's Cybersecurity Framework 2.0.",
            "This reflects and diverges from EU regulatory ambitions under the Network and Information Systems Directive 2. Data protection professionals must closely watch this emerging convergence of cybersecurity management and data protection obligations.",
            "Italy's updated framework goes a step beyond the strategy plan initially outlined in 2015, followed by a 2019 adaptation to encompass obligations introduced by the EU General Data Protection Regulation. This new edition has been designed as an operational reference framework to help public and private organizations \u2014 regardless of size \u2014 organize and govern cybersecurity and data protection activities in a logical and scalable way.",
            "It is well-timed. The NIS2 Directive is being transposed into Italian law through Legislative Decree 138/2024, expanding more rigorous cybersecurity to a wide range of organizations. The revamped framework is a useful tool to support organizations faced with elaborate compliance environments, helping bridge the gap between strategy and operational implementation.",
            "A key change to the 2025 edition is its compatibility with the NIST Cybersecurity Framework, the newly published internationally accepted standard. This is an apparent step toward embracing internationally validated best practices with adaptation of national, as well as EU, legislation.",
            "The update is the result of a development process led by Sapienza University of Rome's Research Center of Cyber Intelligence and Information Security and the Cybersecurity National Lab of CINI with the guidance of Italy's National Cybersecurity Agency. The multistakeholder engagement reflects an overall attitude toward cybersecurity \u2014 one that spans academia, research institutions, government agencies and private industry \u2014 and aims to create an effective cybersecurity community that addresses the increasingly changing threat landscape.",
            "In particular, the framework is neither binding nor an instrument of regulation. Rather, it is an adaptive, voluntary instrument organizations can apply to align internal procedures to regulatory requirements and best practices in cybersecurity. Far from replacing compliance with laws such as the GDPR or NIS2, it assists organizations in developing consistent internal procedures for risk management, continuity and resilience.",
            "A major update with this version is the addition of nine controls directed specifically toward privacy, prefixed by the letters \"DP.\" These controls address such key data protection matters as notice to data subjects, making processing pursuant to some requirement of law, and managing privacy risks within the broader universe of cybersecurity methodologies.",
            "The controls were added because of growing recognition of the extent to which data protection is no longer separate from cybersecurity \u2014 particularly where, as it is within the EU, data protection is statutory and constitutional.",
            "As organizations doing business within Italy make their way toward NIS2 compliance and complete convergence with the GDPR, this framework is a natural, logical means of creating efficient controls over security and privacy.",
            "It is particularly significant to recognize how the Italian system translates to the NIST CSF 2.0. That is because it lets privacy officers bridge the gap between cybersecurity practice at the technical level and the privacy requirements arising from compliance obligations. Specific privacy controls make it easier for data protection officers, as well as compliance teams, to integrate privacy into overall risk management designs.",
            "Moreover, the new framework is an intriguing example of balancing international models with domestic frameworks today. Although it takes heavily from an American system, the localization to EU and Italian context \u2014 plus the added inclusion of privacy controls \u2014 is an example of a hybrid approach. It is an attempt to bring operational guidance into concert with EU regulatory intent, an exercise more relevant than ever given the global reach of organizations within a digitized international economy.",
            "For those who advise multinational or cross-border companies, such nuances matter. The ability to read home country regimes into broader international norms \u2014 and where they fall short \u2014 is going to increase their ability to give accurate, risk-driven advice tailored to both the operational and legal reality of clients.",
            "At the heart of Italy's cybersecurity system is the National Cybersecurity Agency. In addition to assisting with system development, the ACN is responsible for issuing complete guidelines related to NIS2 implementation, including parameters for establishing \"significant\" security incidents, technical mitigation techniques for risks, and reporting incident guidelines. They are issued as official determinations and are part of the broader set of regulatory tools at the disposal of NIS authorities.",
            "For the privacy profession, this renewed framework cannot be looked at independently. Instead, it is at the nexus of an ecosystem of regulatory programs, industry-specific requirements, and technical ACN guidance. Knowledge of these documents \u2014 and where they overlap with the framework \u2014 is key to building an efficient compliance solution.",
            "The 2025 Italian National Framework for Cybersecurity and Data Protection is an important step forward to construct the country's digital infrastructure. Taking inspiration from international best practices like the NIST CSF 2.0 and building upon it by adding controls specifically tailored to protect privacy, it offers organizations an organized, comprehensive framework for cybersecurity and data protection.",
            "The framework is an important tool to assist clients and organizations operating in Italy, offering guidance on addressing NIS2 compliance, maintaining GDPR compliance and integrating privacy into cybersecurity initiatives. The framework raises questions about compliance of international frameworks to individual country systems, raising fundamental issues around interoperability, sovereignty and electronic regulatory positioning.",
            "As requirements become increasingly sophisticated, models like this one will be crucial to help organizations translate high-level requirements into day-to-day practice. The Italian model is significant for its integration of global best practices with local specificity \u2014 making it particularly relevant for privacy and cybersecurity practitioners in this globalized, networked world.",
            "Federico Pontani, CIPP/E, CIPT, FIP, is an information security consultant at EY."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-iapp-europe-the-month-of-consultations-time-to-provide-input-on-shaping-europe-s-digital-future",
        "title": "Notes from the IAPP Europe: The month of consultations \u2014 time to provide input on shaping Europe's digital future",
        "location": "Europe",
        "date_published": "29 May 2025",
        "keywords": [
            "AI Governance",
            "Law & Regulation",
            "Strategy & Governance",
            "Data Security"
        ],
        "description": "The European Commission is seeking stakeholder input on its upcoming Consumer Agenda 2025-30.\u00a0The new agenda is planned to address issues related to new technologies and data-driven practices, gaps remaining in the EU's digital rulebook according to the Commission \u2014 such as harmful practices by online operators other than platforms covered by the Digital Services Act \u2014 and more. In addition, it should also look at regulatory burdens on smaller businesses.\u00a0",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "The European Commission is seeking stakeholder input on its upcoming Consumer Agenda 2025-30.\u00a0The new agenda is planned to address issues related to new technologies and data-driven practices, gaps remaining in the EU's digital rulebook according to the Commission \u2014 such as harmful practices by online operators other than platforms covered by the Digital Services Act \u2014 and more. In addition, it should also look at regulatory burdens on smaller businesses.\u00a0",
            "The Commission is also asking for input on its Apply AI Strategy. Through this call closing 4 June, the Commission hopes to identify the hurdles, including regulatory, to the uptake of artificial intelligence in the EU, with a focus on strategic and public sectors. It is also explicitly asking what challenges companies are facing regarding the AI Act's implementation and how the Commission can help.",
            "The third consultation of note currently open is on the Data Union Strategy, in part linked to the EU's AI efforts. To be distinguished from the European Strategy for Data, which gave rise to the Data Governance Act and the Data Act, the Data Union Strategy aims to enhance innovation and AI development in the EU by enabling data sharing among sectors and different actors. It is set to increase interoperability, and the Commission is looking to understand what it is that stakeholders need to feel safe to share data.",
            "The Commission was expected to launch a public consultation for the upcoming Digital Fairness Act during the 2025 European Consumer Summit that took place 20 May. However, publication of the consultation was postponed at the last minute and is now expected in June.",
            "The proposal for the DFA, planned to tackle problematic online practices such as dark patterns and deceptive techniques, is expected next year.",
            "As mandated by the NIS2 Directive, the European Union Agency for Cybersecurity launched the European Vulnerability Database, which seeks to enhance Europe's digital security and support the implementation of EU cyber laws. In this database, entities are encouraged to share publicly known vulnerabilities. The tool is set to provide transparency to users and offer information on possible risk mitigation measures.",
            "Meanwhile, member states are struggling to meet deadlines set by the NIS2 Directive. The Commission recently sent a reasoned opinion to 19 member states, requesting they transpose the directive \u2014 which aims to enhance cybersecurity of critical sectors across the EU \u2014 into national laws. This is the last step before referral to the Court of Justice of the European Union.",
            "Several EU member states are struggling with the implementation of yet another piece of legislation. On 7 May, the Commission announced it is referring Cyprus, Czechia, Poland, Portugal and Spain to the CJEU for failing to designate or empower their national Digital Service Coordinators under the Digital Services Act.",
            "The European Data Protection Board published two opinions concerning adequacy matters this month. One is on the European Commission's draft adequacy decision concerning the European Patent Organization. The EDPB requested further clarification from the Commission on onward transfers, among others, but reached a favorable conclusion. The EPO may become the first international organization to be afforded an adequacy decision under the EU regime, allowing personal data to be transferred from the EU to the EPO freely.\u00a0",
            "The other opinion concerns the Commission's proposal to extend the U.K. General Data Protection Regulation and Law Enforcement Directive adequacy decisions that were set to expire this June. The board recognizes the need for a six-month extension, as it will allow the Commission to review the adequacy of the U.K. legal framework once the new British data protection rules are in place.",
            "Laura Pliau\u0161kait\u0117 is European operations coordinator for the IAPP.",
            "This article originally appeared in the Europe Data Protection Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/right-sizing-ai-governance-starting-the-conversation-for-smbs",
        "title": "Right-sizing AI governance: Starting the conversation for SMEs",
        "location": "",
        "date_published": "28 May 2025",
        "keywords": [
            "AI Governance",
            "Privacy Program Management",
            "Law & Regulation"
        ],
        "description": "Artificial intelligence is no longer the exclusive domain of large enterprises. From retail and real estate to logistics and law firms, small- and medium-sized businesses are beginning to experiment with AI.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "Artificial intelligence is no longer the exclusive domain of large enterprises. From retail and real estate to logistics and law firms, small- and medium-sized businesses are beginning to experiment with AI.",
            "With three out of five small- and medium-sized businesses using or planning to use AI in some form or another in the next two years, competitive edge is a significant catalyst for AI adoption. More specifically, the appeal of AI to cut costs, increase efficiency, drive creativity and enhance decision-making is further amplified by McKinsey's 2024 \"The state of AI\" report, which found 78% of respondents from large competitors have already adopted AI.",
            "Yet with the promise AI holds, few SMBs are prepared for the accompanying risks. Quickly adopting AI without a plan, adequate training or even rudimentary understandings of the everchanging AI regulation and compliance landscapes poses a significant AI management challenge for SMBs.",
            "To further confound the matter for SMBs, the entire AI governance discourse is not tailored to them. In fact, the discourse originally emerged in the context of AI super adopters \u2014 enterprises that can afford to integrate AI across multiple departments, have the ability to train and hire specialized talent, and have the resources to strategically align AI's opportunities to organizational goals while outsourcing tailored frameworks for detecting and mitigating risk.",
            "There is a significant gap between AI-driven enterprises that have an AI governance strategy in place and SMBs that are still undertaking their first AI journey. Few SMBs are prepared for the accompanying risks of onboarding AI; the imagery of AI governance often evokes unwanted images of committees, costs, red tape, additional needless bureaucracies and tailored frameworks.",
            "However, SMBs can consider AI governance in another, more accessible way: managing AI responsibly. For SMBs, this does not require creating new departments or hiring ethicists and lawyers.",
            "Rather, it calls for a practical approach that fits an organization's shape and size. Essentially, it is a way to ask the right questions, put foundational guardrails in place and grow an organization's AI capacity confidently. Because the adoption of AI only continues to accelerate, now is an important time for SMBs to begin the conversation of AI governance.",
            "AI governance involves the processes, standards and guardrails that help ensure AI systems and tools are safe and ethical. Its frameworks direct AI research, development and application to help ensure safety, fairness and respect for human rights.",
            "To promote responsible and ethical practices throughout the life cycle of an AI system, it is necessary to make decisions for effective development, deployment and monitoring to ensure AI systems are performing as intended.",
            "Moreover, AI governance includes oversight mechanisms that address risks such as bias, privacy infringement and misuse while fostering innovation and building trust. Organizations can rest assured that AI governance provides a structured approach to mitigate these potential risks.",
            "One critical tool organizations can employ is creating solid AI policies and procedures. Establishing roles, expectations, rules and responsibilities is a reliable starting point for managing AI because it places important guardrails around how people think about and use AI.",
            "Other tools include a strong data governance plan. AI needs to use large amounts of data to function properly \u2014 the more organized and clean the dataflows are, the better. And of course, we cannot forget about the importance of AI and data protection laws and regulations, which differ depending on jurisdiction. For example, the EU General Data Protection Regulation and AI Act contain data and AI governance requirements \u2014 the golden standards that other jurisdictions look to for guidance when legislating.",
            "In a nutshell, AI governance establishes the necessary oversight to align AI behaviors with ethical standards and societal expectations to safeguard against potential adverse impacts. Not only do organizations achieve higher levels of compliance, but they also benefit from increased efficiency in developing and applying AI technologies.",
            "Why is this important? IBM found \"80% of business leaders see AI explainability, ethics, bias, or trust as major roadblocks to generative AI adoption. AI governance tackles these issues.\" Similarly, \"investing in AI ethics has the potential to create quantifiable benefits.\"",
            "To that end, it is important to embed ethics by design in AI projects from the outset. It may also be advantageous to create an ethics committee within the organization. This involves maintaining continuous involvement throughout the AI development life cycle using crucial milestones, providing ongoing assessments and feedback and ensuring major components of the ethics strategy are incorporated in the design.",
            "There are several approaches to AI governance, including: a rules-based approach with prescriptive regulations; a risk-based approach, prioritizing high-risk areas from minimal, limited, high and unacceptable; an outcomes-based approach, defining and achieving specific desired results; and a principles-based approach, establishing high-level ethical principles and values to guide AI development, deployment and use.",
            "It is important to note that it is common for organizations to use a combination of these approaches.",
            "Leaders of SMBs thinking about how to get started with AI governance should:",
            "Christina Catenacci is co-founder, vice president, chief privacy officer, chief AI officer, managing editor and chief operating officer of voyAIge strategy.",
            "Tommy Cooke, Ph.D., is co-founder, president and CEO of voyAIge strategy."
        ]
    },
    {
        "url": "https://iapp.org/news/a/insights-from-the-anpd-s-new-technical-note-on-automated-decisions",
        "title": "Insights from the ANPD's new technical note on automated decisions",
        "location": "South America",
        "date_published": "28 May 2025",
        "keywords": [
            "AI Governance",
            "Law & Regulation",
            "Data Subject Rights"
        ],
        "description": "On 15 May, Brazil's data protection authority, Autoridade Nacional de Prote\u00e7\u00e3o de Dados, published Technical Note No. 12/2025, summarizing the results of a public call for contributions on the use of artificial intelligence and automated decision-making.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "On 15 May, Brazil's data protection authority, Autoridade Nacional de Prote\u00e7\u00e3o de Dados, published Technical Note No. 12/2025, summarizing the results of a public call for contributions on the use of artificial intelligence and automated decision-making.",
            "The document supports ongoing regulatory efforts under the ANPD's 2025\u201326 Regulatory Agenda and reflects the growing impact of algorithmic systems on data protection and individual rights in Brazil.",
            "At the heart of this discussion is Article 20 of Brazil's General Data Protection Law, which guarantees individuals the right to request a review of decisions made solely through automated processing of personal data. While this right is already in force, its implementation in real-world AI scenarios remains unclear. The technical note helps move the conversation forward, offering insights into how this right might be interpreted and applied as AI technologies evolve.",
            "The document draws from 124 contributions submitted by companies, civil society organizations, academic experts and public institutions. A shared concern is that automated decisions \u2014 especially those involving credit, employment or digital profiling \u2014 can have serious implications for individual autonomy, equality and privacy.",
            "In this context, many contributors emphasized the importance of transparency, human oversight and algorithmic explainability. Human review, when required, should be meaningful, not merely symbolic, they noted. Several responses pointed out that a person must be able to actually understand and, if necessary, reverse the logic of the automated decision.",
            "Still, the document highlights key areas of disagreement. There is no uniform definition of what constitutes a \"solely automated\" decision. While some argue that decisions derived from generative AI outputs may fall outside the scope of Article 20, others believe any automated outcome with real-world consequences should trigger the right to review.",
            "Another point of tension involves how to reconcile the right to information with the protection of trade secrets. Many contributors advocated for a balanced approach \u2014 ensuring individuals receive clear and understandable information without requiring organizations to reveal proprietary algorithms or models.",
            "When it comes to legal bases for processing personal data in AI systems, most stakeholders agree consent is difficult to implement in practice, especially when dealing with complex models and scalable systems. Legitimate interest was viewed as a more adaptable legal basis, provided appropriate balancing tests and safeguards are in place. There was also a call for more guidance on the responsible use of data scraping and the handling of sensitive data, particularly in high-risk contexts.",
            "Governance was another core theme. Contributors recommended organizations document the entire AI life cycle, including training data, decision logic, safeguards and accountability structures. Data protection impact assessments \u2014 known in Brazil as personal data protection impact reports \u2014 were widely endorsed as a tool for identifying and mitigating risks, especially for high-impact use cases or applications involving vulnerable populations.",
            "While the technical note does not impose new obligations, it offers a preview of how the ANPD may approach future regulation and enforcement. It emphasizes risk-based compliance, layered transparency, and the application of existing LGPD principles to new technological challenges.",
            "It also sends a clear message: even in the age of advanced AI, data subjects must retain the ability to understand and contest decisions that affect their lives.",
            "Tiago Neves Furtado, CIPP/E, CIPM, CDPO/BR, FIP, leads the Data Protection and Artificial Intelligence Team and the Incident Response Team at Opice Blum Advogados."
        ]
    },
    {
        "url": "https://iapp.org/news/a/ai-governance-in-aged-care",
        "title": "AI governance in aged care",
        "location": "",
        "date_published": "28 May 2025",
        "keywords": [
            "Health Care",
            "AI Governance",
            "Frameworks & Standards",
            "Risk Management"
        ],
        "description": "While providing cybersecurity and data protection services to the aged care industry over the past five years, I have seen the number of individuals requiring aged care increase significantly.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "While providing cybersecurity and data protection services to the aged care industry over the past five years, I have seen the number of individuals requiring aged care increase significantly.",
            "The World Health Organization predicts the number of individuals aged 60 and above will reach 1.4 billion by 2030 and 2.1 billion by 2050, while the number of people aged 80 and older is expected to triple between 2020-50.",
            "Medical advances in health care and the pharmaceutical industry mean people are living longer than before. Colleagues at aged care facilities say the increase will lead to significant demand in aged caregivers, medical diagnosis facilities, nursing and aged care facilities. The gap between the supply and demand in aged care facilities is expected to be high in the next five to 10 years, which is why organizations are exploring ways to fill it.",
            "The chief information officer of one aged care facility procured an artificial intelligence management system that would provide AI agents trained by staff to act as smart caregivers. They would advise the elderly, record medicine taken \u2014 under staff supervision, and act as social companions. The AI agents would also help with automatic scheduling of staff.",
            "The CIO engaged our organization for advice on the safe and responsible use of AI, keen to ensure no negative impacts from the implementation. Unlike the EU, where the AI Act regulates organizations implementing AI management systems, Australia does not currently have a mandated law on the use of AI. So we recommended conducting an assessment based on the ISO/IEC 42001 controls that are applicable to the AI management system of the aged care facility.",
            "The aged care industry in Australia generally falls under the small and medium-sized business category, usually serving 1,000 to 2,000 residents with a staff of 200 to 800. Budgets are usually limited which is why it is important to choose the most appropriate AI governance framework that would comprehensively aim to enhance the security posture of the AI management system.",
            "I started by exploring local acts and frameworks in Australia. The Australian government has not passed any AI-related framework or act. The closest set of principles are the AI Ethics Principles \u2014 eight principles designed to ensure AI is safe, secure and reliable \u2014 but they are not detailed comprehensively enough to be used for an assessment.",
            "The U.S. National Institute of Standards and Technology's AI Risk Management Framework is specifically focused in this area and emphasizes the identification, assessment and mitigation of AI-specific risks throughout the AI life cycle. However, I was searching for an AI governance framework that would go beyond risk management.",
            "As an IAPP Certified AI Governance Professional, I procured and studied the ISO 42001 framework, which I found to be a comprehensive standard to establish, implement, maintain and continually improve an AI management system. After consulting with other members of the team, we provided an overview of our approach to the CIO.",
            "ISO 42001 consists of 10 clauses, of which clauses 4\u201310 and the associated requirements are relevant for an assessment. We conducted the assessment using four different phases \u2014 define, implement, maintain and improve \u2014 based on how the clauses and requirements were structured. The normative annexes for ISO 42001 that outline the control objectives necessary for AI governance and risk management were also taken into account during the assessment.",
            "The initial challenge was time management of the assessment. Given such an assessment had not been conducted before and the facility's limited funding, we were expected to do more for less and did not have the luxury of including a discovery component within the project.",
            "We planned for the project to occur over one month, beginning by assessing the requirements of Clause 4 \u2014 Context of the organization, Clause 5 \u2014 Leadership, and Clause 6 \u2014 Planning. We were pleased to discover that the context of the organization was clearly defined. For example, the scope was well set, and the requirements of providing smart caregiver AI agents and the automated scheduling system of human caregivers was adequately established.",
            "The organization's leadership was also committed to integrating the AI management system into business processes. The biggest challenge, however, was the lack of a clear policy on how the system would be used and how the organization would ensure fairness, non-bias and human oversight and supervision.",
            "The policy also lacked guidelines regarding AI impact assessments, AI risk assessments, data governance and continuous improvement plans for the AI management system. The roles and responsibilities were also not clearly defined and there was no AI ethics committee or awareness plan for the developers and caregiving staff who would be using the AI management system.",
            "Since the management system was in place, we noted these gaps and recommended a proper AI policy be drafted as per the control objectives in Annexes A and B specifically controls around policy development and internal organizational roles and responsibilities.",
            "We also determined the lack of a proper AI policy could have significant adverse impacts on staff and caregivers' morale.",
            "We proposed crafting an AI strategy for the organization to clearly identify the existing risks of the AI management system and how they would be addressed. The strategy would include plans to handle the risks and ensure measurable AI objectives are communicated within the organization, as well as proper management plans to keep the system up to date and aligned with the AI policy and strategy.",
            "We then went on to assess the ISO 42001 clauses related to operations or implementation: Clause 6 \u2014 Clause 7 \u2014 Support, and Clause 8 \u2014 Operations. The aged care organization had competent staff and resources to support the AI management system but was not clearly documenting any system architecture or technical procedures being implemented.",
            "The organization also did not have a clear communication, triage and awareness plan due to the lack of an AI policy, and did not conduct AI risk assessments nor have a robust AI life cycle plan. These gaps were also noted and a mechanism was proposed to document any artifacts and processes related to the AI management system and the AI life cycle plan was to be designed and built via the AI strategy as stated in control objectives in Annexes A and B.",
            "After this, we moved on to the monitoring requirements in ISO 42001's Clause 9 \u2014 Performance Evaluation. There was an absence of monitoring measures, internal audit schedules and management reviews all of which we proposed to draft for the aged care industry in a performance evaluation plan.",
            "The final assessment was conducted on Clause 10 \u2014 Improvement where we proposed a continuous improvement plan for the AI management system that would include handling any nonconformities.",
            "A report presenting the gaps and recommendations was well-received by the organization's senior stakeholders, who set aside funding to implement our suggested roadmap.",
            "Many organizations are rushing to implement AI management systems and integrating them within business processes without adequate AI governance in place.",
            "In Australia, especially, there are currently no laws mandating the safe and responsible use of AI. This is changing and there are proposals in place to ensure such laws are implemented, but until then, it is imperative that organizations looking to implement AI management systems do their due diligence and have proper AI governance safeguards in place.",
            "Our AI governance assessment clearly identified missed safeguards. The negative impact of using AI systems without human supervision, especially in the aged care industry, can have detrimental consequences, but they can be avoided.",
            "Organizations should embrace new technologies with cautious optimism and be diligent enough to ensure appropriate safeguards and governance are in place to prevent disastrous consequences.",
            "Asadullah Rathore, AIGP, CIPP/E, CIPM, FIP, is a head of professional services at Excite Cyber."
        ]
    },
    {
        "url": "https://iapp.org/news/a/digital-risk-nothing-ventured-nothing-gained",
        "title": "Digital risk: Nothing ventured, nothing gained\u00a0",
        "location": "",
        "date_published": "27 May 2025",
        "keywords": [
            "AI Governance",
            "Community & Careers",
            "Data Security",
            "Strategy & Governance"
        ],
        "description": "In antiquity, society often perceived risk through the purview of the divine. Fate and providence were matters to be deciphered by augury, the methods of which included observing the behavior of birds and, more latterly, the finding of omens in the entrails of sacrificed animals.\u202f\u202f\u00a0\u00a0",
        "content": [
            "Editor's note:\u00a0Take the 2025 Governance Survey!",
            "In antiquity, society often perceived risk through the purview of the divine. Fate and providence were matters to be deciphered by augury, the methods of which included observing the behavior of birds and, more latterly, the finding of omens in the entrails of sacrificed animals.\u202f\u202f\u00a0\u00a0",
            "Modernity has relegated such practices obsolete. Rudimentary or divine methods of assessing risk have been usurped by the rising perception that risk is a concept of choice and action rather than fate and passivity. Indeed, even the word risk derives from \"risicare,\" the Italian verb \"to risk.\"\u00a0",
            "Though more precise calculations are possible with today's auspices in the field of digital governance risks, the complexities, volatilities and consequences are proliferating and compounding in ways that may sometimes feel as if divine intervention is needed. And, as much as divinity is staging a comeback, organizations are searching for calculable and demonstrable ways to define, assess and manage digital risk.\u00a0\u00a0",
            "Unfortunately, there is no prophetic oracle to pronounce the measurement of risks for digital governance across the intersection of law, technology and human interest. Not yet, at least, and perhaps never. There are, however, many structures, techniques and methods to help identify, categorize and respond to different risks. International standards have flourished to homogenize risk management; laws are proclaimed as \"risk-based;\" and organizations increasingly stress-test scenarios, including via red teaming, to explore and simulate risk in distinct environments. \u00a0",
            "Understanding how others perceive these issues is another way in which individuals and organizations observe risk and, indeed, opportunity. My peers' risks may be mine too. Birds of a feather flock together. Perhaps the augurs were onto something. How one's peers respond may help determine whether and how one follows or, even, how one opportunistically distinguishes and differentiates oneself. \u00a0",
            "Last year's IAPP Privacy Governance Report documented the efficacy of, and corresponding confidence in, an organization's approach to privacy governance by reference to the specific practices, measures and personnel deployed. A recurring theme was how organizations, and the individuals tasked within them, are taking on more work, adjacent and additional to their privacy work. In fact, 81% of privacy professionals have been tasked with an additional responsibility, such as artificial intelligence governance, cybersecurity regulatory compliance and platform liability, alongside their existing privacy day jobs. That increases in volume as the variety of work poses challenges and even risks. Doing so against a backdrop of flat budgetary investment heightens challenges.\u00a0",
            "This year's governance survey invites responses to help document, in more empirical terms than the augurs, how digital risk is perceived in today's world and does so through four prominent prisms: the geopolitical, the technological, the societal and the organizational. The results, as selected by respondents, will index the top risks overall and across those categories, and will help inspire and inform discussion at Navigate: a Digital Policy Leadership Retreat.\u00a0",
            "Chi non risica non rosica.\u202f Nothing ventured, nothing gained. Take the survey and stand to gain from a richer understanding of the risks shaping the governance of digital technology.\u00a0",
            "\u00a0Joe Jones is the director of research and insights for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/navetta-discusses-combining-legal-knowledge-with-tech-advancement",
        "title": "Navetta discusses combining legal knowledge with tech advancement",
        "location": "",
        "date_published": "27 May 2025",
        "keywords": [
            "Technology",
            "AI Governance",
            "Community & Careers",
            "Data Protection Obligations",
            "Law & Regulation",
            "Risk Management"
        ],
        "description": "With a growing regulatory compliance landscape and subsequent organizational obligations, privacy lawyers must serve as translators to help companies keep up. Troutman Pepper Locke Partner David Navetta said his technological background has been a crucial skill when helping organizations navigate complex web of digital matters.",
        "content": [
            "Editor's note: The IAPP\u2019s \u201cProfiles in Privacy\u201d series features a monthly conversation with a notable privacy professional to discuss their journey in privacy, challenges and lessons learned along the way, and more.",
            "With a growing regulatory compliance landscape and subsequent organizational obligations, privacy lawyers must serve as translators to help companies keep up. Troutman Pepper Locke Partner David Navetta said his technological background has been a crucial skill when helping organizations navigate complex web of digital matters.",
            "\"I sit between a lot of very different people with different viewpoints who sometimes speak different languages effectively, and I try to make it all work for them, whether it be a privacy issue or a data breach,\" Navetta said.",
            "Navetta joined Troutman Pepper Locke in February, though his extensive background in privacy litigation began in 2002. He was able to combine his existing law career with his interest in technology and privacy.",
            "Navetta began when privacy was a smaller, less robust field. Now it feels as though privacy, security and artificial intelligence concerns \"just sort of seep into all the cracks everywhere,\" he said. \"I feel fortunate to have caught the wave when it was smaller, and now it's almost a tsunami.\"",
            "The role at Troutman is the latest step in a privacy career focused organizational compliance.",
            "Navetta was a founding partner of InfoLawGroup, a law firm dedicated to advising companies on complex data security, technology and advertising issues. Before Troutman, he served as a partner at Cooley, where he was recognized by Cybersecurity Docket as a top data breach response lawyer in its annual Incident Response 50 list.",
            "Working in various aspects of privacy law and compliance has allowed Navetta to gain a well-rounded approach to guiding clients through a range of regulatory entanglements. \"Not only do you have to know all the things that are changing constantly out in the world, substantively, you have to be able to do a lot of different things from a skill set,\" Navetta said.",
            "\"Handling a litigation matter or data breach is very different than providing strategic advice on some sort of privacy compliance issue,\" he added. \"So, it makes you very well-versed in the area, because you end up seeing the problem from different vantage points and angles, and each of them sort of reinforces the other areas that you practice in.\"",
            "Navetta's comprehensive legal strategies align with Troutman's \"360 model,\" which aims to use innovative solutions when advising organizations. The model works to ensure sure clients \"are well versed in what happens when everything goes wrong in the back end\" to avoid legal challenges while allowing companies to grow.",
            "The advancement of AI technology has created unique growth opportunities for organizations. Amid the race to implementation, Navetta noted companies training AI algorithms must carefully comply with data consent obligations to avoid enforcement or data protection concerns.",
            "\"The value of data and personal information in particular has become so strong and high that you know to not get this right, the stakes are much higher,\" Navetta said. \"It's not just a regulatory action that you have to face or litigation. It's, 'Hey, can we actually do the business that we would like to do? Do we have to kind of go back and try to get everything fixed?\"",
            "To address these challenges, companies are looking to take a more proactive risk-based approach to assess data protection concerns. Navetta said increased regulation, domestically and globally, covering the wide spectrum of overlapping digital fields will require more legal experts.",
            "\"There's going to be a realization that these laws are really table stakes when it comes to the data economy. And so, I think there's just going to be more effort needed, and more lawyers and skills employed in this space,\" Navetta said.",
            "With the privacy community in particular, Navetta said there should be an aim \"to build itself up more,\" through hybrid roles, combining technology and sector-specific skills with legal knowledge. \"The more that people can have diverse backgrounds and skill sets that pull from all those areas, the more successful they'll be,\" he said.",
            "Lexie White is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/more-than-a-fingerprint-reclaiming-privacy-in-biometric-systems",
        "title": "More than a fingerprint: Reclaiming privacy in biometric systems",
        "location": "",
        "date_published": "27 May 2025",
        "keywords": ["Biometrics"],
        "description": "Biometric authentication is increasingly used in daily life from unlocking phones to verifying identity at border control. But as biometric systems grow more pervasive, a key question is being overlooked: What does user control look like when the data is literally part of their body?",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. \r",
            "Biometric authentication is increasingly used in daily life from unlocking phones to verifying identity at border control. But as biometric systems grow more pervasive, a key question is being overlooked: What does user control look like when the data is literally part of their body?",
            "Traditional models of consent and data management break down in the biometric context. Most systems are built with a \"capture once, use indefinitely\" mindset. Consent is often collected in a single moment and rarely revisited. Revocation \u2014 the ability for a user to withdraw consent and have their biometric data removed \u2014 is either poorly supported or not supported at all.",
            "Biometric systems can be designed in ways that actually honor revocability, not just legally, but technically and operationally and organizations can move from checkbox compliance to building meaningful user control into the fabric of biometric infrastructure.",
            "Unlike passwords, biometric identifiers can't simply be reset. Once a fingerprint or facial scan is compromised, there's no changing it. But even beyond breach risks, users may want to revoke biometric consent for other reasons: a change in trust, a shift in regulation or simply evolving personal boundaries.",
            "The problem is, most systems aren't designed to handle this. Even when users delete their biometric profile, residual traces often remain \u2014 in logs, backups, analytics pipelines, or machine learning models. Worse, many systems treat biometric templates as long-lived assets, designed to persist indefinitely for convenience or business efficiency.",
            "This creates a false sense of control. The user clicks \"delete,\" but the data lives on.",
            "To support revocability in biometric systems, a few fundamental assumptions should be reconsidered. First, not all biometric data needs to be stored. For many use cases, on-device matching or ephemeral processing can provide authentication without central storage. Second, consent should not be treated as a one-time checkbox. It should be dynamic and re-evaluated with every data access. Third, deletion must be thorough. True deletion includes removing data from live systems, backups, caches and downstream processors \u2014 or at the very least, making users aware of where deletion cannot occur.",
            "Revocation-friendly design is achievable when certain principles are built into system architecture. Start with ephemeral processing wherever possible. Biometric inputs can often be verified and discarded without storage. Make consent a real-time gatekeeper, something that's checked not only at enrollment but also at every point of access. Design biometric templates with revocation in mind: version them, timestamp them, and enable workflows that allow for their secure removal across environments.",
            "Audit logs should be thorough, but also privacy conscious. They should record biometric access events without retaining sensitive inputs themselves. Where biometric data is used to train or fine-tune models, those models should be capable of excluding or minimizing the influence of deleted inputs. Whether through retraining, dynamic forgetting or other strategies, machine learning systems must be part of the revocation plan.",
            "Organizations can start by mapping where biometric data is stored, duplicated or shared. Many don\u2019t realize that biometric traces can live in analytics platforms, debug logs or downstream services. Once mapped, create a deletion workflow that covers all these touchpoints. Shift toward localized, short-lived processing. Build clear documentation and interfaces that show users what data is collected, how it's used and how they can remove it.",
            "Most importantly, change the mindset: treat biometric data as something entrusted to the organization by the user \u2014 not owned by the organization. That shift in perspective alone can lead to more thoughtful, privacy-respecting implementations. The future of biometric systems demands more than one-time consent or static privacy policies. It requires systems that respect change \u2014 that adapt when users want to revoke, remove or recover control of their data.",
            "Revocability isn't just about compliance. It's a measure of respect. And in an era where biometrics are replacing passwords, that respect must be embedded in the system itself.",
            "Designing for revocation doesn't diminish the value of biometrics. It enhances trust in the systems that use them. And that trust is the foundation on which responsible identity technology must be built.",
            "Naveen\u00a0Kumar Reddy\u00a0Pajjuri\u00a0is a software engineer specializing in privacy-focused system design.\u00a0"
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-iapp-canada-take-a-deep-breath-and-dive-in-on-ai-training",
        "title": "Notes from the IAPP Canada: Take a deep breath and dive in on AI training",
        "location": "North America",
        "date_published": "23 May 2025",
        "keywords": [
            "AI Governance",
            "Community & Careers",
            "Law & Regulation"
        ],
        "description": "At last year's Canadian Privacy Symposium, I was struck by the sense of everyone seemingly overwhelmed by artificial intelligence \u2014 how many kept saying, both in sessions and in conversations, that they felt they were drinking from the firehose, as changes in privacy and AI seemed to be overwhelming.\u00a0",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "At last year's Canadian Privacy Symposium, I was struck by the sense of everyone seemingly overwhelmed by artificial intelligence \u2014 how many kept saying, both in sessions and in conversations, that they felt they were drinking from the firehose, as changes in privacy and AI seemed to be overwhelming.\u00a0",
            "This year, the sense is different. It's more of \"Oh well, let's roll up our sleeves, and get on with it.\" I would credit this in large part to the IAPP Artificial Intelligence Governance Professional certification training \u2014 as well as the numerous other AI-oriented KnowledgeNets, sessions, and focus areas of the IAPP.",
            "In conversations with clients, I emphasize the importance of upskilling our organizations to use AI. We can't put people in front of AI tools without proper training \u2014 it's like giving someone a car without requiring driver education. The EU AI Act emphasizes digital literacy, and increasingly, as with privacy, the commissioners will be asking questions about training \u2014 how we trained our staff, when incidents happen.",
            "Likewise, we in the profession, those in charge of governance \u2014 managing the traffic? \u2014 also need to be equipped, to be knowledgeable, to provide the proper guidance, the rules of the road, as it were.",
            "I had the honor of delivering the AIGP certification training after the IAPP Canada Privacy Symposium 2025. It's challenging training because the topic is so complex. We must wrap our heads around large language models, training models and the importance of data throughout the process of developing and implementing machine learning. Despite the challenges, the feedback I received was very positive \u2014 for which I am very pleased, by the way. Instructors try to provide real-world examples to help classes get their heads around both law and technology.My advice to those pursuing the AIGP certification? Read. The. Materials. Also, read the links to the additional components. Then, read more. There are many good sources to help grasp the technology and you need to absorb the concepts in AI and machine learning. Then, prepare by taking the practice tests and focusing on areas where you might be weak. Then, do the exam. Don't wait too long. I have done myself in by taking the course and deferring the exam too long, which meant I had to re-read everything.This is a fast-moving area. There is no question AIGP content will be updated as new developments emerge in both law and technology. Take a deep breath and dive in.",
            "Constantine Karbaliotis, AIGP, CIPP/C, CIPP/E, CIPP/US, CIPM, CIPT, FIP, is counsel at nNovation.",
            "This article originally appeared in the Canada Dashboard Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/proposed-moratorium-on-state-level-ai-regulation-heads-to-us-senate",
        "title": "Proposed moratorium on state-level AI regulation heads to US Senate",
        "location": "North America",
        "date_published": "22 May 2025",
        "keywords": ["AI Governance", "Law & Regulation", "Enforcement"],
        "description": "A proposed 10-year ban on U.S. states enacting and enforcing artificial intelligence regulations survived in a revised version of Congress' reconciliation bill passed out of the House by a narrow 215-214 vote 22 May. The bill advanced to the Senate, where the moratorium is already receiving notable bipartisan pushback as currently constituted.",
        "content": [
            "A proposed 10-year ban on U.S. states enacting and enforcing artificial intelligence regulations survived in a revised version of Congress' reconciliation bill passed out of the House by a narrow 215-214 vote 22 May. The bill advanced to the Senate, where the moratorium is already receiving notable bipartisan pushback as currently constituted.",
            "Moratorium provisions were notably tweaked before moving out of the House. One update was made to the moratorium's application, which now covers state laws \"limiting, restricting or otherwise regulating\" AI systems or automated decision systems \"entered into interstate commerce.\" Exemptions were also added for state laws imposing criminal penalties.",
            "A House Committee on Energy and Commerce spokesperson told the IAPP the updates came after consultation with consumer protection groups. They added the changes are important to address enforcement of child sexual abuse material and to ensure criminal penalties for AI abuses are not diminished.",
            "Rep. Luz Rivas, D-Calif., mounted an effort to strike the moratorium from the bill before passage, but the challenge was defeated in the House Committee on Rules.",
            "The reconciliation measure's effects on taxes and spending garnered far more attention than the moratorium, but its survival in the final House text is one of the stronger indicators of the White House approach to AI. U.S. President Donald Trump's administration has been critical of EU efforts to put guardrails around the technology, arguing such regulation threatens to stifle the industry's ability to innovate.",
            "U.S. tech companies are echoing the White House's sentiments on innovation burdens, urging passage of a federal law preempting states from passing dozens of AI laws \u2014 mirroring a similar request made for federal privacy legislation \u2014 but to take a light touch in doing so.",
            "As the bill moves to the Senate, Republicans are expected to offer some changes. Members of that caucus are initially expressing doubt about the moratorium, citing states' ability to protect consumers from potential harms until Congress acts.",
            "\"We certainly know that in Tennessee, we need those protections,\" Sen. Marsha Blackburn, R-Tenn., said during a Senate Committee on the Judiciary subcommittee hearing on deepfakes. \"And until we pass something that is federally preemptive, we can't call for a moratorium on these things.\"",
            "Blackburn was referring to her state's passage of a law designed to protect artists' voices and images from being used in unauthorized works created by AI. Deepfakes are one of the issues lawmakers locally and nationally have been interested in, with Trump signing the TAKE IT DOWN Act into law earlier this week. The law requires internet platforms to remove sexually explicit images and videos of others taken without consent and includes AI-generated content.",
            "Senate hearing participants were largely supportive of the NO FAKES Act, which would give victims the ability to bring legal action against those who knowingly create deepfakes and profit from them. It also protects platforms from liability if they remove the content, which has garnered the support of companies such as YouTube and Google.",
            "While the moratorium could face bipartisan scrutiny in the Senate, the House Republican majority showed unity through its approval of the measure and during a House Energy and Commerce subcommittee hearing the day before the floor vote on the reconciliation bill.",
            "With the hearing focused on AI regulation and U.S. competitiveness, some witnesses supported Energy and Commerce Republicans' argument that such a moratorium is critical to defending U.S. dominance in the AI sector and preventing uneven regulation for companies to navigate.",
            "\"Europe would never allow its member states to go out and regulate AI by themselves,\" said Sean Heather, the senior vice president of the U.S. Chamber of Commerce.",
            "\"We should stop international patchworks and AI regulation. We should not be in a rush to regulate. We need to get it right, and therefore taking a time out to discuss it at a federal level is important,\" he continued.",
            "Rep. Jay Obernolte, R-Calif., a member of a bipartisan House AI task force, said the moratorium should not be seen as benefiting Big Tech, but as means to ensure small companies can succeed. He criticized state legislatures for getting out ahead of Congress, saying their resistance to passing a federal privacy law last year would translate into a similar hindrance on Congress' AI efforts.",
            "\"They feel a creative ownership over their frameworks, and they're the ones who are preventing us from doing this now, which is an object lesson to use here of why we need a moratorium to prevent that from occurring,\" he said.",
            "Obernolte also pushed back against arguments that the bill would prevent states from regulating AI under consumer protection laws regarding fraudulent and deceptive practices. He said if those bills do not target AI specifically, \"the states will be free to do that.\"",
            "Democrats pushed back, saying states have only acted when Congress fails to do so and that consumers expect lawmakers to take action when they are at risk.",
            "\"They expect real action from us to rein in the abuses of tech companies, not to give them blanket immunity to abuse our most sensitive data even more,\" said Rep. Lori Trahan, D-Mass.",
            "A frequent mention was the potential effects chatbots can have on children, with attention paid to the case of a 14-year-old Florida boy who died by suicide after interacting with a Character.AI chatbot. A federal judge has allowed a lawsuit blaming the company for his death to go forward.",
            "AI Now Institute co-Executive Director Amba Kak argued the case shows why such a moratorium would be dangerous in the long run.",
            "\"Prevention is the cure when it comes to a range of AI harms, and what we\u2019re seeing instead is a proliferation of very similar kinds of applications to the ones that caused this tragedy in the first place,\" she said.",
            "Caitlin Andrews is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-asia-pacific-region-more-new-problems-to-solve-as-ai-data-march-forward",
        "title": "Notes from the Asia-Pacific region: More new problems to solve as AI, data march forward ",
        "location": "Asia",
        "date_published": "22 May 2025",
        "keywords": [
            "Telecommunications",
            "Finance & Banking",
            "AI Governance",
            "Biometrics",
            "Law & Regulation",
            "Litigation & Case Law",
            "Risk Management",
            "Data Security"
        ],
        "description": "As this column publishes, it is peak summer in India and the mercury levels have been surging. A recent study\u00a0by the Council on Energy, Environment and Water finds 57% of Indian districts covering 76% of the country's population are currently in the \"high to very high\" heat risk bracket. Yet, the world of digital governance marches on.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "As this column publishes, it is peak summer in India and the mercury levels have been surging. A recent study\u00a0by the Council on Energy, Environment and Water finds 57% of Indian districts covering 76% of the country's population are currently in the \"high to very high\" heat risk bracket. Yet, the world of digital governance marches on.",
            "May began with news of a 30 April landmark ruling by the Supreme Court of India, in which the court declared digital access is a fundamental right, an integral part of the right to life and liberty \u2014 under Article 21 of the Constitution of India. The court's ruling articulates and recognizes these rights are not just in the physical realm, but the digital realm, too.",
            "The ruling came in response to a petition by two acid attack victims who, as a result, experienced facial disfigurement and 100% blindness. Due to this, the victims have faced difficulties completing the digital Know Your Customer process that requires a \"live photograph\" by blinking. This has further prevented them from opening a bank account and purchasing a SIM card from mobile service providers.",
            "Meanwhile, as we have seen, use cases continue to emerge where the associated privacy risks are being questioned, along with concerns as to whether they could be addressed by India's Digital Personal Data Protection Act.",
            "For example, Meta recently launched its artificial intelligence-enabled sunglasses in India that enable video recordings. Questions have emerged around how the target individuals of such video recordings will know and have a say if they are being recorded, thus leading to potential privacy violations.",
            "Also, the government of India recently started rolling out e-passports with embedded Radio-Frequency Identification chips. The chips contain personal and biometric data including facial images, fingerprints and iris scans, all in an encrypted format. The concern is a lack of associated rules around who else, aside from border control systems, can access this data and how users would know if their data was being accessed.",
            "Interestingly, the unanswered questions in the vast domain of digital governance are slowly but surely bubbling up to the surface in government and policy circles.",
            "On 28 April, the Department for Promotion of Industry and Internal Trade announced the formation of a committee to examine copyright issues in the context of AI. The committee will look at whether the existing Copyright Act of 1957 is equipped to handle the proliferation of AI-generated content, given how AI tools are increasingly being used to produce images, music and other creative work often using existing copyrighted material.",
            "Meanwhile, the Department of Telecommunications under the Ministry of Communications and Information Technology published security guidelines for satellite-based communication networks 5 May. One of the key themes is localization.",
            "For example, under these guidelines, network control centers, gateways and lawful interception and monitoring systems need to be located within India. Services are required to be geofenced within India with real-time location tracking of all user terminals. User registration and authentication needs to occur domestically. Further, copying or decryption of Indian telecommunication data outside the country is prohibited. These have been as expected, given the heightened focus on national security after the recent geopolitical conflict in the Indian subcontinent.",
            "While policymakers and governments do their bit to set new regulations, the courts march ahead within the existing legal framework.",
            "Recently, the Allahabad High Court in the state of Uttar Pradesh held that someone liking a social media post does not amount to the person publishing or transmitting the same. This came about as part of a case in which the state accused an individual of a series of crimes owing to his post published on social media. The defendant claimed he had merely liked the post.",
            "Further south, the Karnataka High Court dismissed a petition by a leading fintech payments company that refused to provide police with requested information related to a 2022 online sports betting case. In the 29 April decision, the court said, \"confidentiality must coexist with accountability\" and the \"submissions of the petitioner's counsel that information that is to be kept confidential need not be divulged, cannot be accepted. The protection of consumer privacy cannot eclipse the lawful imperative of investigating officers to secure evidence and take the investigation to its logical conclusion.\"",
            "Meanwhile, some interesting reports were published, including one on the AI front. The government of India has been investing and encouraging AI initiatives and capacity building. The IndiaAI mission was made a budget allocation last year of 100 billion rupees, nearly half of which was allocated towards building computing capacity in the country. A recent \"State of AI Governance\" report by the Takshashila institution cautions that bureaucratic processes may leave the computing infrastructure underutilized.",
            "Another report by Thales security said that\u00a073% of respondents from India are investing in AI-specific security tools while 60% of respondents identify future encryption compromise as one of the major concerns around quantum computing security threats.",
            "A third report titled \"How AI is Reshaping the Financial Planning Profession\" was from FPSB India, the Indian subsidiary of the Financial Planning Standards Board, that captured financial planners' responses on the use of AI. The report said that despite the benefits, the planners had reservations regarding the use of AI, with 47% citing data privacy and cybersecurity concerns. Further, \"about 42% of financial companies' top executives are still concerned about the accuracy and reliability of AI outputs.\"",
            "All in all, the further we march forward with AI and data, the more new problems we encounter that need to be resolved.",
            "Shivangi Nadkarni is senior vice president and general manager, digital governance at Persistent Systems Ltd.",
            "This article originally appeared in the Asia-Pacific Dashboard Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-iapp-europe-it-s-a-gdpr-week",
        "title": "Notes from the IAPP Europe: It's a GDPR week",
        "location": "Europe",
        "date_published": "22 May 2025",
        "keywords": [
            "AI Governance",
            "Data Processing",
            "Data Protection Obligations",
            "International Data Transfers",
            "Law & Regulation",
            "Data Security"
        ],
        "description": "The EU General Data Protection Regulation will soon celebrate its ninth anniversary since its 2016 adoption and the law still knows how to make an entrance. This week saw a whirlwind of news on two key policy initiatives pertaining to the GDPR's application.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "The EU General Data Protection Regulation will soon celebrate its ninth anniversary since its 2016 adoption and the law still knows how to make an entrance. This week saw a whirlwind of news on two key policy initiatives pertaining to the GDPR's application.",
            "The GDPR will not be reopened. This statement was repeatedly voiced by the European Commission throughout last year. However, with competitiveness being a top priority of the Von der Leyen II Commission, it is to no surprise that the upcoming digital omnibus package \u2014 which, as part of the Commission's wider plans to simplify EU rules, is set to minimize the EU digital framework's constraints on small- and medium-sized enterprises and small midcaps \u2014 includes targeted revisions to the GDPR.",
            "Earlier this year, EU Commissioner for Democracy, Justice, the Rule of Law and Consumer Protection Michael McGrath unveiled the contours of the GDPR simplification plan, emphasizing it would be limited to revisiting record-keeping requirements to reduce compliance burdens for smaller businesses with limited resources.",
            "The European Commission proposed the regulation for GDPR simplification 21 May. The proposed changes concern a few articles, including Article 30(5), which currently provides an exception to the requirement for companies to keep detailed records of their processing activities, such as information on the categories of data processed, international data transfers and technical and organizational security measures. The Commission proposes expanding the scope of the current derogation to include small mid-cap enterprises and organizations with less than 750 employees.",
            "The exception to this derogation has also been modified. It would only apply to processing that poses a highrisk to data subjects' rights and freedoms, as defined in Article 35. Additionally, the non-occasional processing exception has been removed, and a recital has been added allowing the processing of special categories of personal data to qualify for the record-keeping exception under certain circumstances.",
            "The proposal is a first step in the simplification agenda of the GDPR. Although the Commission has identified several areas of friction in GDPR implementation over the years, it is not clear whether it will take steps to tackle additional areas beyond this week's proposal.",
            "In a joint letter published before the proposal was tabled, the European Data Protection Board and European Data Protection Supervisor express preliminary support for the initiative. However, they highlighted the importance of ensuring a risk-based approach of the legislation is retained irrespective of a company's size.",
            "The digital omnibus package, set to be published in the last quarter of 2025, is expected to also simplify cybersecurity reporting requirements, touch upon certain data sharing rules and even address the Artificial Intelligence Act.",
            "On 21 May, the European institutions held what was expected to be the final trilogue on the proposal for a regulation on additional procedural rules concerning GDPR enforcement.",
            "The interinstitutional negotiations on the file that aims to streamline procedural rules for GDPR enforcement in cross-border cases started in November 2023. In the final meetings, co-legislators were trying to find an agreement on topics such as deadlines, including the nuances for their extension, remedies in case of the lead data protection authority's inaction or overly long procedures and the right to be heard in front of the EDPB.",
            "These issues remain in deadlock, putting a question mark on whether an agreement on this file will be possible before the summer break, a priority for the Polish presidency of the European Council. It remains to be seen how the final version of the file will align with recent developments in the field, such as the advocate general's opinion concluding an organization may challenge an EDPB decision directly before the Court of Justice of the European Union, or the GDPR simplification plans kickstarting.",
            "Laura Pliau\u0161kait\u0117 is European operations coordinator for the IAPP.",
            "This article originally appeared in the Europe Data Protection Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/we-cannot-be-left-behind-how-canada-is-balancing-ai-regulation-innovation",
        "title": "'We cannot be left behind:' How Canada is balancing AI regulation, innovation",
        "location": "North America",
        "date_published": "21 May 2025",
        "keywords": [
            "Government",
            "AI Governance",
            "Data Protection Obligations",
            "Frameworks & Standards",
            "Law & Regulation",
            "Risk Management",
            "Strategy & Governance"
        ],
        "description": "While global jurisdictions are taking different approaches to tackling artificial intelligence, the debate over innovation versus regulation is a common thread. Though Canada is not shying away from the balancing act, it does not yet have consensus on the means to find equal footing.",
        "content": [
            "While global jurisdictions are taking different approaches to tackling artificial intelligence, the debate over innovation versus regulation is a common thread. Though Canada is not shying away from the balancing act, it does not yet have consensus on the means to find equal footing.",
            "Prime Minister Mark Carney emphasized plans for Canada's AI transformation while on the campaign trail and recently appointed a federal AI minister to his cabinet who will oversee the implementation of those endeavors. What remains unclear is the regulatory balance, as provinces begin to address AI safety and governance in the absence of federal action.",
            "The Parliament of Canada worked toward an answer with proposed AI regulation packaged into the omnibus Bill C-27, which was considered across two legislative cycles. Lawmakers held countless hearings on the bill during the last legislative session, including debate over whether AI regulation required separation from the digital omnibus that would simultaneously update Canada's federal private-sector privacy law.",
            "Bill C-27 was ultimately abandoned with the legislative docket cleared ahead of national elections, where the Liberal Party maintained control of the government.",
            "Privacy Commissioner of Canada Philippe Dufresne told IAPP Canada Privacy Symposium attendees he expects AI regulation \"will again become a legislative priority\" with the aim to \"ensure that Canadians remain protected in a modern world and to provide a framework within which the digital economy can thrive.\"",
            "\"AI\u00a0holds incredible promise in advancing innovation, efficiency, and convenience \u2014 and for Canadians to fully embrace it, they must have confidence that it is being developed and deployed in a responsible and privacy preserving manner,\" Dufresne said in his CPS keynote remarks.",
            "The 45th Parliament begins 26 May. There is not yet an indication if Bill C-27 will be reintroduced or if lawmakers might opt for a different legislative vehicle to cover AI.",
            "Despite the parliamentary debate whether potential AI and privacy regulatory overlap makes sense, much attention is being paid to how safety and transparency measures can cover multiple digital fields, including AI.",
            "Dufresne described the current crossroads as \"a pivotal moment\" in a growing digital economy where the Canada \"cannot be left behind\" and \"must be at the table.\" That urgency has led Dufresne into domestic and international partnerships that aim to \"develop and champion privacy principles that will support\u00a0AI\u00a0technologies that are designed and built on a solid foundation.\"",
            "Specifically on the international level through recent G-7 Data Protection Authorities Roundtables, the Office of the Privacy Commissioner is building out the blueprint for how AI requires privacy considerations.",
            "\"Our work has also emphasized the need for developers and providers of generative\u00a0AI\u00a0to embed privacy in the design, conception, operation, and management of new products and services, and that they consider the unique impact that these tools have on children as well as on groups that have historically experienced discrimination or bias,\" Dufresne said.",
            "There is potential for fragmentation on AI regulation in the face of federal inaction. Provincial governments are beginning to turn the gears, with Ontario and Quebec boasting new requirements around various AI development and use.",
            "Ontario's Bill 194, the Strengthening Cyber Security and Building Trust in the Public Sector Act, places guardrails around public-sector AI development and use. Quebec's Law 25 is a modernization of private-sector privacy law that contains associated AI provisions, including those covering automated decision-making technology.",
            "A CPS breakout session dove into the perceived peaks and valleys in Ontario's AI governance landscape, which includes the Responsible Use of Artificial Intelligence Directive for public entities in addition to Bill 194.",
            "According to Ontario's new law, covered entities will follow \"requirements to provide information, to develop and implement accountability frameworks and to take steps respecting risk management.\" Additionally, the statute also calls for human oversight and promulgation of technical standards where necessary.",
            "Bill 194 is not yet fully in effect, with final regulations required to implement AI provisions.",
            "The directive, which took force December 2024, is similarly prescriptive with six responsible use principles and separate requirements. AI risk management, disclosure and reporting, and transparency around purpose comprise the requirements.",
            "Melissa Kittmer, assistant deputy minister of strategic policy at Ontario's Ministry of Public and Business Service Delivery and Procurement, highlighted the differences between the law and directive. She noted the directive has applicability across Ontario ministry and provincial-level agency use of AI, while potential regulations under the law could cover AI in select public sector organizations.",
            "Notably with the directive, Kittmer pointed to the definition for \"AI use case\" as the linchpin for \"the framework around when requirements come into play.\" She also defended the effectiveness of the directive, which isn't viewed as stringent as law or regulation.",
            "\"It's not just a guidance,\" Kittmer said, noting that the directive is issued under legislation. \"If you're issuing guidance, it's sort of saying, 'Here are best practices or things you should consider.' A directive does set out requirements.\"",
            "University of Ottawa Canada Research Chair in Information Law and Policy Teresa Scassa acknowledged Ontario's initiatives for AI guardrails are \"important steps,\" but she still believes there's \"room for more\" that could help inform federal measures. She zeroed in on transparency, specifically highlighting \"the need to show your work\" and how essential it is to increase public trust the government's AI endeavors.",
            "\"I think that's another piece of the puzzle. The ability to look under the hood to some extent, see what's happening, follow what's happening and criticize what's happening,\" Scassa said. \"Public engagement is good, but there has to be enough space and time for the public to engage, and for that engagement to be taken on board and make a difference.\"",
            "Joe Duball is the news editor for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/the-ethical-use-of-ai-in-advertising",
        "title": "The ethical use of AI in advertising",
        "location": "",
        "date_published": "21 May 2025",
        "keywords": ["Advertising & Marketing", "AI Governance"],
        "description": "Artificial intelligence is reshaping the advertising industry, enabling unprecedented levels of personalization, efficiency and audience targeting. The IAPP's AI Governance Profession Report 2025 shows that across sectors, 16% of companies use AI for personalizing experiences and 16% use it for customer interactions. Among marketers, 69% have already integrated AI into their marketing operations, with nearly 20% allocating more than 40% of their budget to AI-driven campaigns.\u00a0\u00a0",
        "content": [
            "Artificial intelligence is reshaping the advertising industry, enabling unprecedented levels of personalization, efficiency and audience targeting. The IAPP's AI Governance Profession Report 2025 shows that across sectors, 16% of companies use AI for personalizing experiences and 16% use it for customer interactions. Among marketers, 69% have already integrated AI into their marketing operations, with nearly 20% allocating more than 40% of their budget to AI-driven campaigns.\u00a0\u00a0",
            "However, as AI becomes increasingly embedded in advertising strategies, it also raises significant ethical concerns, from data privacy risks to algorithmic bias and the potential for consumer manipulation.\u00a0",
            "These challenges cannot be addressed by technology alone \u2014 they require a collaborative approach among stakeholders who shape the advertising ecosystem, including regulators, advertisers, technology companies, civil society organizations and consumers themselves. By fostering transparency, fairness and human oversight, a stakeholder-driven approach can help align AI-powered advertising with ethical principles and societal values.\u00a0",
            "Many entities across the advertising sector have built responsible AI use policies that identify and counteract potential risks associated with using AI in their organizations. In a survey of AI risks that sampled entities ranging from trade organizations like the Association of National Advertisers to large marketing companies like Salesforce to self-regulatory agencies like the Children's Advertising Review Unit, some risks popped up again and again: algorithmic bias, hallucinations, data privacy risks, confusion over whether something is AI-generated and intellectual property concerns.\u00a0",
            "Algorithmic bias, when an algorithm generates unfair or discriminatory outputs, can harm businesses in several ways. For example, marketing campaigns may be mistargeted based on inaccurate assumptions or businesses may make flawed product decisions about things customers do not actually want. Hallucinations, where an AI generates outputs that are false or fabricated, similarly produce results that can be anywhere from useless to misleading. The most robust policies combat these possibilities both proactively and reactively.\u00a0",
            "Marketers can protect against potential algorithmic bias and hallucinations at each step of AI deployment, starting with training the AI on a high-quality, high-quantity dataset. \"Biased data and biased models lead to biased results,\" Jennifer Chase, chief marketing officer and vice president of SAS wrote in an article for Forbes. AI models trained on broad, well-audited datasets are more likely to accurately predict the real world. To this end, multiple companies have created tools that make obtaining and vetting databases easier. Google has released Dataset Search, a large repository of datasets that are freely available on the web. Amazon's SageMaker Ground Truth offers human input at multiple points in the training process, such as giving human feedback on the quality of a model's responses or labeling data to more easily train an AI.\u00a0\u00a0",
            "Policies from companies like Salesforce and PricewaterhouseCoopers stress the importance of building guardrails into the AI before deployment and testing and retesting outputs after deployment. For instance, Salesforce's hallucination reduction policies restrict a model's output to a specified scope, and their mindful friction practice introduces \"pauses in the user experience to ensure intentional human engagement at critical junctures.\" PwC's Responsible AI playbook recommends training employees to know \"how to verify GenAI's outputs, create channels to report suspect results, and establish a risk-based system to review these outputs.\"\u00a0",
            "Even when an AI's inputs are good quality, training AI is a continual process, so auditing an AI's outputs can show if the model needs to be updated or corrected. Some marketing policies require regular evaluations using tools like TensorFlow's Fairness Indicators or IBM's AI Fairness 360, which check for skewed data. Human viewpoints can also provide valuable insight; it can be easy to spot larger errors, but experts can identify subtle hallucinations or bias and help to correct them.\u00a0",
            "A report and recommendation from the International Advertising Bureau collected advice from such experts, many of whom advocate for vigilant analysis of the AI to avert hallucinations or bias. Noticing flaws in a model does not necessarily indicate malintent \u2014 they can happen even \"where perfectly well-meaning models deployed by very smart people learned to do things they were not intended to do, (which can) cause brand damage.\"\u00a0",
            "Another way to mitigate the risk of hallucinations or bias is to limit how AI is used. The EU AI Act defines some AI uses as higher risk than others and imposes more stringent requirements for higher-risk applications. Recognizing this concern, some marketing policies advise against using AI to determine if an individual is eligible for employment, credit, health care, housing or other decisions with legally significant effects. 2X Marketing's policy bars employees from using AI for human resource-related matters like recruitment and hiring, while consumer goods giant Unilever's policy requires that \"any decision that has a significant life impact on an individual should not be fully automated.\" Such limitations and human oversight can help recognize potential issues before a consumer ever interacts with an AI.\u00a0",
            "Every phase of an AI's life cycle \u2014 from training to deployment \u2014 depends on data: the datasets that train it, the inputs it consumes, and the feedback loops that refine its model. Each of those stages can expose an individual's personal information, whether from proprietary customer records in a training corpus, sensitive information a customer submits to a chatbot, or usage logs that go into model updates. Given just how much data an AI needs, these risks can seem daunting, but lawmakers, regulators and professionals alike are developing structured ways to evaluate and mitigate these concerns.\u00a0\u00a0",
            "Many AI and data privacy laws around the world, including state laws in the U.S., require covered entities to conduct privacy impact assessments, also called data protection impact assessments. The U.S. Department of Commerce's Office of Privacy and Open Government defines a PIA as an \"analysis of how information in identifiable form is collected, maintained, stored, and disseminated, in addition to examining and evaluating the privacy risks and the protections and processes for handling information to mitigate those privacy risks.\"\u00a0\u00a0",
            "Many companies must conduct these assessments already, so extending them to AI systems provides a clear way for companies to understand the provenance of their data and identify points where their systems could be more robust.\u00a0",
            "Frameworks like the conformity assessment procedure for AI created by experts from the University of Oxford and the University of Bologna provide additional assessment methods that businesses can use to \"prevent or minimise the risks of AI behaving unethically and damaging individuals, communities, wider society, and the environment.\" These systems give businesses actionable steps to take so they can adapt to rapidly developing legislation and regulations. They also emphasize the importance of clear communication with consumers about how AI interacts with their data.\u00a0",
            "The Association of National Advertisers' Ethics Code of Marketing Best Practices advocates for marketers to also implement notice and transparency measures so that consumers know what data is being collected when and for what purpose. Surveys like this one from Pew Research show that consumers often do not know when they are interacting with an AI, and often when a product is advertised as using AI they might not understand what purpose the AI serves. However, consumers express that they want transparency surrounding AI use in marketing and media. They are more likely to trust companies that have policies on how to use AI ethically.\u00a0",
            "Weaving technical controls and governance processes through every stage of the AI life cycle, from data collection to data curation to model training to deployment and beyond, builds a more resilient system. By adopting these principles, the advertising industry can ensure that AI-driven marketing remains ethical, consumer-friendly and aligned with broader societal values.\u00a0\u00a0",
            "Based on the key principles earlier laid out, there are many good practices that any sized business can observe when using AI:\u00a0",
            "Establish clear guidelines and policies for the use of AI in marketing.\u00a0",
            "Train employees on ethical AI practices.\u00a0",
            "Implement appropriate data governance procedures.\u00a0\u00a0",
            "Diligently monitor AI systems and conduct audits.\u00a0",
            "Protect consumer rights and welcome productive feedback.\u00a0",
            "Verify and fact-check all content, regardless of origin.\u00a0",
            "By prioritizing the ethical use of AI in marketing, businesses have a great opportunity to cultivate trust with their consumers. And the ethical use of AI in marketing is not only instrumental for fostering consumer trust, but also for making the most out of the technology itself as businesses are able to align their AI systems with social norms and values.\u00a0\u00a0",
            "Furthermore, with uncertainty around the future of third-party cookies and other foundational advertising methods, the adtech industry can benefit by supplanting their existing methods with AI. Potential uses for AI in marketing continue to multiplying exponentially, ranging from generating ad copy and images to analyzing campaign metrics from anonymized datasets to automating customer service and beyond; indeed, more uses seem to pop up every day.\u00a0",
            "However, precisely because AI has so many potential uses, adhering to ethical standards and having infrastructure can help limit those uses to what is necessary or helpful to a business. When you have a hammer, everything can look like a nail, so it's wise to identify what problems AI can help with and how exactly businesses can use it to solve those problems.\u00a0\u00a0",
            "Keeping these principles in mind also aids in future-proofing organizational practices against the whirlwind of shifting legislation, regulations and rules. Adhering to best practices helps businesses to anticipate future compliance requirements, and having governance infrastructure in place can aid in adapting when those compliance requirements change.\u00a0",
            "AI continues to redefine the landscape of advertising, so ensuring its ethical deployment will be critical in preserving consumer trust and upholding industry standards. By adhering to principles like fairness, transparency, privacy protection and human oversight, businesses can not only mitigate risks but also harness AI's potential responsibly.\u00a0\u00a0",
            "As AI-driven marketing becomes increasingly sophisticated, a thoughtful, proactive approach will be key to responding to the whirlwind of technological and regulatory changes that define the field of AI right now. Establishing solid, organization-wide principles builds resilience and fosters a future where innovation thrives without compromising ethical standards or consumer rights.\u00a0",
            "C. Kibby is a Westin Research Fellow for the IAPP.",
            "Special thanks to Aly Apacible-Bernardo, former legal research associate for the IAPP,\u00a0for her research contributions during the drafting of this article."
        ]
    },
    {
        "url": "https://iapp.org/news/a/gdpr-reform-opening-pandora-s-box",
        "title": "GDPR reform: Opening Pandora's box",
        "location": "Europe",
        "date_published": "21 May 2025",
        "keywords": [
            "Data Protection Obligations",
            "Law & Regulation",
            "Privacy Program Management"
        ],
        "description": "Translating to \"all-gifted,\" or \"she who sends up gifts\" the Greek myth goes that Pandora was created by the gods and bestowed with blessings and charms. In many ways, she was made and seen as perfect. Told never to open a jar, latterly mistranslated as a box, curiosity got the better of Pandora and, in opening the jar, she released all manner of evil.",
        "content": [
            "Translating to \"all-gifted,\" or \"she who sends up gifts\" the Greek myth goes that Pandora was created by the gods and bestowed with blessings and charms. In many ways, she was made and seen as perfect. Told never to open a jar, latterly mistranslated as a box, curiosity got the better of Pandora and, in opening the jar, she released all manner of evil.",
            "The EU General Data Protection Regulation, and EU data protection law more broadly, have been heralded as the \"gold standard.\" It has been an archetypal regulatory product and progenitor of the \"Brussels effect.\" Urged on by the reports of two former Italian Prime Ministers Enrico Letta and Mario Draghi and in approaching its ninth anniversary since adoption, and seventh since becoming applicable, EU policy and lawmakers are considering whether and how to reform the GDPR in ways that support the competitiveness of European enterprises by not \"imposing unnecessary burden.\"",
            "The proposal concerns limited and targeted changes to the GDPR in view of simplifying it or extending certain measures currently applicable to small and medium-sized enterprises to include small mid-cap enterprises that have \"outgrown the SME definition.\"",
            "Article 30 of the GDPR requires data controllers and processors to maintain a record of data processing activities and prescribes out what information this record should contain, such as the purposes of the processing, the description of the categories of data, the categories of third-party recipients of the data and, where possible, a description of technical and organizational security, among other matters.",
            "The GDPR provides an exemption to that requirement where the data controller or processor has fewer than 250 employees unless the data processing in question is likely to result in \"a risk\" to the rights and freedoms of data subjects, the processing is not occasional or the processing includes special categories of data or criminal conviction and offensive data.",
            "The European Commission proposal purports to \"simplify and clarify\" this exemption in two ways.",
            "First, by extending the exemption to small and mid-cap enterprises with fewer than 750 employees. Second, by making the record-keeping obligations mandatory for those SMEs only when the processing activities are likely to result in a \"high risk\" to data subjects' rights and freedoms or where special category data is processed. The proposal clarifies that the processing of special categories of personal data that is necessary for the purposes of carrying out the obligations and exercising specific rights of the controller or of the data subject in the field of employment and social security and social protection law should not \"as such\" trigger the requirement for maintaining records of processing.",
            "The proposals, codified in a draft regulation, were the subject of a joint letter, published earlier in May, by the European Data Protection Board and the European Data Protection Supervisor setting out their preliminary feedback. The EDPB and EDPS welcomed that the obligation to keep records of processing activity would still be required for likely high-risk processing, recalling how \"even very small companies can still engage in high-risk processing.\" Notably, in that letter, the EDPB and EDPS understood the European Commission to be considering a proposal to extend the exemption to organizations with fewer than 500 employees and with a certain annual turnover, not 750.",
            "Separately, the European Commission proposes reforms to the GDPR provisions on data protection codes of conduct and certification mechanisms. Under current Article 40, the EU member states, respective national data protection authorities, the EDPB, and the European Commission are required to encourage the drawing up of codes of conduct by relevant associations and other organizations representing data controllers and processors.",
            "Similarly, Article 42 requires the same stakeholders to encourage the establishment of data protection certification mechanisms, seals and marks by relevant certification bodies or DPAs. The reforms seek to extend the requirement to have consideration of micro, small and medium-sized enterprises to the new proposed definition of SMCs, so that the \"specific needs\" of SMCs are taken into account.",
            "Thus far, initiatives regarding GDPR codes of conduct and certification mechanisms have been few and far between. Though substantively modest, the winds of change and emphasis on innovation, competitiveness and \"simplification\" might engender renewed efforts.",
            "Though not as profound as the consequences of the opening Pandora's box, the reopening of the GDPR will now animate heightened consultation, discussion and debate on whether and where to redraw the lines set in 2016, if not earlier under the GDPR's predecessor, the Data Protection Directive, which was finalized 30 years ago.",
            "For all the reported hardships associated with the purported burdens of the GDPR, many organizations have nonetheless invested considerable capital and resources in GDPR compliance, much of which has extended to other compliance requirements contained in the panoply of EU digital regulation and broader business objectives.",
            "Whether and how organizations adapt and adjust to the proposed requirements, and the impact to the EU's stated objectives, will be in the spotlight over the coming months, and perhaps even years, while these proposals move through the legislative machinery.",
            "Joe Jones is the Research and Insights director for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/mind-matters-shaping-the-future-of-privacy-in-the-age-of-neurotechnology",
        "title": "Mind matters: Shaping the future of privacy in the age of neurotechnology",
        "location": "",
        "date_published": "19 May 2025",
        "keywords": [
            "Health Care",
            "Technology",
            "AI Governance",
            "Identity & Verification",
            "Law & Regulation",
            "IoT & Personal Devices"
        ],
        "description": "Technology has reached the next level, breaching the final frontier of privacy: our innermost thoughts and feelings.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "Technology has reached the next level, breaching the final frontier of privacy: our innermost thoughts and feelings.",
            "We will soon live in a world where technology can access the mind. In the near future, this technology could be a part of mainstream consumer products. In the distant future, it might not be optional.",
            "Businesses developing neurotechnologies are at a pivotal moment and must decide how to design their products with mental privacy concerns in mind, to bring about the best possible outcome for themselves, consumers and society.",
            "Today, there are devices in development \u2014 or already available in some cases \u2014 that can be implanted in the brain or worn externally to detect electrical activity and other brain signals, essentially reading the mind. Aided by artificial intelligence, these devices can detect whether you're paying attention, whether you like what you're seeing, your political leanings and even whether you've seen something before.",
            "Brain signals can reveal a great deal about a person: their truthfulness, personal feelings, political leanings, propensity to spend money and risk tolerance.",
            "But it doesn't stop there. These devices not only read the mind \u2014 they can \"write\" to it. They can stimulate the brain to cause a reaction.",
            "This technology holds remarkable promise. It could help ALS patients and individuals with paralysis use their minds to control their environment \u2014 keyboards, exoskeletons, wheelchairs. It could allow people who are unable to communicate with others to speak for the first time in decades. It could warn an epileptic of an impending seizure or train someone to reach a meditative state to manage anxiety or stress.",
            "It could also be used to investigate crimes by detecting whether a suspect has seen a crime scene, monitor employee engagement or student attentiveness, gauge consumer reactions to advertisements or products, and enhance soldiers' cognitive abilities \u2014 or sabotage those of adversaries.",
            "During the last few decades, as technology has advanced to the detriment of personal privacy, one assumption has remained intact: that the mind \u2014 the sanctity of one's innermost thoughts and feelings \u2014 would always remain private. These emerging neurotechnologies challenge that assumption, presenting businesses, consumers and regulators with an entirely new paradigm to navigate.",
            "As history has repeatedly shown, industries that fail to self-regulate often find themselves facing legislative intervention. When it comes to privacy, the lesson is clear: businesses can shape their own destiny by proactively adopting ethical design principles and building trust with consumers.",
            "Otherwise, statutory regulation \u2014 often reactive and ill-suited to the fast-paced evolution of technology \u2014 will almost certainly emerge.",
            "For businesses in the neurotechnology space, this is a moment to act, not just to avoid future compliance headaches but also to build a competitive advantage by leading the charge on privacy innovation.",
            "Whether mental privacy becomes protected by self-regulation or statutory regulation, businesses can learn from history to anticipate what the future might hold. Examining the successes and failures of privacy regulation over the last three decades provides valuable lessons for charting a path forward.",
            "Notice and choice have historically been the foundation of many global privacy laws. This framework requires businesses to notify individuals of their data collection and provide them the option to opt out of certain business uses and disclosures of their private information.",
            "While this approach may seem straightforward, many feel it has proven inadequate in practice. Real-life consumers rarely read or fully understand privacy notices. Moreover, neural data, due to its intrinsic and involuntary nature, can reveal far more about an individual than they might expect.",
            "As a result, many privacy experts now suggest a shift away from reliance on notice and choice. Instead, they propose establishing clear rules delineating what businesses can and cannot do with sensitive personal data, including neural data. Early signs indicate mental privacy laws may move in this direction, reflecting a more proactive and protective regulatory approach.",
            "Currently, three U.S. states \u2014 California, Colorado and Montana \u2014 have introduced specific provisions protecting neural data through amendments to their broader consumer privacy laws. These states recognize data derived from the central or peripheral nervous system as sensitive personal information deserving heightened legal protection.",
            "The Colorado Privacy Act says businesses must:",
            "The California Consumer Privacy Act is similar to Colorado's law, but less stringent in some ways and more stringent in others. Instead of requiring affirmative consent, it grants consumers the limited right to opt out of the collection and use of their neural data. If a consumer takes no action, businesses may collect their data by default. However, California's law extends its protections to employees as well as consumers, broadening its scope compared to Colorado's legislation.",
            "Also, California's law requires that businesses present a privacy \"notice at collection\" to consumers, in addition to a posted privacy policy, and the notice of collection must inform consumers how long they will retain neural data, or the criteria they will use to determine the retention period.",
            "Montana's law goes beyond the Colorado and California laws' requirements. The Montana legislature passed Senate Bill 163 in recognition that the use of neurotechnologies outside of medical settings is not covered by health data privacy laws, and therefore was left unregulated. In the bill's declarations, the legislature recognized that each human brain is unique, and that neural data is specific to the individual from whom it is collected. Because it contains distinctive information about the structure and functioning of an individual's brain and nervous system, the Montana legislature declared neural data can be linked to an identified or identifiable individual.",
            "This finding is relevant under other laws, the Colorado Privacy Act, for example, that only apply to biological data that is intended to be used to identify a specific individual, leaving it unclear whether it applies to neural data. The Montana legislature apparently thinks that it could. Montana's bill became law on 2 May, after 10 days passed without the governor signing or vetoing it.",
            "In addition to California, Colorado and Montana, there are 15 state bills pending that would specifically regulate neural privacy.",
            "Outside the U.S., regulatory bodies in Europe and the U.K. have crafted similar guardrails for the collection and use of neural data.\u00a0 In South America, Chile's constitution contains a privacy right for neural data, which has already been successfully enforced in a court. These early guidelines reflect a growing consensus on the need to treat neural data as highly sensitive and deserving of robust protections.",
            "Both self-regulation and statutory regulation for mental privacy are still in their infancy. However, neurotechnology companies can take proactive steps now to anticipate future regulatory trends, align with consumer expectations, and avoid costly compliance pitfalls. There are key elements businesses should consider incorporating into their product development processes.",
            "Achieve true transparency. Go beyond privacy policies to meaningfully inform consumers of what your products do and how their neural data will be used. Communicate this information in ways that are upfront, clear, timely and easily understood.",
            "Provide a tangible value exchange. Demonstrate to consumers the value they receive in exchange for sharing their neural data. For instance, sharing brain data might enable your business to improve the product for everyone who uses it.",
            "Define long-term use cases: Think ahead and be upfront about all potential future uses of neural data. Avoid surprising consumers with new purposes that were not disclosed at the outset.",
            "Empower consumers with control. Offer individuals the ability to access, correct or delete their brain data and to decide about any secondary uses not necessary for the primary service they requested.",
            "Build security by design. Protect neural data from unauthorized access by storing it locally on consumer devices, encrypting it, and ensuring the business does not control the decryption keys. Configure the app with unique credentials so the data is not unlocked via single sign-on with the device itself or a third-party account. If your technology can stimulate the brain, build in guardrails to prevent this from happening inadvertently, or worse, by nefarious actors.",
            "Future-proof data anonymity. Anticipate advances in identification technology by exceeding current de-identification standards.",
            "Prepare for law enforcement requests. Mental data could be highly valuable in a criminal investigation. Establish clear policies for handling requests from law enforcement to access neural data. Proactively communicate these policies to your customers to build trust.",
            "Prepare for diligence scrutiny. Emerging companies should design privacy-forward products with the expectations of potential investors or acquirers in mind. Design products with these considerations in mind and document them through internal and external written policies and procedures.",
            "By prioritizing privacy and ethical design now, businesses can not only gain consumer trust and differentiate themselves in the market but also shape the regulatory landscape to work in their favor, ensuring long-term success and sustainability.",
            "In doing so, neurotechnology companies can navigate this frontier with foresight, balancing innovation with respect for the most personal frontier of all: the human mind.",
            "Kristen Mathews, CIPP/US, is a partner in the cybersecurity, data protection and privacy practice group at Cooley LLP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/transparency-good-data-and-documentation-how-hr-can-navigate-the-eu-ai-act",
        "title": "Transparency, good data and documentation: How HR can navigate the EU AI Act",
        "location": "Europe",
        "date_published": "19 May 2025",
        "keywords": [
            "AI Governance",
            "Employment Privacy",
            "Law & Regulation",
            "Data Protection Obligations"
        ],
        "description": "With the EU Artificial Intelligence Act's inclusion of workplace AI under its prohibited uses, human resource departments are now tasked with re-examining their various AI applications to meet compliance requirements.",
        "content": [
            "With the EU Artificial Intelligence Act's inclusion of workplace AI under its prohibited uses, human resource departments are now tasked with re-examining their various AI applications to meet compliance requirements.",
            "AI used in employment and the workplace is considered \"high-risk\" under the AI Act and thus subject to legal stipulations if it can affect a person's health and safety or employment. Its use in emotional recognition systems in the workplace is prohibited.",
            "Not all HR-focused AI deployments are considered high risk, according to Cian O'Brien, the deputy data protection commissioner for Ireland's Data Protection Commission. But those wondering how to make that distinction should consider how regulators have approached AI already through existing regulations, most notably the EU General Data Protection Regulation.",
            "\"Data protection regulators are already taking the obligation to conduct (data protection impact assessments) as extremely seriously in the context of AI systems,\" O'Brien said during a panel at the IAPP AI Governance Global Europe 2025 in Dublin.",
            "It was a refrain heard throughout the conference as AI stakeholders gear up for enforcement of the landmark AI regulation, which is in the early stages of enforcement and still has many unknowns as to how certain aspects will play out. Technology leaders urged attendees to prepare for uncertainty but noted longstanding data protection principles in the EU can provide guidance.",
            "Standard data transparency practices, including proper documentation and purpose limitation, apply to AI use cases. But before any of that, UKG Senior Managing Counsel for Privacy and Compliance Noemie Weinbaum, AIGP, CIPP/E, CIPP/US, CIPM, CDPO/FR, FIP, said any use of AI in HR should begin by answering a central question.",
            "\"You need to know and understand what problem you're trying to solve when using AI,\" she said. \"Once you've stated this, then you can go back and review holistically what needs to be put together, make sure that it's transparent throughout the chain, so that you have answers to your customers and those customers have answers to their own employees.\"",
            "Being open about why you are collecting data and what it is used for clears up a lot of potential problems early on, AIGG panelists said.",
            "The DPC's O'Brien said the initial transparency helps build the case for legitimate interests, even with a low-risk AI use. The clarity also supports the concept of freely given consent for the data collection, a cornerstone of the GDPR.",
            "There is precedence for this, noted K&L Gates Partner Claude Etienne Armingaud, CIPP/E. The AI Act was not being enforced when France's Nanterre Judicial Court ruled a company did not properly consult the Social and Economic Committee before rolling out AI tools on a wider scale.",
            "\"And so, the Supreme Court just ordered the whole AI deployment to be scrapped and go back to the drawing board in terms of involving the employee representative, informing them about what the AI was doing and how it was doing it,\" he said. \"It's a matter of building that trust through transparency, consultation and managing the expectation of the data subject.\"",
            "UKG Legal Director Roy Kamp, AIGP, CIPP/E, CIPP/US, CIPM, FIP, indicated transparency does not stop at your institution \u2014 you need as much insight into how your vendor operates too, as many HR shops are more likely to have purchase a third-party product.",
            "\"You need to understand, not just from the vendor, what they're doing, but also what is their supply chain doing, and understand that, so you're able to then share it with the employees to be able to get that informed consent,\" he said.",
            "Removing identifying characteristics from an AI model's training data has been viewed as one way to ensure privacy and data protection. But the manner in which it is done can leave room for reidentification, thus leaving processing open for scrutiny.",
            "It is a point Kamp and Weinbaum have made before. Anonymization allows for the permanent removal of identifiers, however, Kamp said AI could make true anonymization even more challenging for HR departments.",
            "\"The data set might be anonymized today, but then you come up with an AI algorithm in six months' time or a year's time that manages to pull data from other sources, and all of a sudden you've re-identified it,\" he said. \"So have a think about that \u2026 is it truly anonymized, and if it is, would it be better for you to treat it as pseudonymized data rather than anonymized data?\"",
            "Weinbaum added companies are required to ensure the data they use in AI remains confidential for other customers and employees alike and thus be skeptical of vendors' claims of untraceable information. She noted the AI Act requires AI tools to be robust and said such standards are likely unachievable with synthetic information alone.",
            "\"I mean, it's a great hope, but in real life, it is not working,\" she said. \"You don't want to be using HR tools based on AI that are not robust, that are not delivering more or less the promises that the vendors are making.\"",
            "After deciding if a particular AI use is high risk and training data is sufficiently protected, O'Brien said HR departments must make a clear case as to how decisions toward using an application was made.",
            "Retroactively explaining an approach is not enough under the GDPR, as contemporaneous documents need to be on hand to justify reasoning. The AI Act also requires high-risk systems to have documentation on how it works and what risks it can pose, with requirements for regularly updated information.",
            "O'Brien said DPIAs are the best means supporting a use case, as they help regulators understand all facets of the decision-making process.",
            "\"That's really what can back up a good story,\" he said \"And the fact that you've taken account of data subjects, rights and freedoms under GDPR when designing your systems by means of data protection by design.\"",
            "O'Brien added documentation around why a DPIA was not needed is also important, noting again that not all HR AI uses may meet the high-risk threshold.",
            "Ireland's DPC has an ongoing probe into whether Google needed to conduct a DPIA before it started processing personal data for its AI model Pathways Language Model 2 under the GDPR. He expects such materials would matter greatly under the AI Act, too.",
            "\"I think that from the first seven years of GDPR enforcement, you're probably going to see the value of that contemporaneous documentation that assesses risk, that assesses how you responded to risk, regardless of whether it's formally under Article 35 or other formal documentation that is required,\" he said.",
            "Caitlin Andrews is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/home-sweet-home-or-location-location-location-the-best-place-for-your-company-s-privacy-office",
        "title": "Home sweet home or location, location, location: The best place for your company's privacy office",
        "location": "",
        "date_published": "19 May 2025",
        "keywords": [
            "Customer Trust & Expectations",
            "Data Protection Obligations",
            "Law & Regulation",
            "Personal Privacy",
            "Strategy & Governance",
            "AI Governance"
        ],
        "description": "In today's world of artificial intelligence-driven innovation, companies are navigating a growing tension: how to honor legitimate customer concerns around data use \u2014 like privacy, confidentiality and ethical handling \u2014 while pushing forward with the kind of bold data initiatives that drive growth and build smarter products?",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "In today's world of artificial intelligence-driven innovation, companies are navigating a growing tension: how to honor legitimate customer concerns around data use \u2014 like privacy, confidentiality and ethical handling \u2014 while pushing forward with the kind of bold data initiatives that drive growth and build smarter products?",
            "The truth is, most companies aren't set up to resolve this contradiction effectively. It's not a question of will. It's a question of structure.",
            "Too often, privacy offices are hidden away in legal or compliance departments, or buried under information technology or security teams. That might have made sense when privacy programs were more about box-ticking. But data governance in the age of AI is something else entirely \u2014 something more interdependent, more collaborative and much more strategic.",
            "Customers are right to question how their data is used. They expect transparency, fairness and control. At the same time, organizations are being asked to build smarter systems, leverage personal data to personalize services, and embed AI into everyday workflows. That requires not only more data, but more kinds of data, used in more complex ways.",
            "We can't reconcile these forces with traditional structures that isolate privacy into a legal compliance silo or treat it solely as a risk to be minimized.",
            "What we need is a privacy office that's not only fluent in data protection \u2014 but also deeply embedded in the organization's data strategy, customer experience and product development life cycle. That's why location matters.",
            "To be clear, this isn't a debate about the independence of the data protection officer or the conflicts that arise when placing the DPO within a function that is heavily involved in data processing decision-making or insufficient access to upper management.",
            "Regulations like the EU General Data Protection Regulation and Brazil's General Data Protection Law have laid out well-defined roles and reporting lines for DPOs. Courts and regulators, like Norway's data protection authority, the Datatilsynet, in its March 2025 decision against Telenor, have repeatedly reinforced those boundaries and given clarity around the role.",
            "But the privacy office is not the DPO. It's a broader, operational function \u2014 often comprising privacy engineers, analysts and legal advisors \u2014 that actively supports decisions around how data is processed, not just whether it complies. And in that role, proximity to the decision-makers \u2014 especially in sales, product and marketing \u2014 makes a real difference.",
            "As organizations mature, privacy programs are evolving into full-fledged data governance initiatives. And that shift requires more interlocking between product, legal, compliance, security and go-to-market teams.",
            "Done right, data governance becomes a unifying framework, a way to build trust, ensure accountability and empower innovation without sacrificing integrity.",
            "And the privacy office? It's perfectly positioned to lead this evolution. If it's sitting in the right place.",
            "To get there, more than just new reporting lines are needed. We need new tools. Imagine a central privacy-led data governance platform that: scans product code via application program interfaces with a trusted security vendor \u2014 the same ones used today for vulnerability assessments; maps data flows directly to a contract life cycle management system that holds every data-related obligation \u2014 whether to a vendor, a customer, or a regulator, and thereby, throughout the organization's estate; and flags gaps in real time, creating a shared dashboard for cross-functional teams to respond together.",
            "This kind of data discovery and obligation-mapping tool would do more than eliminate silos \u2014 it would make data governance operational. It would give sales, product, legal and compliance the same consistent and single source of truth, reduce customer friction, and allow everyone to speak the same language.",
            "But to oversee a tool like this, and to drive its adoption across the business, the privacy office can't be buried in a back room. It needs to sit at the intersection of business strategy, data operations and customer trust.",
            "When the privacy office is integrated into go-to-market teams, three big shifts happen.",
            "Privacy becomes a sales accelerator. Customers ask tough questions. They want to know how data is handled, whether AI is fair, whether data will be deleted or reused. With a privacy team embedded in sales operations, those answers come fast \u2014 and they come with credibility. That builds trust, shortens deal cycles and speeds up deal velocity, and turns transparency into a competitive edge.",
            "AI governance gets smarter, sooner. AI isn't just technical \u2014 it's ethical, legal and operational. Sitting closer to the product and sales teams allows the privacy office to translate customer concerns into actionable product feedback, contribute to risk assessments early and train teams in real time as new laws emerge.",
            "Data governance gets real. A privacy office connected to a central discovery and CLM-linked system becomes a cross-functional control tower. It helps ensure that data minimization, accuracy, deletion rights and AI oversight are baked into product design \u2014 not retrofitted after launch.",
            "Placing the privacy office at the right level in the organization is not about optics. It's about unlocking value.",
            "It's about shifting the perception of privacy from a bottleneck to a bridge \u2014 from reactive compliance to proactive trust-building. And it's about recognizing that in the age of AI, the privacy office is uniquely equipped to lead a broader data governance effort that aligns rights, obligations and innovations across the company.",
            "It's time we stopped asking where the privacy office should go based on legacy organization charts \u2014 and started asking where it can deliver the most value to the organization.",
            "The answer? Right at the center of your data strategy \u2014 home sweet home.",
            "Roy Kamp, AIGP, CIPP/E, CIPP/US, CIPM, FIP, is legal director at UKG."
        ]
    },
    {
        "url": "https://iapp.org/news/a/a-view-from-dc-the-ftc-s-next-priorities",
        "title": "A view from DC: The FTC's next priorities",
        "location": "North America",
        "date_published": "16 May 2025",
        "keywords": [
            "Government",
            "AI Governance",
            "Children's Privacy",
            "Enforcement"
        ],
        "description": "It has been more than 100 days since U.S. President Donald Trump's day-one designation of Andrew Ferguson to lead the Federal Trade Commission.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "It has been more than 100 days since U.S. President Donald Trump's day-one designation of Andrew Ferguson to lead the Federal Trade Commission.",
            "With a primary focus across the administration on downsizing and restructuring federal agencies, there have been few substantive data points so far about the new chairman's priorities on privacy. But Ferguson's public statements since taking the helm provide the beginnings of a roadmap.",
            "Most notably, the chairman appeared yesterday on behalf of the agency before the Committee on Appropriations of the U.S. House of Representatives for a budget oversight hearing. There, he gave testimony on the FTC's competition and consumer protection priorities and, as he put it, \"how we are restoring the agency's financial health and public credibility.\"",
            "In his written statement, Ferguson covers in great depth the usual terrain of the agency's operations. Most of what is conveyed has been previously apparent in his extensive writings during his time on the Commission, but the testimony brings it all together and reveals, in its depth of analysis, the relative priorities of areas from privacy to AI enforcement to platform content moderation policies.",
            "The written statement is also a relatively meaningful document because it represents the official views of the FTC, whereas other testimony, speeches, or written statements of Chairman Ferguson represent only his one viewpoint.",
            "In stark contrast to the usual beseeching tone of FTC chairs requesting money from Congress, Ferguson's testimony presented a confidence in his ability to pursue the FTC's priorities at any funding level. As chairs usually do, he boasted of the ability of the agency to punch above its weight, providing \"remarkable value to the American public for relatively little cost.\"",
            "Though recognizing the need for \"adequate staffing\" to properly pursue the FTC's joint missions, and the need for investment to pursue new enforcement priorities like those that would be created under the Take It Down Act, Ferguson also expressed his unconditional support for the president's deregulatory agenda. Specifically, he wrote, \"The FTC is committed to maintaining a workforce that can deliver for the American people and carry out its mission while reducing the size of the agency in line with the President's vision.\"",
            "The written testimony goes on to provide hard numbers on agency staffing, including revealing that the FTC has already reduced staffing to 1,221 full-time employees, a reduction of 94 personnel so far. Ferguson made clear that this is just the beginning. As he put it, \"We anticipate reducing to a Full-Time Employee level that will be the lowest it has been in 10 years by using the Voluntary Early Retirement Act, the Voluntary Separation Incentive Program, and the Deferred Resignation Program, as well as potentially through a targeted Reduction in Force, if necessary.\"",
            "In his oral testimony, Ferguson provided a ballpark goal of 1,100 personnel for the agency moving forward, which would represent a 15% reduction from prior levels. He also reiterated his hope that this number would be reached without resorting to the government's \"reduction in force\" layoff mechanism.",
            "The FTC's mandate to fight fraud and other egregiously deceptive practices receives the greatest amount of attention in the oversight testimony. Ferguson spends more than four pages of the document reviewing the FTC's efforts to fight robocalls, combat fraud targeting older Americans, protect service members and veterans and halt deceptive billing and cancellation practices.",
            "Three more pages review efforts to prevent financial misconduct and fight opioid recovery fraud and \"other health-related misconduct,\" though without reference in either section to financial- or health-related privacy matters. On the other hand, Ferguson did express a strong interest in genetic privacy in his recent letter on the potential impact to consumers of the pending 23andMe bankruptcy.",
            "The testimony turns to AI under a section titled \"empowering innovation and addressing fraud in new fields.\" Here, the document echoes the public statements of Ferguson and other commissioners in promising a hands-off approach to AI governance, while continuing to reign in fraud and deceptive marketing claims about AI products.",
            "On the fraud side, Ferguson highlights recent enforcement against get-rich-quick schemes that happened to be based around AI-powered products. Beyond this, the document cites the deceptive claims about \"the world's first robot lawyer\" in the DoNotPay settlement and the allegedly wildly deceptive marketing claims about detecting generative AI text in the recent Workado enforcement.",
            "Ferguson's FTC makes clear it will continue to pursue similar matters around AI, even as it allows room for the emerging technology to deliver \"significant opportunities for consumers, workers, and our economy.\"",
            "Though data security and privacy receive their own section in the written testimony, there is a notable difference in how these areas of FTC enforcement are presented, and the section receives less than two-and-a-half pages of coverage.",
            "Rather than starting with the FTC's bread-and-butter Section 5 enforcement accomplishments, which represent the majority of the agency's actions in privacy, the testimony is clear to focus on \"unlawful\" activities \u2014 by which it mostly seems to indicate business practices that violate explicit privacy laws and regulations such as the Children\u2019s Online Privacy Protection Act or the Gramm-Leach-Bliley Act's Privacy Rule and Safeguards Rule.",
            "Almost as an aside, the document mentions the FTC's Section 5 authority as \"another privacy and data security enforcement tool,\" while immediately dropping a footnote that reads, \"The Commission supports congressional efforts to create baseline privacy legislation that protects Americans online.\"",
            "In contrast to the footnote-heavy approach in the rest of the document \u2014 the Ranking Member of the oversight committee, Steny Hoyer, D-Md., referred to it as \"footnoted more than any other statement I've read as an opening statement\" \u2014 the testimony does not cite to any example cases for general consumer privacy matters, even when generally reminding Congress of these activities.",
            "Instead, these accomplishments are quickly summarized in a manner that reiterates the Chairman's stated goal of returning to the foundations of privacy enforcement, highlighting deception and using the phrase \"substantial injury\" rather than unfairness. \"Where companies have misrepresented their data collection and use practices to consumers, or where data practices have caused substantial injury to consumers, the Commission has brought law enforcement actions.\" Substantial injury is one of the requirements of an unfairness charge, but it is also the most instrumental factor in most of Ferguson's disagreement with certain charges brought in recent privacy cases, such as the slate of 2024 location privacy matters.",
            "In a return to footnotes, the privacy section of the written testimony is dominated by an overview of the agency's work to protect children and teens.",
            "Though it mostly focuses on COPPA enforcement, calling it \"some of the Commission's most valuable work,\" the continued emphasis on teens is notable, given that the FTC must rely on general Section 5 authority to focus on the privacy risks faced by users from 13 to 17 years old.",
            "After reviewing recent relevant actions, the testimony reiterates that \"protecting children and teens online is similarly of paramount importance to the Trump-Vance FTC.\"",
            "The section closes by stating that the \"Commission is also dedicated to exploring other ways the FTC can protect children and support families.\" It cites the twice-delayed workshop on the attention economy scheduled for 4 June, promising that invited experts will discuss, \"concrete solutions to protect kids online, including age verification and parental consent requirements.\"",
            "The FTC chair sets the agenda of the agency and has significant discretion when it comes to its day-to-day administration, but the FTC is structured to be led by five commissioners. Any major decision requires the approval of a majority of the sitting commissioners. With that in mind, the views of the other commissioners also have some bearing on the priorities of the FTC in the coming years.",
            "Seated behind Ferguson during the hearing was Mark Meador, the newest appointed commissioner. Meador comes from a competition background. His public statements on privacy \u2014 and even consumer protection more broadly \u2014 have been relatively sparse, though he was questioned about privacy issues during his confirmation hearing, at one point mentioning that protecting the online privacy of children and teens is one of his \"most important missions.\"",
            "For her part, Commissioner Melissa Holyoak, the third Republican leading the agency, agrees that continuing to protect the privacy of children and teens is paramount. She highlighted this and other priorities in her keynote address at IAPP's 2025 Global Privacy Summit. Her speech, which you can view in its entirety on the IAPP site, also ran the gamut of other FTC privacy issues, showing continued interest in a \"flexible, risk-based approach\" to privacy enforcement, even as she highlighted the new more hands-off approach to AI technologies.",
            "The FTC currently hosts only three out of its usual five commissioners after the president fired the two remaining Democratic commissioners in a move that is subject to an ongoing legal battle. Alvaro Bedoya and Rebecca Slaughter also appeared at the IAPP Summit this year, interviewed on a panel hosted by The Verge podcaster Nilay Patel. They discussed the lawsuit at length, their views on the proper role of an independent FTC, and the future of accountability for Big Tech. The IAPP has posted a video of the full discussion, or you can listen to the episode of Decoder.",
            "Please send feedback, updates and tea leaves to cobun@iapp.org.",
            "Cobun Zweifel-Keegan, CIPP/US, CIPM, is the managing director, Washington, D.C., for the IAPP.",
            "This article originally appeared in The Daily Dashboard and U.S. Privacy Digest,\u00a0free weekly IAPP newsletters. Subscriptions to this and other IAPP newsletters can be found\u00a0here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-iapp-canada-cps25-highlights-privacy-ai-cybersecurity-evolution",
        "title": "Notes from the IAPP Canada: CPS25 highlights privacy, AI, cybersecurity evolution",
        "location": "North America",
        "date_published": "16 May 2025",
        "keywords": ["AI Governance", "Data Security", "Community & Careers"],
        "description": "How the heck do you follow television host and author Rick Mercer on stage after he's given the most riveting, hilarious, thought-provoking and patriot rant ever? That's all that kept going through my head on Tuesday as I sat through his IAPP Canada Privacy Symposium 2025 keynote and knew I had to somehow make the link between his rant and our profession with over 1,000 people in the audience.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "How the heck do you follow television host and author Rick Mercer on stage after he's given the most riveting, hilarious, thought-provoking and patriot rant ever? That's all that kept going through my head on Tuesday as I sat through his IAPP Canada Privacy Symposium 2025 keynote and knew I had to somehow make the link between his rant and our profession with over 1,000 people in the audience.",
            "At the end of the day, however, there were actually many parallels and lessons to derive. Take ethical and reasonable chances. Don't be the office of \"no.\" Be as Canadian as possible at all times, and respect but don't try to be American, British or French \u2014 or anyone else.",
            "All these qualities translate into how our privacy, artificial intelligence and cybersecurity profession has evolved in this country. If you were there, you know that at one point in his speech Mercer spoke about a pigeon flying into his mouth. What's the lesson there? \u00a0No matter how much we plan, organize and analyze things, there are always variables that pop up that catch us off guard and force us to change course \u2014 and run to the drug store to buy emergency mouth wash.",
            "In the past few days since the Symposium, my inbox has been filled with notes from people saying how much they appreciated the conference, emphasizing how much they got out of it.",
            "In my opening remarks to the conference, I spoke about my gratitude to be part of this community and to be part of this amazing and unique annual conference in Canada. After receiving these thoughtful emails, I'm reminded again that this sense of gratitude is not an isolated occurrence. I think many, if not all of us in our community, feel pretty grateful to be part of a profession that is inclusive, welcoming, encouraging and willing to face the challenges of our future with thoughtful and ethical principles in mind.",
            "By the way, the idea of incorporating the grateful aspects to my life and profession came moments before getting on the stage because my wonderful and beautiful partner, Anne-Marie, gave me the idea to speak from my heart, to speak to my gratitude. Thank you, Anne-Marie.",
            "Speaking of gratefulness, I can't even start to list all the great sessions and keynotes and networking opportunities this past week gave us. One of the things that stood out: the rise of the next generation of professionals willing to embark on and keep going on this journey. About 30% were attending for the first time and there were also over 25 students there, whom the IAPP had awarded scholarships to. To see them interacting with the senior pros in our field, including commissioners and their staff was telling. We have a bold, bright and determined class of new(er) professionals ready and willing to help lead through challenging times.",
            "Another thing I'm hugely grateful for this week is the IAPP staff that made the Canadian Symposium happen. I'd list them by name, but the list would be too long and, quite frankly, I know some of them don't like to be called out. Their humility and hard work is something I admire tremendously. Please raise a very Canadian bloody Caesar toast to this excellent crew.",
            "Kris Klein, CIPP/C, CIPM, FIP, is the managing director, Canada, for the IAPP.",
            "This article originally appeared in the Canada Dashboard Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/developers-prepare-for-uncertainty-look-to-prior-regulations-with-ai-act-coming-online",
        "title": "Developers prepare for uncertainty, look to prior regulations with AI Act coming online",
        "location": "Europe",
        "date_published": "15 May 2025",
        "keywords": [
            "AI Governance",
            "Law & Regulation",
            "Frameworks & Standards"
        ],
        "description": "Businesses should be ready for uncertainty and prepared to adapt artificial intelligence governance strategies as the regulatory landscape around the EU AI Act is built, according to representatives of leading AI developers speaking at the IAPP AI Governance Global Europe 2025 in Dublin, Ireland.",
        "content": [
            "Businesses should be ready for uncertainty and prepared to adapt artificial intelligence governance strategies as the regulatory landscape around the EU AI Act is built, according to representatives of leading AI developers speaking at the IAPP AI Governance Global Europe 2025 in Dublin, Ireland.",
            "During an AIGG keynote panel discussion, Anthropic Associate General Counsel Ronan Davy said it will take time for case law, regulatory tactics and industry standards around the EU landmark regulation to develop. That is going to lead to some ambiguity for developers and deployers as the act's staggered timeline rolls out with more obligations.",
            "It will be helpful for practitioners to recognize \"there is going to be ambiguity, and that's OK,\" he said. \"Know that the compliance program you build for day one is going to continuously reiterate and evolve.\"",
            "Davy's comments underscore the challenges facing AI users and creators as elements of the act's enforcement metrics remain uncertain.",
            "The finalization of the EU general-purpose AI Code of Practice, meant to provide voluntary governance rules for companies, has been delayed until this summer. Technology companies are pushing hard to create more favorable conditions under the draft code, which comes with the frustration of civil society and lawmakers involved in the act's creation.",
            "And as the uncertainty grows around the code, the European Commission is also signaling potential targeted changes to the AI Act in the not-so-distant future. According to Politico, Head of Unit for AI Policy Coordination and Development Kilian Gross indicated the European Commission's \"first focus\" is to \"simplify the implementation\" of the AI Act for companies, while adding potential provisional changes could be explored \"if (simplification) should not be enough.\"",
            "Davy said he has yet to see one uniform approach for how to compose a compliance team, but more businesses are starting to approach overlapping digital laws from a holistic perspective.",
            "\"I think as more and more EU laws come online, we're starting to see increased intersectionality and complexity in terms of how they will be managed in parallel,\" he said.",
            "Those working in a field with established regulations will also likely find meeting the AI Act compliance challenges easier, said Niamh Donnelly, the co-founder of Irish robotics company Akara. The company's flagship robot disinfects hospitals, and Donnelly said the longstanding history of health care regulation made a strong baseline for her compliance team.",
            "That concept showed up in a privacy-by-design approach to the robot, which uses an infrared camera instead of a more traditional one as a way to protect people\u2019s privacy, Donnelly said.",
            "\"So you have a sensor in a robot \u2014 maybe look at what information that sensor is taking in and does it need to take in all that information? And can we maybe change it?\" she pointed out.",
            "Companies accustomed to meeting data compliance laws, including the EU General Data Protection Regulation are in a better position to meet the AI Act's requirements, according to OpenAI Associate General Counsel, Privacy and Data Protection Emma Redmond.",
            "She said OpenAI wants a better understanding of some components of the regulation, including how different elements of the general-purpose code will work in a practical setting. And improved understanding, she said, hinges on a working relationship with regulators to grasp their interpretation and outline them about what the company is trying to do.",
            "\"We haven't really seen anything like this, with so many authorities involved in one area,\" Redmond added.",
            "Caitlin Andrews is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-asia-pacific-region-china-ramps-up-ai-governance",
        "title": "Notes from the Asia-Pacific region: China ramps up AI governance",
        "location": "Asia",
        "date_published": "15 May 2025",
        "keywords": ["AI Governance", "Regulatory Guidance", "Enforcement"],
        "description": "It was wonderful seeing so many familiar faces at the IAPP Global Privacy Summit 2025 in Washington, D.C., three weeks ago. I'm already looking forward to IAPP Asia 2025: Privacy Forum and AI Governance Global in Singapore this July.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "It was wonderful seeing so many familiar faces at the IAPP Global Privacy Summit 2025 in Washington, D.C., three weeks ago. I'm already looking forward to IAPP Asia 2025: Privacy Forum and AI Governance Global in Singapore this July.",
            "In China, artificial intelligence governance is absolutely in the spotlight. The Cyberspace Administration of China launched a three-month special campaign starting 1 May to regulate AI technology abuse.",
            "In the first phase, the CAC will zero in on six key issues: failing to make the required algorithm or large language model filing with the regulator; selling noncompliant AI products or services; using illegal, unauthorized or untrue data as training datasets; neglecting to review and monitor AI-generated content; not implementing AI labelling requirements; and failing to address security risks in key industries such as the misleading aspects of AI-generated medical prescriptions.",
            "In the second phase, the focus will shift to issues including creating and spreading rumors, false or pornographic information using AI, impersonating others to carry out illegal acts, engaging in online bullying and trolling via AI, and harming minors' interests by creating rumors, pornographic material, or inducing addiction in minors with AI.",
            "While ramping up AI governance, China is also actively educating and encouraging the younger generation to use AI properly. A few days ago, China's Ministry of Education issued two AI guidelines for primary and middle school students. In primary schools, AI education emphasizes experience and interest-building. Students are expected to learn basic knowledge about how simple AI tools work, start developing basic logical thinking, and build cybersecurity and privacy awareness. In high schools, the focus is on helping students understand AI's technical logic, deepen their ethical understanding and explore using AI to solve real world problems. AI will serve as a useful tool for teachers to boost the quality and efficiency of classroom teaching and offer personalized education.",
            "In Hong Kong, with AI becoming more prevalent and bringing privacy and cybersecurity risks, the Office of the Privacy Commissioner for Personal Data is actively promoting AI compliance and best practices. The PCPD completed compliance checks on 60 organizations regarding their AI use, finding 80% of these organizations used AI in daily operations, a 5% increase from 2024. Around 54% of AI-using organizations employed three or more AI systems, mainly in customer service. Half of these organizations collected and used personal data via AI systems, and most provided personal data collection statements, stored data properly, and implemented security measures like encryption and access control.",
            "The PCPD stressed that AI comes with risks, so organizations are encouraged to adopt best practices such as formulating AI strategies and governance structures, conducting comprehensive risk assessments, regularly auditing AI systems, developing internal policies or guidelines on the use of generative AI by employees, complying with Hong Kong's privacy ordinance for personal data protection, and communicating with stakeholders.",
            "AI governance will surely stay a hot topic in the APAC region. I'll keep you updated on new developments.",
            "Barbara Li, CIPP/E, is a partner at Reed Smith.",
            "This article originally appeared in the Asia-Pacific Dashboard Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/a-view-from-brussels-greetings-from-dublin",
        "title": "A view from Brussels: Greetings from Dublin",
        "location": "Europe",
        "date_published": "15 May 2025",
        "keywords": ["AI Governance", "Law & Regulation"],
        "description": "Beannachta\u00ed \u00f3 Bhaile \u00c1tha Cliath. Greetings from Dublin.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "Beannachta\u00ed \u00f3 Bhaile \u00c1tha Cliath. Greetings from Dublin.",
            "\"Privacy and (artificial intelligence) governance professionals have a critical role to play in the unfolding AI revolution,\" said Irish Minister for Trade Promotion, AI and Digital Transformation Niamh Smyth, who opened the IAPP AI Governance Global Europe 2025 this week in Dublin, Ireland.",
            "Ireland adopted and updated its national AI strategy last year. Aligning strongly with the EU level approach laid out in its recently published AI Continent Action Plan, Ireland is focusing on three pillars to foster AI development: AI for good; AI innovation ecosystem; and AI-ready citizens. Stakeholder engagement will also be \"a big piece\" transversally, Smyth said.",
            "She also underlined that it is essential to ensure government has access to independent advice as it continues to develop, implement and monitor progress across its AI plans and ecosystem.",
            "\"AI governance is not an obstacle to AI development. We must be cognizant of risks it can pose but a prerequisite to the wide spread of AI is public trust. We need safeguards,\" she said.",
            "The risk-based approach built into the EU AI Act is a way for Ireland and other European governments to calibrate oversight vis-\u00e0-vis harm along the AI supply-chain. Dublin is fully committed to a comprehensive implementation of the AI Act and is considering giving a mandate to a centralizing authority for supervision.",
            "Indeed, approaching AI governance for any organization is still raising many questions. There is a shift away from existential risks to thinking about near term risks, for example related to robotics and job displacement. Representatives of OpenAI, Anthropic and Irish robotics startup Akara spoke to the challenges of where and how to start the governance journey, during their AIGG keynote session.",
            "Several fundamentals emerged:",
            "When it comes to the EU AI Act, the lack of guidance on practical elements and the myriads of authorities involved are among the biggest compliance challenges for many in that space. Conversely, the act's staggered implementation timeline has been very helpful. As there is more clarity around the landscape of regulatory authorities, organizations will have an opportunity to build relationships with their regulators. That can be tremendously helpful to get a sense of their goals, explain their technology and approach, and build a mutual understanding of where everybody is coming from.",
            "Organizations should acknowledge the reality that there will be a lot of ambiguity. In the meantime, creating a mindset of responsible AI use will be important to build up governance across the organization.",
            "Isabelle Roccia, CIPP/E, is the managing director, Europe, for the IAPP.",
            "This article originally appeared in the Europe Data Protection Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/preparing-your-company-for-a-financing-round-a-privacy-action-plan",
        "title": "Preparing your company for a financing round: A privacy action plan",
        "location": "",
        "date_published": "15 May 2025",
        "keywords": [
            "Finance & Banking",
            "Data Protection Obligations",
            "Data Security",
            "Enforcement",
            "International Data Transfers",
            "Law & Regulation",
            "Strategy & Governance",
            "AI Governance"
        ],
        "description": "As privacy and cybersecurity risks become more material to business operations, investors are no longer viewing data protection as a peripheral concern \u2014 they're treating it as a core indicator of a company's readiness to scale.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "As privacy and cybersecurity risks become more material to business operations, investors are no longer viewing data protection as a peripheral concern \u2014 they're treating it as a core indicator of a company's readiness to scale.",
            "For companies preparing to raise capital, how personal data is managed, secured and governed has become a critical factor in the investment calculus. Robust data practices can directly impact valuation, negotiation leverage and overall deal certainty. This is particularly true for companies in data-intensive industries, such as direct to consumer businesses, software as a service vendors, the burgeoning artificial intelligence space, and regulated entities in the financial or health care sectors.",
            "In today's regulatory environment, where enforcement actions and class-action lawsuits are on the rise, weak data governance can invite serious consequences \u2014 regulatory penalties, reputational damage, operational disruptions and a stalled deal process.",
            "On the flip side, companies that demonstrate strong data protection and compliance practices can stand out in a competitive fundraising landscape. They not only reduce friction during due diligence but also signal to investors that they are built for sustainable growth and resilient operations.",
            "There are five key actions every leadership team should consider taking to strengthen their data protection posture ahead of a financing round.",
            "Investors increasingly view privacy compliance as a threshold issue \u2014 an early litmus test for a company's operational maturity and risk posture. During diligence, companies are expected to clearly articulate what data they collect, how it's used and shared, and how they comply with evolving privacy laws.",
            "Falling short in this area doesn't just raise red flags about potential regulatory exposure, it casts doubt on broader internal controls and the company's overall approach to risk management.",
            "Conversely, a well-defined and proactive privacy program can serve as a competitive differentiator. As customers and partners grow more privacy-conscious, strong data governance isn't just a compliance requirement \u2014 it's a strategic asset.",
            "Recommended actions:",
            "A privacy policy is the storefront of the privacy program, often the first document investors review. If it is inaccurate, outdated or incomplete, it may signal broader compliance deficiencies or exposure to regulatory enforcement.",
            "Inconsistencies between a company's actual practices and its public disclosures have led to investigations and enforcement actions.",
            "In privacy, the key is to say what you do and do what you say.",
            "Recommended actions:",
            "Cybersecurity is no longer just an information technology concern \u2014 it's a critical business risk that directly influences a company's ability to secure financing.",
            "High-profile breaches and escalating regulatory enforcement have made investors acutely aware of the potential fallout from inadequate security practices. A single cybersecurity incident can materially impact valuation, delay a deal or create costly post-close liabilities. As a result, investors are looking for evidence that a company has implemented reasonable, risk-based security measures aligned with its size, industry and threat landscape.",
            "Failure to demonstrate even baseline controls \u2014 such as formal policies and procedures around access management, vulnerability monitoring, incident response planning and employee training \u2014 can signal operational immaturity and expose the company to reputational, financial and regulatory risk.",
            "In contrast, a well-designed and well-documented cybersecurity program instills confidence. It tells a story of a leadership team that understands its risk environment and is proactively managing it. Beyond reducing friction in the diligence process, a sophisticated security posture can serve as a competitive edge, especially in industries where data integrity and customer trust are paramount.",
            "In today's investment climate, cybersecurity isn't just a cost center \u2014 it's a value driver.",
            "Recommended actions:",
            "Tip: Maintain documentation of policies, training records, assessments and corrective actions. Investors often request this as part of diligence.",
            "As the use of AI and machine learning expands, so too does regulatory and investor scrutiny. Investors increasingly expect companies to understand and mitigate the intellectual property, privacy, fairness and explainability risks associated with these technologies. This is particularly important for companies in regulated industries or those using personal data in consequential decision-making.",
            "Recommended actions:",
            "Class action litigation related to privacy practices \u2014 particularly in the U.S. \u2014 has increased significantly. The plaintiffs' bar has targeted companies over the use of session replay tools, cookies, chatbots and pixels, often alleging violations of wiretapping statutes or state privacy laws. Collection and use of biometric information, even of employees, triggers strict scrutiny under biometric privacy laws. Investors are increasingly aware of these risks and may flag potential exposure as a diligence concern.",
            "Recommended actions:",
            "Preparing for a financing round demands more than polished pitch decks and optimistic revenue projections. Today's investors are paying close attention to how companies manage privacy, cybersecurity and AI \u2014 areas facing intensifying scrutiny from regulators and plaintiff attorneys worldwide.",
            "But effective risk management involves more than just checking compliance boxes. It's about showing operational maturity. Demonstrating a strong, proactive approach to privacy and data protection signals that your company is not only ready to scale but built for long-term resilience. This can accelerate the diligence process, build investor trust and ultimately enhance your valuation.",
            "By addressing these critical issues early, you not only minimize the risk of unpleasant surprises during diligence \u2014 you also craft a narrative that sets your company apart as a responsible, forward-thinking data steward.",
            "Jacqueline Klosek is a partner, Omer Tene is a partner, Federica De Santis, CIPP/E, CIPP/US, is a counsel, and Reema Moussa is an associate at Goodwin Procter."
        ]
    },
    {
        "url": "https://iapp.org/news/a/proposed-federal-moratorium-on-us-state-level-ai-regulation-passes-house-committee",
        "title": "Proposed federal moratorium on US state-level AI regulation passes House committee",
        "location": "North America",
        "date_published": "14 May 2025",
        "keywords": ["AI Governance", "Law & Regulation"],
        "description": "A proposed federal moratorium on state-level AI regulation and enforcement passed out of the U.S. House Energy and Commerce Committee early Wednesday morning. The proposal has drawn criticism from Democratic lawmakers in the House and a bipartisan group of interstate policymakers.",
        "content": [
            "A proposed federal moratorium on state-level AI regulation and enforcement passed out of the U.S. House Energy and Commerce Committee early Wednesday morning. The proposal has drawn criticism from Democratic lawmakers in the House and a bipartisan group of interstate policymakers.",
            "In a vote of 29-24, the House E&C committee voted to advance the moratorium after Democrats aimed to remove the provision. Update: On 16 May, the House Committee on the Budgetvoted against the reconciliation bill. However, lawmakers reportedly plan to regroup quickly with the aim of resurrecting the bill in short order.",
            "IAPP Managing Director, Washington, D.C., Cobun Zweifel-Keegan, CIPP/US, CIPM, analyzed the proposal earlier this week.",
            "The moratorium is part of a proposed budget reconciliation bill, and if passed by the full Congress, would halt any state-level AI laws or laws that regulate AI systems or automated-decision making technology. To pass the reconciliation bill, Congress would only need a simple majority.",
            "According to Politico, Committee Chair Brett Guthrie, R-Ky., defended the moratorium, saying it undergirds the reconciliation bill's USD500 million investment in AI technology systems. \"To protect the integrity of this project,\" Guthrie said, \"we're implementing guardrails that protect against state-level AI laws that can jeopardize our technological leadership.\"",
            "U.S. President Donald Trump and his administration have been clear about promoting AI innovation over regulation or obstacles to AI development in the geopolitical AI race against China.",
            "In comments provided to the IAPP, Maryland state Senator Katie Fry Hester, D-Md., who also co-signed a letter challenging the proposed moratorium, said, \"the states have always been a laboratory for democracy\" and many are picking up where the federal government has left off. She cited the fact that Congress has not yet passed federal privacy legislation, so many state legislators are aiming to work together to limit the state-level patchwork across the country, giving businesses more legal certainty.",
            "The letter, which is co-authored by Hester, as well as state lawmakers from Colorado, Connecticut, Minnesota, New York, Vermont and Virginia, along with New York University Professor Gary Marcus, characterized the moratorium as \"a major step backwards\" and suggested it is likely at odds with the 10th Amendment.",
            "\"This would be deeply problematic under any circumstance, but it's especially dangerous in the context of rapidly evolving technology already reshaping healthcare, education, civil rights, and employment,\" they write. \"If enacted, the statute would preempt states from acting \u2014 even if AI systems cause measurable harm, such as through discriminatory lending, unsafe autonomous vehicles, or invasive workplace surveillance.\"",
            "In a separate letter, the National Conference of State Legislatures, a bipartisan organization that represents legislatures in states, territories, commonwealths and Washington, D.C., expressed its \"strong opposition\" to the 10-year moratorium, arguing it's \"an infringement on states' authority to effectively legislate in this rapidly evolving and consequential policy domain, and in our view, is a violation of the Byrd law.\"",
            "In his article analyzing the moratorium, the IAPP's Zweifel-Keegan breaks down the how the Byrd rule comes into play in the reconciliation bill.",
            "\"States have historically served as vital laboratories of democracy, crafting policies that reflect the unique needs, values and priorities of their constituents,\" the NCSL writes. \"In the realm of AI \u2014 where implications for privacy, cybersecurity, fraud, workforce, education, and public safety remain profound and continually evolving \u2014 legislative flexibility is essential. A federally imposed moratorium would not only stifle innovation but potentially leave communities vulnerable in the face of rapidly advancing technologies.\"",
            "In a recent Lawfare article,\u00a0Kevin Frazier and Adam Thierer wrote\u00a0the proliferation of AI bills \"could undermine the nation's efforts to stay at the cutting edge of AI innovation at a critical moment when competition with China for global AI supremacy is intensifying.\" They called on Congress \"to get serious about preemption.\"",
            "They also argue that the \"important goals of encouraging a robustly innovative national AI marketplace and strong strategic base to compete with China will be undermined unless Congress preempts the development of a patchwork of conflicting and costly state and local regulatory policies.\"",
            "A spokesman for Colorado Gov. Jared Polis, a Democrat, said he supports the moratorium, saying, \"He is generally supportive of a federal moratorium to give Congress a chance to figure this out and create a true 50-state solution to smart AI protections.\"",
            "Just last year, Polis signed the Colorado AI Act, the first of its kind in the U.S.",
            "However, in an analysis of the law at the time, Zweifel-Keegan and former IAPP Westin Fellow Andrew Folks, CIPP/E, CIPP/US, CIPM, pointed out that Polis \"simultaneously released a\u00a0signing statement\u00a0contextualizing his approval of the bill. Most of the act's major provisions enter into effect 1 Feb. 2026, though the Colorado legislature reportedly intends to study and possibly revise the bill before that time.\"\u00a0",
            "Speaking this week at IAPP AI Governance Global Europe 2025 in Dublin, Ireland, Daniel Pietragallo, AIGP, CIPP/US, FIP, special counsel at Buchhalter Law Firm and former Colorado Senior Assistant Attorney General, said the provision \"is very well written. This is very narrowly tailored to get around any objections.\"",
            "If ultimately passed by Congress, the provision will be challenged legally \"to see if it meets certain requirements\" under the Byrd exemption, but, he said, \"I think it's got a really decent chance of passing through the U.S. Congress and signed into law by the current administration.\"",
            "On the question of how states could potentially circumnavigate the proposed moratorium, Pietragallo said, \"the way the law is written, it precludes enforcement for anything that involves AI or ADMT, so that not only affects the Colorado AI Act, but also the Colorado Privacy Act, which would now preclude enforcement for situations where companies weren't allowing consumers to take advantage of their opt-out rights.\"",
            "Pietragallo, however, noted the Colorado law \"says that it's a consumer protection violation to violate the statute, and so while you're precluded from enforcing the AI governance statute, maybe states aren't precluded from taking the position that some of the conduct engaged in by the companies represents an unfair and deceptive practice. And you could bring an action under that theory and leave the words 'automated decision making' out.\"",
            "Jedidiah Bracy is the editorial director for the IAPP.",
            "IAPP Staff Writer Caitlin Andrews contributed reporting for this article.",
            ""
        ]
    },
    {
        "url": "https://iapp.org/news/a/kosseim-reflects-on-state-of-play-ahead-of-second-ontario-ipc-term",
        "title": "Kosseim reflects on state of play ahead of second Ontario IPC term",
        "location": "North America",
        "date_published": "14 May 2025",
        "keywords": [
            "AI Governance",
            "Children's Privacy",
            "Law & Regulation",
            "Enforcement"
        ],
        "description": "The Office of the Information and Privacy Commissioner of Ontario has been proactive with its business and consumer support during Commissioner Patricia Kosseim's first five-year term. Kosseim told attendees at the IAPP Canada Privacy Symposium 2025 the IPC's initiatives and support system will only grow as she moves into her second term.",
        "content": [
            "The Office of the Information and Privacy Commissioner of Ontario has been proactive with its business and consumer support during Commissioner Patricia Kosseim's first five-year term. Kosseim told attendees at the IAPP Canada Privacy Symposium 2025 the IPC's initiatives and support system will only grow as she moves into her second term.",
            "With the building blocks in place, Kosseim said the IPC is equipped to tackle and play a role in \"five futures\" that will cement provincial and federal privacy standards for years to come. The focuses include harmonized Canadian privacy laws, privacy's environmental impacts, children's privacy, sustaining the privacy profession and growing the IPC's impacts.",
            "Each of the core imperatives requires cooperation across the IPC, lawmakers, businesses and consumers, and Kosseim indicated the unison will make the difference in the ever-changing digital economy.",
            "\"We live in a data-driven world propelled by AI that may feel very scary and overwhelming at times,\" Kosseim said in her closing keynote remarks. \"But we can't give up the good fight. By collaborating, being flexible in our approach, and stepping forward with courage and perseverance, we can shape better outcomes and help build a better future.\"",
            "Efforts to align Canada's federal and provincial privacy statutes predate Kosseim's first term, but she has played witness to the peaks and valleys of the process in recent attempts.",
            "Ontario joined Quebec in completing meaningful changes to its provincial privacy law through the Strengthening Cyber Security and Building Trust in the Public Sector Act. The bill, which earned royal assent November 2024, brought significant updates to provisions of the Freedom of Information and Protection of Privacy Act while raising new cybersecurity and artificial intelligence requirements.",
            "Other provinces have not moved as quickly on reform, and the same can be said about federal reforms to the Personal Information Protection and Electronic Documents Act.",
            "The Parliament of Canada stood up and considered different PIPEDA reform vehicles in recent years that each failed. The latest attempt with Bill C-27 fell short as federal elections cleared the legislative docket.",
            "Kosseim said the uncertainty around global trade and social policies creates a domestic policy rethink that privacy laws can be a part of. She indicated the \"case for harmonized privacy laws has never been stronger,\" with provisional differences and \"glaring gaps\" within the patchwork making business compliance \"needlessly complex.\"",
            "She stressed the importance of provincial and territorial interpretation remaining in place, but advocated for a common floor to create certainty for businesses and consumers alike.",
            "\"There's an economic burden to regulatory compliance across provincial borders, and in some cases, an opportunity cost in having to forgo markets altogether,\" Kosseim said. \"We do need a basic common canvas to work from if we want to empower innovation, investment and trust in our digital economy.\"",
            "Kosseim touted the IPC as a \"steadfast champion\" for children's privacy rights during her first term.",
            "Efforts to ensure protections is one aspect of the IPC's children's work, but its privacy education initiatives are also making waves.",
            "The Privacy Pursuit lesson plans are a joint project from the IPC and MediaSmarts that \"help educators teach students in Grades 2 through 8 about why privacy is important and how to protect their privacy online.\" Also being integrated into schools is a digital privacy charter that Kosseim described as \"12 clear commitments for schools to help empower students to make informed privacy choices.\"",
            "Kosseim added the charter applies to educators and schools as well, with wide adoption being essential to prevent incidents like the recent PowerSchool data breach sweeping through Canadian schools.",
            "\"Now is the time for education leaders to courageously step forward and sign on to this charter to make these protections a reality,\" she said.",
            "While in the midst of a transition period to her second term, Kosseim asked IPC staff to \"start thinking about the next tranche of big, bold ideas\" to keep its offerings \"fresh, modern and innovative.\" She added the IPC will also \"be consulting externally and working with our strategic advisory council to develop a new strategic plan for the next five years.\u201d",
            "Concepts for next steps will depend on strong input from privacy professionals doing the work on the ground. Kosseim stressed flexibility and education among professionals, to the extent of collecting a spectrum of knowledge and experiences.",
            "\"Don't be afraid to take a non-linear path,\" she said. \"If an exciting opportunity comes up in another department, organization or even sector that will give you a different vantage point on privacy issues you really care about, don't dismiss it just because it's not a step up the organizational chart.\"",
            "Joe Duball is the news editor for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/eu-ai-literacy-not-a-far-jump-for-established-privacy-professionals-regulator-says",
        "title": "EU AI literacy not a far jump for established privacy professionals, regulator says",
        "location": "Europe",
        "date_published": "14 May 2025",
        "keywords": [
            "AI Governance",
            "Data Protection Obligations",
            "Frameworks & Standards",
            "Privacy Program Management",
            "Regulatory Guidance"
        ],
        "description": "An Irish data protection commissioner said privacy and data protection folks may not have to go too far afield to bring their institutions up to speed on EU artificial intelligence literacy requirements.",
        "content": [
            "An Irish data protection commissioner said privacy and data protection folks may not have to go too far afield to bring their institutions up to speed on EU artificial intelligence literacy requirements.",
            "Commissioner Dale Sunderland said there are several instances where the EU AI Act's literacy requirements, which states entities need their staff who use AI to have sufficient understanding of how it works and how to prevent any harms coming from its use. Those provisions, Sunderland said, are not too different from the EU General Data Protection Regulation's terms requiring understanding of technologies and now they can affect people's rights and freedoms. Data protection officers are also familiar with the GDPR's mandate that they raise awareness and train staff on best practices.",
            "\"Data protection has always been aimed at assuming a baseline understanding at an organizational level, which can be a safeguard measure in itself, and this concept can be leveraged for AI knowledge and literacy,\" he said. \"I don't think we're starting from scratch. They're very different, the context is a bit different, the complexity of technology is absolutely different, but the core foundational principles are very much the same.\"",
            "Given the similarities between the AI Act and the GDPR, Sunderland said, \"it makes no sense to me, as a regulator, for any organization, and even for regulators to treat them as entirely separate matters.\"",
            "The comments came during the IAPP AI Governance Global Europe 2025 conference and shed some light on how Ireland, which regulates some of the biggest companies in the technology industry, may view the task of AI literacy, one of the first requirements of the bloc's landmark AI regulation. The European Commission has laid out detailed guidelines and is maintaining a repository of information on how to meet this requirement.",
            "There is no fine linked to AI literacy explicitly in the law. But while Sunderland said it may be that Article 4 is enforced on its own, he said it would more likely be a factor AI regulators consider when they assess violations of the law when it starts taking broader effect this August. He pointed to Article 15, which regulates the level of accuracy high-risk systems are supposed to achieve, and whether designers or developers of AI are able to provide suitable literacy training.",
            "\"It could potentially be ... seen as a contributing factor to a lack of appropriate ... for example, cybersecurity, or lack of due diligence in dealing with bias in arguments,\" he said.",
            "AI literacy is a foundational concept, Sunderland later added, saying it also speaks to an organizations' ability to understand why it is using AI and how specific uses can benefit their company in the long run. The risks of not understanding that go beyond the business.",
            "\"I think the issue with AI and its enormous potential, and I would think quite low understanding of how the technology works, is that when something goes wrong, it can go really badly wrong, with huge impacts for individuals,\" he said.",
            "Not being able to demonstrate good AI literacy could also affect how customers view your enterprise, said Jasmien C\u00e9sar, AIGP, CIPT, the senior managing counsel for privacy, AI and data for Mastercard. Customers will be looking to understand what value AI adds to their lives and are more likely to choose one whose AI governance they have confidence in, she said.",
            "\"I think it's something that we saw with GDPR, is customers, consumers, investors, they really start focusing on, what are you doing in terms of privacy and data protection? What do you have in place?\" C\u00e9sar said.",
            "There are ways to make AI literacy implementation more approachable. C\u00e9sar said it can be helpful to start by considering what baseline knowledge all employees need to have on AI. She advised the audience to consider role-specific training, noting a data scientist does not need machine learning explained to them but those interacting with high-risk systems, like HR, need a baseline understanding of how the EU AI Act works and how to apply it when using AI.",
            "But, she said AI literacy can be an upskill for employees and encouraged people to see it as an opportunity to teach employees about responsible AI as a whole.",
            "\"Don't approach it as, 'it's an EU thing, so I'm going to make it EU focused, and I'm only going to train my EU employees or people who are interacting with the EU,'\" C\u00e9sar said.",
            "Caitlin Andrews is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/how-different-jurisdictions-approach-ai-regulatory-sandboxes",
        "title": "How different jurisdictions approach AI regulatory sandboxes",
        "location": "",
        "date_published": "14 May 2025",
        "keywords": ["AI Governance"],
        "description": "Regulatory sandboxes provide a controlled environment for companies to test innovations while testing the bounds of regulation under the auspices of the regulator. In several jurisdictions, there are already provisions for sandboxes, which generally allow companies to apply for a waiver of regulatory obligations, often referred to as regulatory relief or mitigation, for a set period while the company tests out an innovative artificial intelligence system or feature. Often this can take the form of a company testing the impacts of an incremental change to current regulations. The coordinating regulator oversees the company and has greater access to observe whether the regulatory obligations should be modified in the future.",
        "content": [
            "Regulatory sandboxes provide a controlled environment for companies to test innovations while testing the bounds of regulation under the auspices of the regulator. In several jurisdictions, there are already provisions for sandboxes, which generally allow companies to apply for a waiver of regulatory obligations, often referred to as regulatory relief or mitigation, for a set period while the company tests out an innovative artificial intelligence system or feature. Often this can take the form of a company testing the impacts of an incremental change to current regulations. The coordinating regulator oversees the company and has greater access to observe whether the regulatory obligations should be modified in the future.",
            "Regulatory sandboxes were first employed to test financial regulations in the U.K. in 2015, leading to various changes to regulations. In recent years, the idea of applying this concept to other innovative technologies has been put forth, as these technologies will likely change in coming years.",
            "The Organisation for Economic Co-operation and Development, citing the use of regulatory sandboxes for financial technologies, recommends governments \"consider using experimentation to provide a controlled environment in which AI systems can be tested and scaled up\" in its AI principles, when regulatory sandboxes could provide such an environment. So far, regulatory sandboxes for AI will be administered in each EU member state, Utah, Singapore and the United Arab Emirates.",
            "The UAE has a goal of becoming the world's AI regulatory testing ground and has had a regulatory sandbox, Regulations Lab, since January 2019 after the creation of the lab was authorized through federal legislation. The lab is a space where companies can apply for temporary licenses to test and vet innovations for innovative technologies, including AI. The lab also seeks to use this lab to anticipate and develop future legislation, learning from the outcomes of the Regulations Lab.",
            "Under Article 57 of the EU AI Act, each member state must set up its own AI regulatory sandbox or participate in a multistate sandbox. The AI regulatory sandboxes in the EU were seen as a way to support innovation in SMEs through limited regulatory relief. During the AI regulatory sandbox period, companies would be permitted to ignore or apply a modified form of a regulation. In 2022, Spain became the first country to pilot an AI sandbox. Each EU member state is obliged to set up their own regulatory sandbox or join another member state's sandbox by 2 Aug. 2026.",
            "Singapore has also used AI sandboxes as a method to boost innovation and gain more insights into a specific topic. In 2023, Singapore had its first sandbox specifically to gather insights into the gaps in generative AI large language model evaluations. Unlike the sandboxes in the EU or UAE, this experiment was aimed at fostering technical innovation in certain sectors rather than regulatory innovation.",
            "It is not clear whether organizations that take part in the sandboxes have access to regulatory relief, as Singapore does not have an EU AI Act-style law regulating AI. Singapore continued to use sandboxes to test innovations in 2024 with one that supported local companies looking to incorporate generative AI in customer engagement and marketing and sales, naming specific AI providers in Singapore with which trials can be conducted.",
            "Utah passed S.B. 149, or the Artificial Intelligence Policy Act, in 2025, leading to the first AI sandbox in the U.S. The Learning Lab allows for participants to receive regulatory mitigation, which aligns more closely with the EU sandboxes than those employed in Singapore. In the U.S., Connecticut, Oklahoma and Texas have proposed bills that would set up sandboxes in their jurisdictions. The proposed legislation includes regulatory mitigation for participation in the sandbox with the goal of supporting innovation.",
            "Organizations that would like to participate in a regulatory sandbox, such as the Learning Lab in Utah, will need to submit a formal application. The regulator overseeing the sandbox will evaluate the economic or societal benefits of the proposed innovation while weighing potential negative implications of regulatory mitigation.",
            "Depending on the jurisdiction, the regulator will accept applicants to a specific cohort or sprint, which groups participants into a specific thematic area, such as generative AI or HR technologies. Before being given regulatory mitigation, the participants might be required to adhere to voluntary data management and security protocols. It should be noted that for participants, they might have to concurrently comply with laws outside of the sandbox while regulatory mitigation is provided only in the specific jurisdiction the sandbox is in.",
            "During the active or testing phase, regulators will receive greater insight into the operations of the participants. After the active phase, regulators will have collected data about the actual benefits of the proposed innovation, as well as the necessity and efficacy of the regulations which were temporarily mitigated. In past regulatory sandboxes, the results of the sandbox led regulators to change their regulations if they were seen to be hampering innovation without providing benefit to consumers.",
            "Many legislators around the world are looking to AI sandboxes as an opportunity to work together with companies to test the utility of regulations. For example, the EU, UAE and several U.S. states have implemented or have pending legislation to implement regulatory sandboxes. Singapore has taken a different approach to gain participants in their sandbox: instead of offering regulatory mitigation, they provide grants and access to AI systems. Advice for regulators and participants in AI sandboxes is forthcoming, as more and more jurisdictions look to implement sandboxes. For example, the Datasphere Initiative has done significant work to design and develop different sandbox initiatives for AI globally. In a recent report, they summarized current and planned sandboxes for AI and data, and provided in-depth guidance on where and how regulatory sandboxes can be best utilized.",
            "The types and configurations of sandboxes are numerous, as there does not seem to be a one-size-fits-all approach to setting up a regulatory sandbox. For companies interested in participating, regulatory sandboxes provide a unique environment to test out their ideas in a controlled, sanctioned environment.",
            "Richard Sentinella is the AI governance research fellow at the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/ai-insurance-discrimination-and-unfair-differentiation-an-overview-and-research-agenda",
        "title": "AI, insurance, discrimination and unfair differentiation: An overview and research agenda",
        "location": "",
        "date_published": "14 May 2025",
        "keywords": ["AI Governance", "Customer Trust & Expectations"],
        "description": "Insurers, in the neutral sense, are always discriminating between groups of people. Their core business is underwriting risks, estimating the expected claims cost through risk assessments. \u00a0",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. ",
            "Insurers, in the neutral sense, are always discriminating between groups of people. Their core business is underwriting risks, estimating the expected claims cost through risk assessments. \u00a0",
            "Many insurers use artificial intelligence to underwrite risks or analyze past data and while such intelligent programs can make risk predictions more accurate, they may also have discriminatory effects on society.",
            "In \"AI, insurance, discrimination and unfair differentiation,\" we investigate how insurers apply AI, identifying two related trends \u2014 data-intensive underwriting and behavior-based insurance \u2014 and possible effects related to discrimination and unfair differentiation.",
            "With data-intensive underwriting, insurers use and analyze more data. With machine learning, insurers could find new correlations in data with which the insurer could more accurately predict the expected claim costs of a certain consumer group.",
            "This form of underwriting comes with potential discrimination-related risks. A legal risk is that insurers could accidentally discriminate indirectly \u2014 disparate impact. For example, if an insurer uses a newly found correlation to set prices, they could inadvertently cause harm to certain ethnic groups, or other groups with legally protected characteristics.",
            "There are other possibly unfair, or at least controversial, effects of data-intensive underwriting. First, consumers may be confronted with prices based on characteristics they have little influence on. In the Netherlands, for example, some insurers charged different car insurance prices based on the consumer's house number. Consumers can influence other characteristics more easily, such as the type of vehicle they buy.",
            "Second, insurers could use certain consumer characteristics to set prices, while the consumer does not see the logic in it. AI systems are good at finding correlations in large datasets. In theory, an insurer could make a correlation between the chance that a consumer files a claim, and whether a consumer has an address with an even number, is born in a certain month, or that people spend more than 50% of their days on streets starting with the letter J. Third, insurers could introduce products that are only intended for specific groups. For example, Promovendum, a Dutch insurer, markets its insurances as being only for the highly-educated. Such practices can be controversial because the insurer targets specific groups of the population, thereby excluding the rest.",
            "Fourth, insurance practices could reinforce inequalities already existing in society. This could occur if an insurer, on purpose or by accident, charges higher prices to lower-income individuals.",
            "With behavior-based insurance, insurers can adapt the price to individual consumers in real-time, based on the consumer's behavior. Some car insurers offer a discount if the consumer agrees to being tracked by the insurer, using a device in the car, and drives safely. A health or life insurer could offer a discount to consumers who, according to their health tracker, walk a certain number of steps. In the U.S., some car insurers track consumers with an app.",
            "An important difference between data-intensive underwriting and behavior-based insurance is that behavior-based insurance bases the price on an individual consumer's behavior rather than the characteristics of a group. Also, behavior-based insurance focuses more on preventing risks than on paying a consumer after a risk has materialized. Insurers could, at least in theory, prevent accidents by nudging risky drivers to drive safer.",
            "The risks of behavior-based insurance are somewhat similar to those with data-intensive underwriting. For example, some people may be excluded from behavior-based insurance, like bad drivers for whom behavior-based car insurance might be so expensive it is out of their reach. In a hypothetical market where all car insurers offer behavior-based insurance, bad drivers may not have the ability to insure themselves affordably.",
            "Behavior-based insurance could reinforce financial inequality. If wealthier people receive more discounts \u2014 based on their health trackers for example \u2014 they pay less.",
            "Both data-intensive underwriting and behavior-based insurance could have several negative effects. It cannot be determined that data-intensive underwriting is more fair than behavior-based insurance, or vice versa. Many aspects of data-intensive underwriting and behavior-based insurance are unclear and deserve more research. For example, it is unclear whether people find behavior-based insurance less attractive than data-intensive underwriting because of the privacy interference that comes with it.",
            "One thing is clear, however, public debate is needed to decide which AI-driven insurance practices are accepted in our societies.",
            "Marvin van Bekkum is a Ph.D. candidate, Frederik Zuiderveen Borgesius is professor of ICT and Law and Tom Heskes is professor of data science at Radboud University."
        ]
    },
    {
        "url": "https://iapp.org/news/a/eu-commissioner-lays-out-suite-of-ai-governance-consumer-protection-goals",
        "title": "EU commissioner lays out suite of AI governance, consumer protection goals",
        "location": "Europe",
        "date_published": "14 May 2025",
        "keywords": [
            "AI Governance",
            "Children's Privacy",
            "Enforcement",
            "Law & Regulation"
        ],
        "description": "The European Commission's lead on democracy and consumer protection reinforced plans to tackle gaps in the bloc's consumer protection laws next year, citing ongoing challenges around addictive designs and dark patterns keeping Europe from having a fair digital single market.",
        "content": [
            "The European Commission's lead on democracy and consumer protection reinforced plans to tackle gaps in the bloc's consumer protection laws next year, citing ongoing challenges around addictive designs and dark patterns keeping Europe from having a fair digital single market.",
            "Commissioner of Democracy, Justice the Rule of Law and Consumer Protection Michael McGrath told attendees at the IAPP AI Governance Global Europe 2025 conference the Commission is aware privacy and artificial intelligence professionals face an increasingly complicated regulatory environment, between the EU General Data Protection Regulation, the AI Act and more digital-specific regulations.",
            "But \"missing pieces of the puzzle\" mean consumers are still losing time, money and trust to unfair practices, he said.",
            "To fix that, McGrath said he will be looking to introduce a new Digital Fairness Act focused on ensuring the rules for using AI solutions in business and consumer situations are clear.",
            "\"The DFA will neither duplicate nor reopen matters already addressed in adopting legislation, and will instead include burden reduction and simplification measures, such as for reducing information requirements in repetitive transactions like in-app purchases,\" he said.",
            "The comments come as the EU is facing a regulatory reckoning, with pressure coming from within and outside the continent to loosen some of its digital rules. The European Commission has been looking at revamping the GDPR to create simpler rules, particularly for smaller and medium-sized businesses. A preliminary plan to change record-keeping obligations has been co-signed by the European Data Protection Board and the European Data Protection Supervisor.",
            "McGrath pitched the revamp as part of a suite of other digital actions planned for this year and the next. He noted the plans for a stronger \"democracy shield,\" a framework meant to strengthen digital protections around issues like misinformation and democracy. A public consultation was recently launched to understand specifically how to address how AI can influence elections.",
            "\"President (Ursula) von der Leyen has already made it clear that there is a growing need to address deepfakes and their potential impact on campaigns and elections across Europe,\" he said.",
            "McGrath also promised to introduce a digital strategy for the justice system looking at how to use AI to streamline processes while protecting rights and making the process transparent. His office is also looking at how to support the market surveillance authorities tasked with enforcing the AI Act on the local level, such as providing unsafe product detection tools and integrating AI into the product safety and enforcement cycle.",
            "The keynote also featured a conversation between Helen Dixon, former commissioner for Ireland's Data Protection Commission, and Ireland's Ombudsman for Children Niall Muldoon about the role his office plays in advocating for better protections for children when it comes to AI harms.",
            "The ombudsman was adamant more work needs to be done in this area and suggested AI products should be designed with children in mind first, with adults needing to toggle additional features in order to access more age-appropriate content. He also stressed the need to include younger people's perspective on AI, noting they are already more enmeshed in its use and are growing up in an environment where generative AI is more common.",
            "\"They're not asking for too much; you ask them what they want, they're fair,\" Muldoon said. \"They don't want a gold star, they just want it to be safe, secure and equal for everybody.\"",
            "But Muldoon saw an opportunity for AI to be better leveraged in education and supported reforming Ireland's final exams to a more continuous assessment approach. Rather than punishing students who use AI in their assignments, he said there should be resources dedicated to teaching them how to use it responsibly and further their educations.",
            "\"It's about finding a solution for it,\" he said, because children are already using the technology. \"And we're not going to be able to put that genie back in the bottle.\"",
            "Caitlin Andrews is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/compliance-technology-adoption-navigating-and-overcoming-challenges",
        "title": "Compliance technology adoption: Navigating and overcoming challenges ",
        "location": "",
        "date_published": "13 May 2025",
        "keywords": [
            "Community & Careers",
            "Third Party Management",
            "Privacy Technology",
            "Regulatory Guidance",
            "Law & Regulation"
        ],
        "description": "Organizations are increasingly dependent on third-party vendors for a wide range of services and technology solutions. Compliance technologies are one example of such solutions, and they encompass platforms, products or services that support organizations, wholly or in part, that automate efforts to meet regulatory and policy compliance requirements. While some may be built in-house the majority are procured from third-party vendors. Indeed, in the IAPP Privacy Governance Report 2024, we identified that almost nine in 10 respondents used a third-party vendor to support cookie consent, while eight in 10 used a third-party vendor to support third-party risk management, regulation tracking and data mapping.",
        "content": [
            "Editor's note: Take the 2025 Governance Survey!",
            "Organizations are increasingly dependent on third-party vendors for a wide range of services and technology solutions. Compliance technologies are one example of such solutions, and they encompass platforms, products or services that support organizations, wholly or in part, that automate efforts to meet regulatory and policy compliance requirements. While some may be built in-house the majority are procured from third-party vendors. Indeed, in the IAPP Privacy Governance Report 2024, we identified that almost nine in 10 respondents used a third-party vendor to support cookie consent, while eight in 10 used a third-party vendor to support third-party risk management, regulation tracking and data mapping.",
            "This is no surprise when considering the need for organizations to adhere to a complex web of laws, regulations, and policies as well as the need to meet governmental, regulatory and consumer expectations. Compliance technologies can play a vital role in supporting organizations to manage these requirements and prevent compliance from becoming a barrier to meeting business objectives and ongoing innovation.",
            "However, organizations may find that using third-party vendor tools is not always as simple as buying and plugging in an off-the-shelf solution. Organizations are likely to have to navigate several critical complexities to successfully procure and integrate third-party compliance technologies.",
            "During the procurement process, organizations must first identify and select the right vendor to deliver the selected services. With a multitude of overlapping technology solutions offered by a variety of vendors, a deep understanding of the organization's specific needs and how potential solutions meet these needs is required. The absence of this risks organizations choosing a solution that may be either too narrow in scope, too broad as a complex governance, risk and compliance platform, lacking in scalability for future needs and business growth, and ultimately unable to support the organization in meeting regulatory and policy requirements.",
            "The integration phase may also present several challenges. Ineffective data governance may hinder effective integration of tooling. The organization may have data silos that increase the challenge of connecting compliance related data to platforms, inaccurate data reducing the effectiveness of reporting, a lack of data ownership that impacts the speed of integration and a lack of documentation over existing infrastructure and legacy systems.",
            "Complex application programing interfaces integration may present further challenges, with incompatible APIs leading to integration failures and limited functionality of the procured tooling solution. Factors such as rate limiting, data transfer restrictions and API functionality are likely to be key considerations as part of both the procurement and integration process.",
            "Legacy systems may present its own unique set of challenges should these need to be integrated with the new compliance solution. Many legacy systems may use outdated technologies or proprietary data formats that do not readily integrate with the compliance solution potentially requiring costly modifications to off-the-shelf solutions or development of custom workarounds. The balance between using standardized tooling and customization of tooling to fit specific organizational needs may need to be assessed at the outset to reduce the likelihood of hidden costs further down the integration journey.",
            "Switching from one vendor to another may add another layer of complexity with vendor dependence and lock in playing a key part of whether the organization can hold existing vendors to account. Barriers in data migration from one vendor to another may reduce likelihood of the organization switching solution providers in the future, perhaps even impacting the quality of service provided by some vendors post-integration.",
            "Ultimately, the success of any new tool is dependent on employees and users adopting and using the tool as intended. Resistance to change, concerns over disruption to existing workflows, and/or a lack of understanding may add to resistance among users. Implementation of effective change management that addresses these concerns as well as offering targeted and tailored training may further support adoption of the third-party compliance tool.",
            "Which of these challenges should organizations seek to address and what might be some potential solutions? In this year's Governance Survey, we\u2019re looking for answers to those very questions. By combining these answers with demographic data from the survey we hope to answer how these challenges vary by organizations of different types and sizes as well as whether perceptions of budget sufficiency and compliance confidence impact the extent to which organizations face these challenges. We hope this offers you the opportunity to benchmark your organization's third-party compliance technology implementations against peer organizations.",
            "Saz Kanthasamy, CIPP/E, CIPM, FIP, is the principal researcher, privacy management for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/policy-analysis-us-house-committee-seeks-moratorium-on-state-AI-rules",
        "title": "Policy analysis: US House committee seeks moratorium on state AI rules",
        "location": "North America",
        "date_published": "13 May 2025",
        "keywords": ["Government", "AI Governance", "Law & Regulation"],
        "description": "Just as U.S. state legislative sessions wind down with more artificial intelligence laws on the books, federal policymakers appear to be seeking limits on state AI enforcement.",
        "content": [
            "Just as U.S. state legislative sessions wind down with more artificial intelligence laws on the books, federal policymakers appear to be seeking limits on state AI enforcement.",
            "In advance of a committee markup scheduled for 13 May, the U.S. House Energy and Commerce Committee published proposed text for its part of a draft budget resolution, which is on a fast-track to passage by the full Republican-controlled Congress.",
            "In relevant part, the proposal seeks to block the enforcement of state AI laws during a time-limited moratorium. Specifically, it reads, \"no State or political subdivision thereof may enforce any law or regulation regulating artificial intelligence models, artificial intelligence systems, or automated decision systems during the 10-year period beginning on the date of the enactment of this Act.\"",
            "IAPP's Editorial team reported on the development 12 May, including initial reactions from stakeholders.",
            "At first blush, this language may seem expansive, as it incorporates prior broad legislative definitions of AI. Laws with the effect of regulating AI are innumerable.",
            "However, the moratorium is presented alongside a \"rule of construction,\" which limits its operation explicitly to those state and local rules that apply differently to AI systems than to other technical systems. Thus, the ban on enforcement appears designed to avoid applying to any technology neutral law, which means it would potentially not affect civil rights, consumer protection, privacy or other laws that treat harmful outcomes the same whether facilitated by AI systems or not.",
            "The language takes some effort to parse, especially as it includes double-negative nested exceptions to exceptions, but the end result appears to be as follows. If a state or local law imposes a \"substantive design, performance, data-handling, documentation, civil liability, taxation, fee, or other requirement\" on covered AI systems, it would be subject to the 10-year enforcement moratorium, unless the requirement (A) is imposed under federal law or (b) is imposed by a generally applicable law that treats non-covered models and systems \"that provide comparable functions\" the same as covered AI models or systems.",
            "Also exempt are state and local laws that do not \"impose a fee or bond.\" And in the case of laws that do impose a fee, they are still exempt if they treat covered systems the same as noncovered systems and only impose \"reasonable and cost-based fees.\"",
            "By its terms, the rule of construction also excludes those laws designed to facilitate the development and deployment of AI, i.e., \"removing legal impediments\" or \"streamlining\" regulatory procedures.",
            "The moratorium would seem to target laws like the Colorado AI Act that singles out high-risk AI systems. It would also proscribe enforcement of other common types of legislative proposals, such as those in the employment sector and those governing the development of foundation models. Its intended effect on the dozens of state AI laws that apply to the states\u2019 own internal governance of such systems is less clear.",
            "But the intended effect of the provision on comprehensive state privacy laws is immediately apparent. The majority of the 19 states with such laws include certain provisions that apply only to automated decision-making technologies. As currently drafted, the moratorium explicitly calls out \"automated decision systems\" and appears to echo the relevant definition under the current draft California regulations \u2014 systems that \"replace human decision making\" \u2014 while also capturing a broader category of systems that \"materially influence\" human decision-making.",
            "If given effect, the proposed moratorium would therefore restrict the enforcement of ADMT rules, while preserving the ability of states to enforce the rest of their comprehensive privacy laws \u2014 assuming the applicability of the remainder of these laws is severable from the effect of the moratorium.",
            "Less clear is any possible effect on other privacy laws, such as those focused on biometrics. If the scope of legal protections for biometric technologies does not extend beyond the bounds of the federal definition of AI systems, could the enforcement of laws like Illinois' Biometric Information Privacy Act be impacted?",
            "The proposed AI moratorium is just one small act of a much longer play.",
            "Congressional Republicans are working to come together around a large package of deep budget cuts and other initiatives that they are seeking to advance as part of a budget reconciliation package, which is not subject to the Senate filibuster, meaning it could pass without Democrat support.",
            "As part of the usual course of the reconciliation process, Congress instructed various committees to submit recommendations on changes in laws within their jurisdiction to help reduce the budget by specified amounts.",
            "The Energy and Commerce committee was asked to reduce the budget by USD880 billion over 10 years. Pursuing this obligation, the committee is entering a markup session 13 May to discuss whether to move forward with four committee \"prints\" covering broad areas within its jurisdiction: energy, environment, health and communications. Though, ostensibly, a legislative vehicle for the budget, bills like this can include new policy directives, so long as they do not violate strict parliamentary rules.",
            "Among other proposed changes \u2014 including authorizing the auctioning of wireless spectrum currently reserved for government uses \u2014 the communications print includes the AI moratorium alongside a USD500 million budget for the U.S. Department of Commerce to \"modernize and secure Federal information technology systems through the deployment of commercial artificial intelligence, the deployment of automation technologies, and the replacement of antiquated business systems.\"",
            "It is not by accident that the AI moratorium language occurs as part of a provision authorizing new spending by the Department of Commerce to acquire commercially available AI systems. There are strict congressional rules on the types of policy provisions that can be included in budget reconciliation bills and committees must carefully design their component legislative text to survive possible later challenges.",
            "Most importantly, once the reconciliation bill reaches the Senate, it is subject to what is known as the Byrd rule, which prohibits any matter that is \"extraneous to the instructions\" sent to the committee. Nonbudgetary provisions are prohibited as are provisions where the budgetary provisions are \"merely incidental\" to their non-budgetary components.",
            "If the language reaches the version of the reconciliation bill considered by the Senate, Senators can bring objections under the Byrd rule, which allows for the surgical removal of any offending provisions.",
            "Here, though not explicit in the text itself, the committee appears to be setting up the argument that a moratorium on the enforcement of complex and diverging state AI laws will facilitate the Department of Commerce\u2019s acquisition of AI systems. Though critics will see this as contrived, the logical connection here seems to be that the federal government is unable to modernize systems effectively and efficiently if the spread of commercially available AI is slowed by a patchwork of state AI laws.",
            "Such arguments echo a well-timed op-ed by Kevin Frazier and Adam Thierer in Lawfare calling for a \"learning period moratorium\" if Congress is unable pass its own preemptive AI governance rules. In turn, the op-ed cites R Street's recent comments to the Energy and Commerce Committee's request for information on privacy and security legislation. The comment concludes:",
            "\"A pro-freedom, pro-innovation national policy framework for AI and advanced computation is essential if the United States hopes to win the race to be the global leader for the 'most important general-purpose technology of our era.' A learning period moratorium can help ensure that result by preventing a patchwork of rushed regulatory solutions from undermining AI opportunity in America.\"",
            "The AI enforcement moratorium also has powerful allies in the Senate. Sen. Ted Cruz, R-Texas, who chairs the Senate Commerce Committee, has already voiced public support for a moratorium. In comments at a hearing last week, he adopted R Street's language and questioned witnesses about their thoughts on a \"learning period moratorium.\"",
            "What sounded at the time to be a relatively off-hand question now shows that lawmakers have been coordinating across chambers to prepare for this de-regulatory initiative.",
            "As supportive evidence for the moratorium idea, its champions routinely cite the success of Clinton-era policies that encouraged the regulation-free growth of the internet economy. Specifically, they point to the Internet Tax Freedom Act, a 1998 law that prohibited states from implementing new taxes on internet access or e-commerce transactions for an initial three-year moratorium period.",
            "Commenters \u2014 and probably state attorneys general \u2014 will raise constitutional questions about the ability of the federal government to limit state's ability to enforce their own laws.",
            "Such questions are similar but not entirely contiguous with the complex area of federal preemption. Since preemption requires the federal government to commit to positive policies over the areas of law that it preempts, the moratorium idea seems to be a fallback option, and one that is potentially more defendable under principles of federalism.",
            "This argument held water with the internet tax moratorium. But there are significant differences here. Both moratoria rely on the strong interstate commerce powers of the federal government. But taxes on e-commerce transactions are so inextricably tied to interstate commerce that it is difficult to make an argument otherwise. The connection to the development of commercially available AI systems will rely on similar arguments, but is almost certainly more attenuated.",
            "If the momentum in support of a moratorium results in its final passage, it is almost certain to result in legal challenges. It will take some time to feel its full impact.",
            "But one thing is clear: Republicans are serious about their commitment to a de-regulatory moment for AI.",
            "Cobun Zweifel-Keegan, CIPP/US, CIPM, is the managing director, Washington, D.C., for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/house-commerce-committee-floats-10-year-moratorium-on-state-level-ai-enforcement",
        "title": "House Commerce Committee floats 10-year moratorium on state-level AI enforcement ",
        "location": "",
        "date_published": "12 May 2025",
        "keywords": ["AI Governance", "Enforcement", "Law & Regulation"],
        "description": "Last week, U.S. House Energy and Commerce Chairman Brett Guthrie, R-Ky., announced a full committee markup of the committee's budget reconciliation text. Set for Tuesday, 13 May at 2 p.m. ET, a memorandum from the majority staff to committee members and staff, which was published Sunday, 11 May, includes language that could lead to a halt on enforcement of state-level laws related to artificial intelligence systems.",
        "content": [
            "Last week, U.S. House Energy and Commerce Chairman Brett Guthrie, R-Ky., announced a full committee markup of the committee's budget reconciliation text. Set for Tuesday, 13 May at 2 p.m. ET, a memorandum from the majority staff to committee members and staff, which was published Sunday, 11 May, includes language that could lead to a halt on enforcement of state-level laws related to artificial intelligence systems.",
            "In part 2 (page 9), subsection (c) states that \"no state or political subdivision may enforce any law or regulation regulating artificial intelligence models, artificial intelligence systems, or automated decision systems during the 10-year period beginning on the date of enactment of this Act.\"",
            "Additional text can be found under section c (page 6), which includes text on the \"rule of construction\" of the moratorium.",
            "In his press release announcing the full markup, Guthrie said that through the reconciliation process the committee \"is working to ... unleash American energy and innovation.\"",
            "On Monday afternoon, Energy and Commerce Committee Democrats criticized provisions in the reconciliation bill.",
            "Commerce, Manufacturing, and Trade Subcommittee Ranking Member Jan Schakowsky, D-Ill., said the AI moratorium \"gives Big Tech free reign to take advantage of children and families\" and \"allow AI companies to ignore consumer privacy protections, let deepfakes spread, and allow companies to profile and deceive consumers using AI.\"",
            "California Privacy Protection Agency Executive Director Tom Kemp, whose agency is currently drafting state regulations related to automated decision-making technology, said, \"When we block responsible safeguards in the face of rapid technological change, we make ourselves \u2014 and future generations \u2014 less safe from privacy harms.\" Kemp called on \"Congress to strike this provision and uphold its longstanding approach to federal privacy and technology legislation: establish a baseline for protections while preserving states' authority to adopt stronger laws.\"",
            "IAPP Managing Director, Washington, D.C., Cobun Zweifel-Keegan, CIPP/US, CIPM, analyzed the proposal, noting that \"the ban on enforcement appears designed to avoid applying to any technology-neutral law, which means it would potentially not affect civil rights, consumer protection, privacy or other laws that treat harmful outcomes the same whether facilitated by AI systems or not.\"As can be seen in the IAPP U.S. State AI Governance Legislation Tracker, there is no shortage of AI-related bills across the country.",
            "In a post for Lawfare, Kevin Frazier and Adam Thierer wrote that the proliferation of AI bills \"could undermine the nation's efforts to stay at the cutting edge of AI innovation at a critical moment when competition with China for global AI supremacy is intensifying.\" They call on Congress \"to get serious about preemption.\"",
            "In comments provided to the IAPP, Goodwin Partner Omer Tene said, \"There's certainly great concerns in industry about the avalanche of state legislative bills regulating various aspects of AI. If privacy regulation is a patchwork, this is emerging to resemble an artwork comprising microplastics.\"",
            "It is unclear whether the committee will accept the 10-year moratorium or whether it will face legal challenges.",
            "Tene adds that \"federal moratoriums are rare and have typically focused on very specific technologies, which are regulated at the federal level (e.g. commercial drones). Here, Congress purports to block regulation of an incredibly broad, all encompassing technology, and to do so absent any semblance of federal regulation.\"",
            "Tene points to legal precedent. \"In my opinion, it's in tension with the Tenth Amendment anti-commandeering principle as applied in Murphy v. NCAA.\"",
            "Husch Blackwell Partner David Stauss, CIPP/E, CIPP/US, CIPT, FIP, PLS, also questioned whether such a moratorium would be legal.",
            "He points out that \"some states, such as Kentucky, have passed laws regulating the state's use of AI systems. Other states, such as Kansas, have passed laws restricting the state's use of DeepSeek. Based on the limited information available, even that type of regulation would be prohibited.\"",
            "How many laws would be affected is up in the air, but depending on how the federal government defines terms, the scope could be considerable.\"A lot would depend on how the terms are defined,\" Stauss said. \"Keep in mind that the Colorado AI Act uses a broad definition of AI based on the OECD definition, while other proposed state definitions have used narrower definitions intended to cover only things like large language models. While Colorado has a broad definition, it includes many carveouts such as firewalls, storage, and calculators, to name a few. If the federal definition is really broad, then all sorts of laws could be implicated, even product liability and medical malpractice laws as extreme edge cases.\"",
            "In addition to the plethora of proposed AI bills, it is unclear what kind of effect such moratorium would have on existing privacy laws.",
            "\"The right to opt out of profiling in the state consumer privacy laws would be preempted given that those are defined specifically by reference to automated decision making.\"",
            "Notably, the California Privacy Protection Agency recently published modified draft text for its proposed automated-decision making technology regulations. These are open to public comment until 2 June.",
            "Stauss added, \"While we tend to focus on the algorithmic discrimination, provenance, and disclosure laws, states have passed laws on many different AI-related topics such as the use of AI in elections, deep fakes, name, image and likeness, CSAM, and healthcare. Numerous state insurance regulators have also adopted the NAIC model bulletin, with insurance being a state-regulated industry.\"",
            "Consumer Reports announced its opposition to the proposed moratorium Monday afternoon. \"Congress has long abdicated its responsibility to pass laws to address emerging consumer protection harms; under this bill, it would also prohibit the states from taking actions to protect their residents\" CR Policy Analyst for AI Issues Grace Gedye said.",
            "\"This incredibly broad preemption would prevent states from taking action to deal with all sorts of harms, from non-consensual intimate AI images, audio, and video, to AI-driven threats to critical infrastructure or market manipulation, to protecting AI whisteblowers, to assessing high-risk AI decision-making systems for bias or other errors, to simply requiring AI chatbots to disclose that they aren't human.\"",
            "This article has been updated to include response from House Committee Democrats, the CPPA and Zweifel-Keegan's analysis.",
            "Jedidiah Bracy is the editorial director for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/dufresne-announces-opc-consultation-on-potential-childrens-privacy-code-for-canada",
        "title": "Dufresne announces OPC consultation on potential children's privacy code for Canada",
        "location": "",
        "date_published": "12 May 2025",
        "keywords": [
            "Children's Privacy",
            "Customer Trust & Expectations",
            "Enforcement",
            "Law & Regulation",
            "Frameworks & Standards"
        ],
        "description": "The Office of the Privacy Commissioner of Canada is moving into the next phase of work to address its strategic priority on children's privacy. Commissioner Philippe Dufresne announced at the IAPP Canada Privacy Symposium 2025 that the OPC is opening an \"exploratory consultation\" on potentially devising a federal children's privacy code.",
        "content": [
            "The Office of the Privacy Commissioner of Canada is moving into the next phase of work to address its strategic priority on children's privacy. Commissioner Philippe Dufresne announced at the IAPP Canada Privacy Symposium 2025 that the OPC is opening an \"exploratory consultation\" on potentially devising a federal children's privacy code.",
            "In a press release following Dufresne's announcement, the OPC described a potential code as means to help companies \"ensure that their products and services are designed with the highest standards of privacy and data protection in mind.\"",
            "Dufresne told CPS attendees the OPC recognizes the \"unique sensitivities\" around children's personal data and a potential code \"will be aimed at creating a safer, more transparent online environment for children.\" He added, \"We want young people to feel empowered to exercise their privacy rights and to safely explore, learn and grow without compromising their privacy or security.\"",
            "The consultation is scheduled to run through 5 Aug. with results to be presented in the following months. Dufresne said specific questions will cover \"the role of consent, how privacy impact assessments can address the best interest of the child, as well as best practices and no-go zones.\"",
            "The OPC's motivations for examining the feasibility and appetite for a children's code are wide-ranging. It would be the latest initiative in the children's privacy prong of the office's 2024-2027 strategic plan following the completion of a consultation on age assurance in March.",
            "Among the lead factors for consideration of a code is Canadian parents indicating an urgent need for enhanced children's safeguards exists. Those views are reflected in the children's privacy response contained in the OPC's recently released 2024-2025 Public Opinion Research on Privacy Issues, which Dufresne highlighted in his remarks.",
            "\"The survey found the vast majority of parents worry about their children's privacy online,\" Dufresne said. \"Two-thirds or more (of parents) are moderately to extremely concerned, with 45% highly concerned about risks to their child from the use or misuse of their personal information.\"",
            "The OPC's survey offered some segmented responses to fully understand the issues at hand, asking parents about issues related to children ages 6-12 and teens ages 13-17. Notably with views on companies' children's privacy practices, 74% of respondents have little or no trust in children's data handling and protection.",
            "During a CPS breakout session, Concordia University Postdoctoral Fellow Christopher Dietzel and MediaSmarts Director of Education Matthew Johnson each outlined similar children's viewpoints observed in their research work.",
            "Dietzel indicated the surveillance landscape around children's data and their online presence isn't lost on the children themselves. He said they've \"accepted or normalized\" the tracking practices, but that \"doesn't necessarily mean that they approve of privacy settings or certain privacy infractions and transgressions.\"",
            "Johnson cited recent MediaSmarts privacy research revealing two-thirds of teens believe if a website has a privacy notice then the operator is not collecting data on a user at all instead of understanding notices explain collection and use. Meanwhile, many youth respondents were skeptical of location-sensing practices on platforms, which Johnson referred to as a crossroads for minors with the \"the overlap between corporate surveillance and parental surveillance.\"",
            "\"Almost 61% feel that you shouldn't be able to track online activities,\" Johnson said. \"But they also feel that excessive protection from surveillance can be stifling and make it harder to seek help from trusted adults.\"",
            "Canada would not be the first country to enact a children's privacy code. In his CPS remarks, Dufresne hopes to \"replicate\" the codes adopted in Australia and the U.K. as well as similar state-level bills in the U.S.",
            "Canada's code isn't likely to be a one-for-one match with global partners, but the exploration is a product of ongoing the international collaboration by the OPC.",
            "The OPC led the Global Privacy Enforcement Network's 2024 sweep on deceptive design patterns, bringing together 26 global data protection authorities in a probe of 1,010 websites. The OPC is also working on an investigation into genetic testing company 23andMe with the U.K. Information Commissioner's office, which oversees enforcement of the U.K. Children's Code.",
            "McMillan Partner Lyndsay Wasser, CIPP/C, said during a CPS breakout session the OPC has to look outside Canada's borders for solutions on children's privacy because many jurisdictional statutes are \"silent\" or \"missing\" the children's angle. She pointed to OPC guidance on children's privacy, and its principles for data governance as well as requirements for privacy impact assessments and privacy by design and by default, as building blocks for an improved legal framework.",
            "\"There's no reason some of those couldn't be built into a statute,\" Wasser said. \"We have these general principles and regulators are clear about what they expect to see, while many organizations want to do it the right way. ... They don't want to be the test case to take it to a court and challenge the implementation.\"",
            "Joe Duball is the news editor for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/irelands-dpc-discusses-recent-tiktok-enforcement-decision",
        "title": "Ireland's DPC discusses recent TikTok enforcement decision",
        "location": "Europe, Asia",
        "date_published": "12 May 2025",
        "keywords": [
            "Government",
            "Data Processing",
            "Data Protection Obligations",
            "Enforcement",
            "International Data Transfers"
        ],
        "description": "The 530 million euro fine by Ireland's Data Protection Commission against TikTok could mark a watershed moment in data transfer enforcement under EU General Data Protection Regulation.",
        "content": [
            "The 530 million euro fine by Ireland's Data Protection Commission against TikTok could mark a watershed moment in data transfer enforcement under EU General Data Protection Regulation.",
            "The DPC issued the fine after an investigation found the company did not comply with GDPR data transfer obligations as TikTok's remote access practices allowed European Economic Area\u00a0user data to be shared with employees located in China. The move served as the first data transfer fine from an EU member state to China.",
            "In an IAPP LinkedIn Live, DPC Deputy Commissioner Cian O'Brien said employees at ByteDance, TikTok's parent company, were granted access to EEA user data for business needs, which also resulted in personal data transfers to China \"in circumstances where the transfers were found to be systemic, repetitive and continuous.\" Despite TikTok not directly storing vast amounts of EU user data on servers in China, \"it's very clear that this remote access did result in a very significant transfer of EEA user data to China,\" O'Brien said.",
            "The DPC's investigation analyzed the company's privacy policies from 2021-23, where it determined TikTok did not sufficiently inform data subjects their data would be transferred outside the EEA. TikTok updated its privacy policy during the probe, though the DPC issued its decision based on aspects of its 2021 policy which claimed, \"data was stored on servers outside of China, and that it was the subject of limited remote access by entities in TikTok's corporate group located in China,\" O'Brien said.",
            "Due to the DPC's investigation findings, the social platform was ordered to bring its data transfer operations into compliance with the GDPR's obligations within six months or face a potential suspension of TikTok's data transfers to China.",
            "While TikTok did acknowledge discrepancies between the EU and China's data protection standards, \"it did not adequately define the scope of those divergences. So, it did not consider the divergences in the specific context of the specific transfers,\" O'Brien said. \"TikTok's position was that, as the data was stored outside of China, the divergences in Chinese law do not result in that lack of essential equivalence.\"",
            "In response to the DPC's fine, TikTok noted the decision focused on the company's data transfer standards before the implementation of its Project Clover initiative, which now stores European users' data \"in a dedicated European data enclave.\"",
            "O'Brien said the DPC considered changes made by TikTok when forming its enforcement decision and determined it was \"still necessary\" to order the company to bolster its compliance.",
            "When transferring consumer data to another country, organizations must assess countries' data protection standards and ensure policies regarding the collection and use of data is transparent for consumers.",
            "\"Wherever an entity is transferring personal data based on standard contractual clauses, it must not commence those transfers until it has verified and guaranteed an essential equivalent level of protection. And if it cannot do that, it must not proceed with the transfers,\" O'Brien noted.",
            "The DPC's enforcement against TikTok has gone uncontested by other EU data protection authorities, potentially signaling a trend in DPA enforcement of GDPR's data transfer obligations. O'Brien claimed as the GDPR enters its seventh year of enactment, \"there's a lot more certainly in the law which makes it a lot easier for data protection authorities to agree on the correct interpretation on really novel and really tricky points of law.\"",
            "With major enforcement decisions and hefty fines for organizations, companies should fully address compliance obligations and be able to dispute potential concerns from regulators. If organizations' standard contractual clauses do not \"verify and guarantee essential equipment\" for their specific data transfers, O'Brien recommended companies \"look for alternatives and to look at localization, to look at derogations, and to not commence transfers until they have achieved that level of essential equivalence.\"",
            "Lexie White is a staff writer for the IAPP."
        ]
    }
]
