[
    {
        "url": "https://iapp.org/news/a/how-proposed-ai-enforcement-moratorium-cuts-into-us-state-level-powers",
        "title": "How proposed AI enforcement moratorium cuts into US state-level powers",
        "location": "",
        "date_published": "27 June 2025",
        "keywords": "[{\"keyword\": \"policymakers\", \"score\": 0.4644}, {\"keyword\": \"congress\", \"score\": 0.4479}, {\"keyword\": \"legislation\", \"score\": 0.435}, {\"keyword\": \"moratorium\", \"score\": 0.4122}, {\"keyword\": \"proposal\", \"score\": 0.3608}]",
        "description": "Public policy differences between the U.S. Congress and state legislatures are routine, especially with debates on digital policy. The latest example comes with U.S. Congress' proposed 10-year ban on enforcing state artificial intelligence laws, viewed by state lawmakers and enforcers as cutting into their respective authority and mission to serve their constituents.",
        "content": [
            "Public policy differences between the U.S. Congress and state legislatures are routine, especially with debates on digital policy. The latest example comes with U.S. Congress' proposed 10-year ban on enforcing state artificial intelligence laws, viewed by state lawmakers and enforcers as cutting into their respective authority and mission to serve their constituents.",
            "The moratorium emerged from the U.S. House's budget reconciliation proposal in May and has withstood criticism and updates to reach a potential full Senate vote. The current iteration of the moratorium, characterized in the Senate bill as a \"temporary pause,\" moves away from an outright ban and ties states' compliance to their right to access a federal funding pool for broad infrastructure improvements.",
            "IAPP Managing Director, Washington, D.C., Cobun Zweifel-Keegan, CIPP/US, CIPM, redlined the latest changes to the provision, which is still receiving bipartisan opposition in the Senate despite momentum toward inclusion in the final bill text. The Senate bill will require concurrence back in the House, where opposition now exists after the lower chamber's initial approval of the AI provision.",
            "According to Politico, the Senate parliamentarian is asking the Senate Committee on Commerce, Science and Transportation to clarify the exact nature of the broadband funding tie before the provision can move forward. Confusion exists as to whether noncompliance would prohibit access to the full USD42 billion fund or a USD500 million allocation, with the former scenario likely to add to existing Senate Republican opposition.",
            "The motivation behind the moratorium is clear: Avoid watering down a booming industry with fragmented regulation. U.S. Sen. Ted Cruz, R-Texas, has touted his AI proposal as necessary to support American leadership on AI innovation.",
            "While Congress is focused on AI's potential, states are keeping consumer safety front and center.",
            "States have been firm with their displeasure over the moratorium from the onset. State lawmakers and enforcers have sent multiple letterspleading their case against limiting states to establish AI governance requirements and mitigate harms that may crop up from AI development and use.",
            "\"There's nothing to fall back on. This moratorium\u00a0actually reduces rights that people currently have,\" California Privacy Protection Agency Executive Director Tom Kemp told the IAPP. \"We've always believed, whether it's AI, automated decision-making or privacy, there should be a high floor. But even then, there should be an ability for states to go over and beyond to best address the needs of their constituents.\"",
            "In the latest opposition letter, Kemp joined six state attorneys general to reiterate to Senate leadership how the proposal does not benefit consumer protection. They claimed the ban would \"create a regulatory vacuum that benefits AI developers at the expense of privacy rights\" and AI-driven technology \"demands the flexibility and responsiveness that only multi-level governance can provide.\"",
            "Meanwhile, industry recognizes the appetite for firm guardrails, but largely views a potential state patchwork as unworkable.",
            "OpenAI Associate General Counsel for AI Policy and Regulation Ben Rossen, CIPP/US, said the state patchwork on comprehensive privacy law is \"not ideal\" but has become \"manageable\" due to aligned concepts and provisions. However, he indicated the many interpretations of AI across state lines might not yield the same sense of harmonization.",
            "\"The AI moratorium is actually a fascinating thing,\" Rossen said at the IAPP and Berkman Klein Center For Internet and Society's Digital Policy Leadership Retreat 2025. \"More than 1,000 bills have been proposed on AI in the past six months. Some of them really do kind of regulate these sort of fundamental national security questions. ... But a state-level patchwork of all these frontier (AI) regulations would also be really damaging.\"",
            "State lawmakers are singing a consumer-focused refrain in their opposition to the moratorium.",
            "In a 3 June letter to Congress, lawmakers harped on needing the ability and runway to support consumer concerns and risks. They wrote, \"AI will raise some of the most important public policy questions of our time, and it is critical that state policymakers maintain the ability to respond.\"",
            "The letter also covered how states can be \"more nimble in their response\" to AI than Congress and a moratorium in this moment would \"would freeze policy innovation in developing the best practices for AI governance at a time when experimentation is vital.\"",
            "\"Over the past several years, states across the country have enacted AI-related laws increasing consumer transparency, setting rules for the government acquisition of new technology, protecting patients in our health care system, and defending artists and creators,\" lawmakers wrote.",
            "In prior remarks to the IAPP on the passing of the Texas Responsible Artificial Intelligence Governance Act, state Rep. Giovanni Capriglione, R-Texas, raised similar flags spelled out in the letter. He argued the vague and proscriptive nature of the current provision is not workable while Congress does not currently have an immediate federal fallback if issues arise in the next 10 years.",
            "\"I appreciate all the federal government does. However, they have not really been able to work on super complicated, technical things like this for a long time and actually get them passed,\" Capriglione said. \"I would make the case (Congress) is still quite a ways away from having something in place that will sufficiently protect my constituents here in the state of Texas.\"",
            "Hall Estill Partner Collin Walke served as Democrat member of the Oklahoma House from 2016-22, spearheading the state legislature's comprehensive privacy law efforts over multiple years. A common refrain in his side of debates was Oklahoma needed to act because Congress was not, an argument he insists is resurfacing here.",
            "\"It's astounding that the federal government would prohibit states from taking up important issues affecting their citizens,\" Walke told the IAPP. \"We elect our officials to solve problems. If our federal delegation is unwilling to act, the states absolutely must.\"",
            "There is a difference between an attempt to harmonize approaches versus the objective of the moratorium, according to Center for Democracy and Technology CEO Alexandra Reeve Givens. She told IAPP-Berkman Klein Center retreat attendees that the proposed ban can be viewed as 10-year \"free pass\" and supports state legislators fighting back.",
            "\"You can't deny the rights of different jurisdictions, whether regulatory agencies or, in this case, states, to do their jobs and protect their citizens if people at the federal or harmonized level aren't doing so,\" she said.",
            "State Rep. Steve Elkins, D-Minn., told the IAPP that Minnesota has AI-focused laws concerning deepfakes in elections and revenge porn that would clearly be paused under the moratorium. Minnesota's comprehensive privacy law, which Elkins authored and takes force 31 July, might also be a casualty based on its AI ties in definitions and provisions for \"profiling\" and \"legally consequential decisions.\"",
            "\"These provisions would probably be preempted even though the words 'artificial intelligence' are nowhere to be found in these provisions,\" Elkins said. \"I think it's silly to try to define AI for this use case. There is a continuum of mathematical prediction techniques used to \"profile\" consumers, ranging from regression analysis to neural networks. Even within the neural network family of techniques there is a continuum with respect to transparency. No judge or jury will ever be able to find that boundary.\"",
            "Unlike Elkins, Walke does not envision existing state privacy laws getting swept up in the budget provision.",
            "\"That would be a big legal fight given the number of states that have enacted such legislation,\" he told the IAPP. \"And there's the fact that most companies are already able to comply with the data privacy laws on the books, so there is no longer a reason to push back.\"",
            "Walke added the legal battles are likely to come from states with a \"heavy technological presence\" while others have \"little incentive\" to challenge because AI is not a legislative priority for them.",
            "Joe Duball is the news editor for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-iapp-canada-building-momentum-to-address-youth-privacy-issues",
        "title": "Notes from the IAPP Canada: Building momentum to address youth privacy issues ",
        "location": "",
        "date_published": "27 June 2025",
        "keywords": "[{\"keyword\": \"conversations\", \"score\": 0.3771}, {\"keyword\": \"privacy\", \"score\": 0.3597}, {\"keyword\": \"presenters\", \"score\": 0.3591}, {\"keyword\": \"interviewing\", \"score\": 0.3524}, {\"keyword\": \"iapp\", \"score\": 0.3503}]",
        "description": "I was at an event last week focused on youth privacy issues and how young people are inheriting a whole new world that requires skills, knowledge and savvy to navigate. Privacy Commissioner of Canada Philippe Dufresne moderated the day's first panel which featured a handful of some of the most impactful speakers I've heard in a while.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "I was at an event last week focused on youth privacy issues and how young people are inheriting a whole new world that requires skills, knowledge and savvy to navigate. Privacy Commissioner of Canada Philippe Dufresne moderated the day's first panel which featured a handful of some of the most impactful speakers I've heard in a while.",
            "His panel involved interviewing a number of younger people \u2014 mid to older teens \u2014 about what they thought about privacy, privacy laws, artificial intelligence and data regulation, and it was fantastic. Their presentations were thoughtful, humorous, insightful and genuinely human. I'm going to enjoy watching from the sidelines as these individuals develop their careers.",
            "What was cool was that these young people stuck around for the entire day and as different presentations were made on the main stage, at each turn, they asked from their table in the audience \u2014 over the microphone so that everyone could hear \u2014 some pointed and difficult questions of the presenters. And these, I would add, were not planted questions.",
            "I thought it was particularly meaningful because the data protection authorities from the G7 countries were all listening and taking notes. I know from the final DPA remarks and the cocktail reception after the event that they were all influenced by the day's conversations and interactions. I shared quite a few details about the day in a LinkedIn post, so those who were not there could get a flavor of it.",
            "Youth privacy is a big concern today and I'm totally on-board with creating a better environment for them as they explore this new frontier. Some of my clients are social media companies and I can see from working with them that they want to do right by our planet's youth. One of my clients has me do a weekly scan of anything that might be relevant to them just in this space alone \u2014 it's that important.",
            "Late last week an opposition party member of Parliament introduced Bill C-216, a private-member's bill called \"An Act to enact the Protection of Minors in the Digital Age Act and to amend two Acts.\" Private member's bills rarely get through the legislative process. This one, however, may have some merit, so we will be watching it closely when Parliament resumes in the fall.",
            "Here is a quick summary of the proposed new law:",
            "Protection of Minors in the Digital Age Act",
            "Mandatory reporting of child sexual abuse material",
            "Criminal Code amendments",
            "To say the least, partisan politics aside, this issue is a pressing and important one. In fact, it is one of the most important of our generation and the world we leave our kids and grandkids. (The youngest just graduated high school this week. I'm not in a rush; just sayin'.)",
            "Let's collectively build on the momentum to figure out ways this can be done and done in a way that, as the young people said last week, respects their privacy but also their autonomy and ability to grow, explore, be creative and be human.",
            "Kris Klein, CIPP/C, CIPM, FIP, is the managing director, Canada, for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/navigate-2025-potential-eu-ai-act-pause-opens-new-questions-on-approach-to-global-regulation",
        "title": "Navigate 2025: Potential EU AI Act pause opens new questions on approach to global regulation",
        "location": "",
        "date_published": "26 June 2025",
        "keywords": "[{\"keyword\": \"ai\", \"score\": 0.4309}, {\"keyword\": \"regulation\", \"score\": 0.3961}, {\"keyword\": \"delay\", \"score\": 0.3913}, {\"keyword\": \"pause\", \"score\": 0.339}, {\"keyword\": \"eu\", \"score\": 0.2416}]",
        "description": "The increasing sentiment around artificial intelligence regulation is global policy makers are being left to put a square peg in a round hole given the speed at which AI development is proliferating. It begs the question whether regulation can be done \"right\" and what that looks like, especially with the EU looking more and more likely to stop the clock on implementation of the landmark AI Act with an eye toward reassessing its regulatory approach.",
        "content": [
            "The increasing sentiment around artificial intelligence regulation is global policy makers are being left to put a square peg in a round hole given the speed at which AI development is proliferating. It begs the question whether regulation can be done \"right\" and what that looks like, especially with the EU looking more and more likely to stop the clock on implementation of the landmark AI Act with an eye toward reassessing its regulatory approach.",
            "Speaking at the IAPP and Berkman Klein Center For Internet and Society's Digital Policy Leadership Retreat 2025, Irish Member of European Parliament Michael McNamara indicated all signs point to an AI Act pause because stakeholders simply \"need time and need to know what it is they have to adhere to.\" But he warned attendees about the potential perils of any sort of pause.",
            "\"The AI Act is very far from perfect, but I do think it was a welcomed attempt to govern in this area,\" McNamara said. \"I think a delay is acceptable, but there comes a point at which any delay, if it's for a long time, just kind of deprives (the regulation) of the momentum it needs to work. That would be a concern.\"",
            "The signs are clear, according to McNamara. Escalated pressures, notably led by the U.S., around perceived burdens brought on by EU digital regulation is one factor while a lag in providing essential deliverables for AI Act implementation is another.",
            "The chief concern around implementation derives from the European Commission stretching out the deadline to release the general-purpose AI code of practice, which aims to help AI Act covered entities better understand and prepare for the act's GPAI requirements to take effect 2 Aug.",
            "McNamara said the release of the code before the GPAI requirements take force \"looks ambitious now,\" making an implementation delay a logical option.",
            "\"It hasn't been finalized yet and the date it was expected to be finalized was 2 May. Obviously that's passed and we don't see any immediate finalization (coming soon),\" said McNamara, adding that covered entities are are focused on the code as a \"presumption of compliance.\"",
            "The EU is not alone in trying to find a regulatory balance on AI. Japan and South Korea offer recent examples of frameworks that divert from the AI Act while U.S. state-level legislation ranges from covering cross-sectoral AI development and use to more targeted legislation, including bills on automated decision-making and deepfakes.",
            "OpenAI Associate General Counsel for AI Policy and Regulation Ben Rossen, CIPP/US, told retreat attendees AI-specific legislation is in flux, but that does not mean companies do not have existing statutes in sight when they are developing and using new technologies.",
            "\"In some ways, there is a host of regulation that already exists. There's consumer protection law, tort law, product liability law and all these things that already exist to regulate AI,\" Rossen said. \"And yet, the very common perception is that AI is still largely unregulated.\"",
            "The application of new or existing laws remains a point of friction. Companies cannot be left uninformed, according to Guido Scorza, board member for Italy's data protection authority, the Garante, and enforcers must take seriously their responsibility to spell out the law clearly.",
            "\"The tension between innovation and regulation isn't new at all,\" Scorza said. \"We were, and probably still aren't, always able to to give industry legal certainty in time. That's our most important responsibility, because it's our duty to recognize if society is changing and needs a faster regulatory solution than in the past.\"",
            "The panel discussed the potential for more self-regulation among AI companies in the absence of hard rules.",
            "Rossen said context is important, as broad self-regulation over AI \"does not strike anybody in industry as a responsible way of regulation.\" However, he indicated a common \"preparedness framework\" currently adopted across large AI developers is creating foundational standards.",
            "While the framework isn't identical among companies, the aim to evaluate safe AI capabilities while emphasizing risk assessment is a common priority.",
            "\"There are huge incentives already for companies to take the challenge that AI poses extremely seriously, regardless of regulation,\" Rossen said.",
            "Scorza said he \"can't accept\" self-regulation, noting AI's inherent connection to fundamental rights, including speech and privacy, leaves \"no space\" for companies to police themselves. Instead, he pitched co-regulation where policy makers set a flexible framework aimed at closer cooperation with companies.",
            "Policy makers are left to regulate what is \"being deployed in the public space,\" according to McNamara, making self-regulation a measure for developers' internal practices.",
            "\"What people do in the privacy of their own labs is a different matter,\" McNamara said. \"That's when their own regulation, boards, etc., come into play. And quite frankly, it's relationships that they have with states and nation states because there are close links.\"",
            "Joe Duball is the news editor for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-iapp-europe-data-protection-and-ai-in-focus",
        "title": "Notes from the IAPP Europe: Data protection and AI in focus",
        "location": "",
        "date_published": "26 June 2025",
        "keywords": "[{\"keyword\": \"eu\", \"score\": 0.4199}, {\"keyword\": \"gdpr\", \"score\": 0.3993}, {\"keyword\": \"legislation\", \"score\": 0.3642}, {\"keyword\": \"disputed\", \"score\": 0.2725}, {\"keyword\": \"deadlines\", \"score\": 0.2613}]",
        "description": "The end of June marks the wrap-up of Poland's six-month presidency of the Council of the European Union. Before it passes the baton to Denmark 1 July, Poland managed to bring to a close one of its priority files \u2014 a proposal for a regulation on additional procedural rules relating to enforcement of the EU General Data Protection Regulation. The council and the European Parliament reached a long-awaited provisional agreement on the file 16 June.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "The end of June marks the wrap-up of Poland's six-month presidency of the Council of the European Union. Before it passes the baton to Denmark 1 July, Poland managed to bring to a close one of its priority files \u2014 a proposal for a regulation on additional procedural rules relating to enforcement of the EU General Data Protection Regulation. The council and the European Parliament reached a long-awaited provisional agreement on the file 16 June.",
            "The proposed regulation aims to accelerate enforcement of cross-border cases, one of the most criticized aspects of the GDPR, by harmonizing some national procedural rules. The provisional agreement introduces binding deadlines for enforcement procedures and certain rights to both the complainant and the parties under investigation, such as the right to be heard during different stages of the procedure and the right of access to the case information. Without the final text, uncertainty remains surrounding resolution of some disputed topics, such as the European Data Protection Board's role in the dispute resolution mechanism.",
            "The European Commission tabled this proposal in the summer of 2023. As a previous European Parliament's \"unfinished business\" file, it was carried over to the new parliamentary term last summer. The new rules aiming to improve GDPR enforcement will enter into force after the official adoption of the text by both institutions, fine-tuning by lawyer-linguists and publication in the Official Journal of the European Union.",
            "Another development in the field of data protection: Receiving of Royal Assent last week, the Data (Use and Access) Act became law. This is an important moment in the evolution of the U.K.'s approach to data protection after Brexit, as the act introduces new data sharing rules, including on the access and use of health care information, consumer and traffic data, and rules on digital identity verification. According to the U.K. Government, the new legislation will \"unleash the power of data\" and make British people's \"day-to-day lives easier.\"",
            "It remains to be seen whether these changes in the U.K. data protection regime will affect the EU adequacy decisions allowing free flows of personal data between the EU and U.K., which are up for review by the Commission at the end of this year.",
            "Regarding the intersection between privacy and artificial intelligence, France's data protection authority, the Commission nationale de l'informatique et des libert\u00e9s, released new recommendations on development of AI systems. The advice focuses on the use of legitimate interest as a legal basis and includes an assessment that can be used to determine whether legitimate interest can be relied upon, specific cases in which it is allowed or not and examples of safeguards to be used, such as omitting the collection of certain data.",
            "With the next batch of the EU AI Act's implementation deadlines approaching in August, the Commission launched a public consultation to gather input on implementing the regulation's rules on high-risk AI systems. Until 18 July, stakeholders are invited to share practical examples of AI systems and identify issues they want to be addressed in future commission guidelines, including the classification of high-risk AI systems, high-risk requirements and obligations and responsibilities along the AI value chain.",
            "At the same time, the topic of possibly delaying the AI Act's implementation was widely discussed this month. Some believe that postponing the entry into application of certain AI Act rules would be appropriate, especially if relevant guidance and technical standards are not finalized. Head of Office and Digital Policy Adviser for MEP Axel Voss, European People's Party, in the European Parliament Kai Zenner and Resaro Chief Trust Officer Sebastian Hallensleben highlighted the risks of delaying the act's implementation and suggested certain next steps the Commission should take.",
            "At least some of the uncertainty is hoped to be clarified in the next digital simplification omnibus, but the question is if it will happen soon enough, as important implementation deadlines are just around the corner.\u00a0 \u00a0",
            "Laura Pliau\u0161kait\u0117 is European operations coordinator for the IAPP.",
            "This article originally appeared in the Europe Data Protection Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/notes-from-the-asia-pacific-region-chinese-regulators-strengthen-ai-data-protection-governance",
        "title": "Notes from the Asia-Pacific region: Chinese regulators strengthen AI, data protection governance",
        "location": "",
        "date_published": "26 June 2025",
        "keywords": "[{\"keyword\": \"enforcement\", \"score\": 0.4329}, {\"keyword\": \"compliance\", \"score\": 0.4059}, {\"keyword\": \"ai\", \"score\": 0.3356}, {\"keyword\": \"cybersecurity\", \"score\": 0.3179}, {\"keyword\": \"beijing\", \"score\": 0.3051}]",
        "description": "China has been in a heat wave since we stepped into June, and for companies falling short on artificial intelligence and data privacy compliance, the regulatory climate is just as intense. As temperatures rise, so does the pressure on organizations to meet increasingly stringent legal and regulatory standards.",
        "content": [
            "China has been in a heat wave since we stepped into June, and for companies falling short on artificial intelligence and data privacy compliance, the regulatory climate is just as intense. As temperatures rise, so does the pressure on organizations to meet increasingly stringent legal and regulatory standards.",
            "In recent weeks, China's key regulatory authorities \u2014 including the Cyberspace Administration of China, the Ministry of Industry and Information Technology, the Ministry of Public Security, the People's Bank of China, the State Administration for Market Regulation and their regional counterparts \u2014 have launched a series of enforcement campaigns. These efforts are focused on a range of digital concerns, including mobile apps, generative AI technologies, internet fraud, cyberbullying, facial recognition systems, biometric data processing and cybersecurity risks.",
            "In Shanghai, the CAC identified that several generative AI platforms failed to conduct mandatory security impact assessments. This oversight led to the generation of content involving pornography, violence, money laundering and violations of personal data rights. As a result, some companies were required to carry out comprehensive corrective actions and their AI services were suspended pending review.",
            "Regulators in Beijing have requested AI companies and service providers strengthen compliance across the entire AI life cycle \u2014 including the filing of large language models, training data evaluation, content monitoring, regulating application programming interfaces, accountability of AI in health care and finance fields, and protection of children's information. Nearly 100 noncompliant AI accounts were recently shut down. With China's AI labeling rules set to take effect in October, the CAC is urging service providers to implement proper labeling for AI-generated content, including text, images, audio and video.",
            "Beyond AI-specific measures, Beijing regulators are also intensifying their focus on consumer-facing sectors such as smart parking, online food delivery, hotel booking, education, entertainment ticketing, online medical platforms and even digital fuel stations. A recent random audit of 197 mobile apps \u2014 affecting more than 50,000 business operators \u2014 revealed various issues, including failure to disclose privacy policies, unauthorized collection of personal information, lack of adequate security measures, and improper API authorization processes. In response, the CAC plans to conduct routine inspections and has introduced a whistleblower hotline. A public blacklist of violators will also be published periodically.",
            "Similar enforcement actions are underway in other major cities and provinces, including Tianjin, Guangdong, Zhejiang and Jiangsu, reinforcing a coordinated national approach.",
            "These developments indicate a clear and consistent trajectory: China's regulators are significantly strengthening governance around AI and personal data protection. This trend is expected to continue. It is vital for businesses to stay informed of regulatory trends and take timely actions to align with compliance expectations.",
            "Barbara Li, CIPP/E, is a partner at Reed Smith.",
            "This article originally appeared in the Asia-Pacific Dashboard Digest, a free weekly IAPP newsletter. Subscriptions to this and other IAPP newsletters can be found here."
        ]
    },
    {
        "url": "https://iapp.org/news/a/rebuilding-digital-trust-how-blockchain-is-making-privacy-a-default",
        "title": "Rebuilding digital trust: How blockchain is making privacy a default",
        "location": "",
        "date_published": "26 June 2025",
        "keywords": "[{\"keyword\": \"privacy\", \"score\": 0.451}, {\"keyword\": \"iapp\", \"score\": 0.4427}, {\"keyword\": \"decentralized\", \"score\": 0.4151}, {\"keyword\": \"safeguarding\", \"score\": 0.3597}, {\"keyword\": \"platformsthat\", \"score\": 0.2728}]",
        "description": "Today's digital world is chaotic and safeguarding privacy within it is even more complicated.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. \r",
            "Today's digital world is chaotic and safeguarding privacy within it is even more complicated.",
            "Every click, search, and casual scroll through an app contributes to a system that collects and analyzes user data. People's habits, preferences, and interests are often mapped, studied and can be exploited.",
            "The issue lies in the very systems our society has built. Centralized platformsthat form the backbone of today's internet are vulnerable because few hands hold a high concentration of data; thissystem makes data breaches unavoidable. Privacy, which should be a basic right, has become something people have to advocate for \u2014 bit by bit. Large-scale breaches and compromises of sensitive data are signs of a deeper problem with how centralized systems handle data.",
            "Nonetheless, a significant shift is happening in organizations' approach to privacy and trust. There is less reliance on centralized institutions, and more trust is being placed in technology itself.",
            "Blockchain is at the core of this transformation.",
            "While Bitcoin or other cryptocurrencies may first come to mind for many, blockchain is much more than that application. It is a fundamental rethinking of how trust, control and privacy is managed online. It ensures security through mathematics, cryptography and distributed consensus, rather than depending on central authorities to protect information.",
            "Zero-knowledge proofs are one of the most powerful ways blockchain reforms privacy. The cryptographic method is used to prove knowledge about a piece of data without revealing the data itself. An individual, for example, could prove they are over 18 without revealing their actual birth date or that their income falls within a certain range without providing tax returns.",
            "Users can authenticate themselves or verify claims without exposing any underlying personal sensitive data using zero-knowledge proofs. Instead of having to share personal information to participate in the digital world, blockchain technology allows individuals to maintain control over their data.",
            "This technology could be a game-changer for privacy and user autonomy.",
            "Decentralized identifiers are another powerful way to give individuals full control over their digital identity. Today, most individuals can be identified online through email addresses, social media accounts and/or government-issued IDs. These forms of identification are all created and controlled by others and can be taken away, misused, breached or changed without consent.",
            "In contrast, decentralized identifiers let individuals create and manage their own secure digital ID without relying on companies or governments. Individuals could have their own ID and decide how, when and with whom this information is shared and for how long. It's like a personal passport for the internet.",
            "Decentralized identifiers and zero-knowledge proofs enable a new identity model where users control their data and only reveal what is necessary through selective disclosure. With selective disclosure, individuals have granular control over data and the power to choose exactly what relevant information to share.",
            "Because blockchain systems are transparent yet pseudonymous by default, they support these privacy enhancements without compromising accountability or security.",
            "Blockchain is also open to everyone. There are no gatekeepers and no necessary permissions. That might sound contrary to privacy, but blockchain builds privacy rights and trust into its design and into the system itself, unlike traditional systems where access is controlled.",
            "As Web3, a decentralized internet where users own their data, identities and digital assets, approaches privacy must be more than a feature. It must be the foundation. Web3 is not about rebuilding the same systems with polished interfaces, but a fundamental reconsideration of how digital interactions should work and give individuals autonomy and sovereignty over their digital selves.",
            "Blockchain is not a magical solution. Like any technology, it can be poorly built, used carelessly or simply misunderstood. New threat actors and attack vectors will find emerging technologies like blockchain. So, privacy must be thoughtfully designed from the ground up. Especially in blockchain, where recorded data is permanent and can't be erased, tough questions must be asked, like how to protect people's privacy while still keeping systems accountable and how toensure transparency doesn't come at the cost of personal freedom.",
            "These are real challenges. On the other hand, the opportunity for improvement is exciting: a future where individuals don't have to trade their privacy to participate in the digital world nor have to give up control for the sake of convenience. It won't be easy, but the opportunity to reshape how we interact online is too crucial to ignore.",
            "In this new paradigm, privacy is not an add-on but present by design and default as protocol. Blockchain offers a blueprint for a world where an individual's digital identity is a reflection of their autonomy and sovereignty.",
            "The battleground for privacy has expanded beyond activists and technologists \u2014 it's now a mainstream concern for all who interact with the digital world. Blockchain isn't just another tool in the fight for privacy, it is reshaping the very ground on which the battle is fought.",
            "Sayali Paseband is cybersecurity engineering advisor at Verisk Analytics."
        ]
    },
    {
        "url": "https://iapp.org/news/a/global-ai-law-and-policy-trends-update",
        "title": "Global AI law and policy trends update",
        "location": "",
        "date_published": "25 June 2025",
        "keywords": "[{\"keyword\": \"ai\", \"score\": 0.4606}, {\"keyword\": \"policymakers\", \"score\": 0.4057}, {\"keyword\": \"regulation\", \"score\": 0.3956}, {\"keyword\": \"governance\", \"score\": 0.3882}, {\"keyword\": \"innovation\", \"score\": 0.3115}]",
        "description": "The trend towards risk-based artificial intelligence legislation seems to have turned on its head. Instead of, or in addition to, focusing on managing risks to consumers, policymakers are trending to embrace AI as an economic engine of growth. This shift is evident in the EU, Japan and the U.S. where governments have reprioritized policies, proposed and rescinded legislation and increased AI-focused innovation funds.",
        "content": [
            "The trend towards risk-based artificial intelligence legislation seems to have turned on its head. Instead of, or in addition to, focusing on managing risks to consumers, policymakers are trending to embrace AI as an economic engine of growth. This shift is evident in the EU, Japan and the U.S. where governments have reprioritized policies, proposed and rescinded legislation and increased AI-focused innovation funds.",
            "The changing tides of policies globally, however, has a profound impact on how organizations consider their internal AI governance, especially for the higher risk AI systems. Consumer protection- and rights-focused approaches to policy, like those in some of the EU\u2019s applicable laws, may lead to more uniform governance measures. Co-regulatory approaches, such as those implemented in Singapore, arguably leave more room for organizations to decide how they can best govern AI use and AI systems.",
            "Various jurisdictions have or are contemplating national AI legislation. Brazil\u2019s senate has approved legislation that will now be deliberated in the lower chamber. South Korea passed and signed the AI Basic Act into law and will provide greater regulatory guidance in 2025. Both the South Korean and Brazilian laws will regulate AI based on risk, meaning that certain use cases will be banned and others will have stricter regulatory requirements, much like the EU AI Act. Read the IAPP's full analysis of the South Korean AI Basic Act and commentary around the future of AI legislation in Latin America.",
            "Japan recently passed the Act on the Promotion of Research and Development and the Utilization of AI-Related Technologies, which strikes a departure from previous iterations of wide-reaching AI legislation. Unlike previous bills, such as those in Colorado, the EU, or South Korea, it focuses more on spurring innovation through government support rather than consumer protections, marking a shift in global AI policy.",
            "The U.S. has also changed course with the new Republican administration and control of Congress. Overall, the new administration appears to be prioritizing innovation in its new AI policy. This shift can be seen in the name change of the AI Safety Institute to Center for AI Standards and Innovation as well as the new U.S. Office of Management and Budget memoranda that places a greater emphasis on innovation.",
            "A moratorium on the enforcement of state and local AI regulations has been debated as part of the One Big Beautiful Bill Act. One of the stated goals of the proposed moratorium is to increase innovation by simplifying the regulatory burden organizations are facing by only allowing enforcement of federal AI laws or, for example, technology-neutral consumer protection laws. The AI Diffusion Rule, which restricted the flow of the most powerful microchips under the Biden administration, has been scrapped in the name of boosting innovation. The government will instead include access to the same chips as part of their negotiated trade bills. Both examples indicate that U.S. policy is moving towards more relaxed regulations on AI use and development.",
            "Given the changing tides in AI policy in the U.S. and around the world, how are other countries responding? The Brussels Effect, or the influence the EU has outside of its borders through its internal policies, seems to have been challenged by growing geopolitical competition among aspiring leaders in AI development who desire to reap the economic rewards of succeeding in the AI development and deployment race. While there still is EU-inspired risk-based legislation popping up in U.S. states and South Korea, policies are shifting towards a greater emphasis on innovation and less on guardrails and consumer protection. Japan\u2019s new law is a good example of this shift.",
            "There have been instances of the EU itself forgoing legislation that might be harmful to AI developers, such as the AI Liability Directive, and focusing on finding ways to increase innovation in AI development in the bloc. The European Commission's AI Continent Action Plan is at the heart of their efforts to do so; it invests 200 billion euros in AI efforts, with 20 billion euros earmarked for AI gigafactories.",
            "The first wave of factories was designated in December 2024 and the second wave in March 2025. While the goal of this initiative is to strengthen their competitiveness, they also are providing organizations with services, such as the AI Act Service Desk, to help navigate the EU AI Act\u2019s requirements. Overall, it seems that Brussels is also shifting its policies to try to capture the economic benefits of AI, including by possibly delaying or watering down the AI Act.",
            "Behind the push to innovate is the expectation of economic gains. AI is broadly expected to boost global between USD7 trillion over 10 years up to USD25 trillion annually by some estimates. Japan sees AI as a path out of its economic slump, a goal reflected in its domestic actions like new light-touch regulations and exemptions that allow AI developers to use copyrighted material in their training datasets.",
            "The U.S. Congressional Budget Office recently released a report on AI and its potential effects on the economy and the federal budget. With only 5% of businesses and 9% of employees utilizing AI, the report shows the adoption by businesses remains limited. It highlights that AI's impact on the economy is generally positive.",
            "While a majority of employers have not seen AI as a factor for decreasing employment counts, almost all employees will see some level of automation in their work when AI is sufficiently integrated. AI will increase the productivity of workers and free up time for higher level tasks as it becomes more integrated. This effect will likely be felt over the next decade as the adoption figures rise.",
            "Even without factoring potential impacts to the economy through productivity gains or effects to the labor market, investors are already heavily funding AI and its supporting infrastructure, which will, by itself, make a huge mark on economic growth. To power further adoption and advancement in AI, more AI-powering chips will need to be produced, additional data centers built to house them and greater electric supply secured to power them.",
            "In 2023, it was predicted that AI investment could reach USD200 billion by 2025. In 2024, the U.S. saw more than USD109 billion invested in AI \u2013 with a wide gap in investment between the U.S. and the EU, which saw less than USD20 billion in AI investment overall. This disparity in investment might be driving the EU\u2019s fear of missing out on an economic growth engine and its rethinking of constraining AI development and deployment.",
            "Countries seem to be looking for ways to address AI's negative impacts while simultaneously trying not to discourage investment or development. Keeping an eye on the developments and trends is important because each country will have its own approach in an ever-changing environment. This tension between economic growth and individual rights or consumer protections is seen across the globe. A poll recently found that 77% of Americans \"want companies to create AI slowly and get it right the first time, even if that delays breakthroughs.\" For policymakers, the difficulty is to set up the conditions to ensure companies are making breakthroughs while insuring they get it right the first time.",
            "It is likely organizations will pursue AI governance, regardless of the official AI policies and threat of increasing regulation. Organizations will still need to internally align the use and development of AI with their stakeholders and pursue risk-minimizing strategies \u2014 all of which an effective AI governance program will do. Even more so, non-AI-specific laws will still apply to AI systems, such as those concerning non-discrimination, data privacy and rules around non-consensual sexual imagery; organizations would have to comply with these targeted areas of AI legislation.",
            "Despite the change of emphasis from AI risk in global AI policy in favor of innovation, AI governance inside organizations will likely see more relevance in the next few years.",
            "Richard Sentinella is the AI governance research fellow at the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/eu-model-contractual-clauses-for-ai-procurement-a-practical-guide",
        "title": "EU model contractual clauses for AI procurement: A practical guide",
        "location": "",
        "date_published": "25 June 2025",
        "keywords": "[{\"keyword\": \"procurement\", \"score\": 0.4235}, {\"keyword\": \"contractual\", \"score\": 0.42}, {\"keyword\": \"ai\", \"score\": 0.3512}, {\"keyword\": \"policies\", \"score\": 0.3158}, {\"keyword\": \"risks\", \"score\": 0.3099}]",
        "description": "In late March, the Public Buyers Community of the EU published model contractual clauses for the public procurement of artificial intelligence, which are rapidly becoming a reliable source of best practice standards for private-sector AI contracting. An initiative by the Directorate General of Growth of the European Commission, the Public Buyers Community aims to advance economic growth, competitiveness and business development, particularly among small and medium-sized businesses.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "In late March, the Public Buyers Community of the EU published model contractual clauses for the public procurement of artificial intelligence, which are rapidly becoming a reliable source of best practice standards for private-sector AI contracting. An initiative by the Directorate General of Growth of the European Commission, the Public Buyers Community aims to advance economic growth, competitiveness and business development, particularly among small and medium-sized businesses.",
            "As companies implement third-party risk policies as a part of their AI governance programs, these MCC-AI may influence procurement functions and guide customers' purchasing processes. The clauses largely follow the requirements for high-risk AI systems as defined under the EU AI Act.",
            "It is critical to make a conscious risk-based decision grounded on a set of best practices as AI capabilities evolve and become more impactful. The MCC-AI, published in light and high-risk versions along with helpful commentary, demonstrate two risk tiers of complete model contractual clauses and represent a library of clauses that are useful to address specific risks.",
            "The MCC-AI can be beneficial to private sector companies in accomplishing several goals, including aligning standards for best practices in AI contracting, creating a blueprint for risk management, ensuring international compliance, demonstrating supply-chain due diligence and mitigating litigation risk. Private sector companies and public sector organizations are not legally required to use the MCC-AI.",
            "A comprehensive approach should future-proof the procurement process to be able to adapt to new and changing AI system capabilities. Purchasers should think about how the MCC-AI specifically meet the needs of their AI use cases. Vendors should examine existing privacy, security, AI governance and compliance measures and/or standard terms to identify the measures they can and cannot honestly provide \u2014 as well as which provisions would be irrelevant to their services.",
            "The MCC-AI-High-Risk are intended for procuring AI systems defined as high-risk under the AI Act, those that \"may pose a high risk to the health and safety or fundamental rights of persons.\" The MCC-AI-Light are for those not classified as high-risk, but still requiring \"transparency obligation or requirements for explanation of individual decision-making by the public administration.\"",
            "Both sets of clauses address:",
            "Only the MCC-AI-High-Risk contain provisions that require a quality management system, including a strategy for regulatory compliance and accountability; a conformity assessment prior to delivery of the AI system; and an AI register for public transparency and comprehensive audit details.",
            "Certain provisions of MCC-AI-Light are enhanced in the MCC-AI-High Risk, including the option to continue risk management provisions after the contractual term, enhanced transparency to require disclosure of detailed performance metrics, the option to specify documentation language, and enhanced supplier and third-party data provisions with two-way indemnification structure.",
            "The purpose of a contract is to allocate and understand risks and costs between parties. The use case for an AI system is fundamental and must be understood. The MCC-AI, therefore, cannot be a one-size-fits-all solution. In many cases, even the light version may be overkill.",
            "For example, despite the intimidating breadth of the AI Act, most consumer-facing AI applications don't need MCC-AI at all because they would be low or minimal risk under the AI Act. These use cases include AI features of video games, spam filters, basic content recommendation algorithms and content generation tools \u2014 excluding deepfake creators \u2014 as well as broad categories of low-risk productivity and entertainment applications.",
            "If a system is generating content for a marketing department, the risk relates to the effects of what the system will help create. If the content generation is not using personal data and the worst-case scenario is essentially poor campaign quality, then most of these clauses would either be irrelevant or redundant to provisions usually found in standard terms for an online service. Such a use case is minimal risk.",
            "On the other hand, if the system gathers personal information and constructs behavioral profiles, serving content or on a schedule personalized to the target, then using the MCC-AI to address specific risks makes sense. For example, both the MCC-AI-Light and MCC-AI-High-Risk are designed to mitigate privacy risks and comply with the EU General Data Protection Regulation. That said, a well-constructed data protection addendum \u2014 as already offered by many software-as-a-service providers \u2014 would likely already meet the same requirements.",
            "There could be a non-high-risk scenario that nevertheless poses serious AI risks to a business, such as a system intended to predict important business outcomes \u2014 like logistics or demand and/or inventory predictions. In such a scenario, the key risks would center around the accuracy and usefulness of the AI system.",
            "Therefore, much of the MCC-AI-Light\u2014 such as cybersecurity and data governance, integrity and accuracy \u2014 would be helpful from the buyer's perspective. Even some of the MCC-AI-High-Risk might be a good idea, such as pre-delivery conformity assessment.",
            "For vendors, these requirements don't necessarily mean the contract has to look like these MCC-AI. For example, cybersecurity requirements can be met with existing security terms and agreeing to maintain ISO 9001 certification can demonstrate a sufficient quality management system.",
            "Alex Wall, AIGP, CIPP/E, CIPP/US, CIPM, FIP, is principal attorney at Wall Law."
        ]
    }
]