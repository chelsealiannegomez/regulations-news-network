[
    {
        "url": "https://iapp.org/news/a/global-ai-law-and-policy-trends-update",
        "title": "Global AI law and policy trends update",
        "location": "",
        "date_published": "25 June 2025",
        "keywords": [
            "AI Governance",
            "Law & Regulation"
        ],
        "description": "The trend towards risk-based artificial intelligence legislation seems to have turned on its head. Instead of, or in addition to, focusing on managing risks to consumers, policymakers are trending to embrace AI as an economic engine of growth. This shift is evident in the EU, Japan and the U.S. where governments have reprioritized policies, proposed and rescinded legislation and increased AI-focused innovation funds.",
        "content": [
            "The trend towards risk-based artificial intelligence legislation seems to have turned on its head. Instead of, or in addition to, focusing on managing risks to consumers, policymakers are trending to embrace AI as an economic engine of growth. This shift is evident in the EU, Japan and the U.S. where governments have reprioritized policies, proposed and rescinded legislation and increased AI-focused innovation funds.",
            "The changing tides of policies globally, however, has a profound impact on how organizations consider their internal AI governance, especially for the higher risk AI systems. Consumer protection- and rights-focused approaches to policy, like those in some of the EU\u2019s applicable laws, may lead to more uniform governance measures. Co-regulatory approaches, such as those implemented in Singapore, arguably leave more room for organizations to decide how they can best govern AI use and AI systems.",
            "Various jurisdictions have or are contemplating national AI legislation. Brazil\u2019s senate has approved legislation that will now be deliberated in the lower chamber. South Korea passed and signed the AI Basic Act into law and will provide greater regulatory guidance in 2025. Both the South Korean and Brazilian laws will regulate AI based on risk, meaning that certain use cases will be banned and others will have stricter regulatory requirements, much like the EU AI Act. Read the IAPP's full analysis of the South Korean AI Basic Act and commentary around the future of AI legislation in Latin America.",
            "Japan recently passed the Act on the Promotion of Research and Development and the Utilization of AI-Related Technologies, which strikes a departure from previous iterations of wide-reaching AI legislation. Unlike previous bills, such as those in Colorado, the EU, or South Korea, it focuses more on spurring innovation through government support rather than consumer protections, marking a shift in global AI policy.",
            "The U.S. has also changed course with the new Republican administration and control of Congress. Overall, the new administration appears to be prioritizing innovation in its new AI policy. This shift can be seen in the name change of the AI Safety Institute to Center for AI Standards and Innovation as well as the new U.S. Office of Management and Budget memoranda that places a greater emphasis on innovation.",
            "A moratorium on the enforcement of state and local AI regulations has been debated as part of the One Big Beautiful Bill Act. One of the stated goals of the proposed moratorium is to increase innovation by simplifying the regulatory burden organizations are facing by only allowing enforcement of federal AI laws or, for example, technology-neutral consumer protection laws. The AI Diffusion Rule, which restricted the flow of the most powerful microchips under the Biden administration, has been scrapped in the name of boosting innovation. The government will instead include access to the same chips as part of their negotiated trade bills. Both examples indicate that U.S. policy is moving towards more relaxed regulations on AI use and development.",
            "Given the changing tides in AI policy in the U.S. and around the world, how are other countries responding? The Brussels Effect, or the influence the EU has outside of its borders through its internal policies, seems to have been challenged by growing geopolitical competition among aspiring leaders in AI development who desire to reap the economic rewards of succeeding in the AI development and deployment race. While there still is EU-inspired risk-based legislation popping up in U.S. states and South Korea, policies are shifting towards a greater emphasis on innovation and less on guardrails and consumer protection. Japan\u2019s new law is a good example of this shift.",
            "There have been instances of the EU itself forgoing legislation that might be harmful to AI developers, such as the AI Liability Directive, and focusing on finding ways to increase innovation in AI development in the bloc. The European Commission's AI Continent Action Plan is at the heart of their efforts to do so; it invests 200 billion euros in AI efforts, with 20 billion euros earmarked for AI gigafactories.",
            "The first wave of factories was designated in December 2024 and the second wave in March 2025. While the goal of this initiative is to strengthen their competitiveness, they also are providing organizations with services, such as the AI Act Service Desk, to help navigate the EU AI Act\u2019s requirements. Overall, it seems that Brussels is also shifting its policies to try to capture the economic benefits of AI, including by possibly delaying or watering down the AI Act.",
            "Behind the push to innovate is the expectation of economic gains. AI is broadly expected to boost global between USD7 trillion over 10 years up to USD25 trillion annually by some estimates. Japan sees AI as a path out of its economic slump, a goal reflected in its domestic actions like new light-touch regulations and exemptions that allow AI developers to use copyrighted material in their training datasets.",
            "The U.S. Congressional Budget Office recently released a report on AI and its potential effects on the economy and the federal budget. With only 5% of businesses and 9% of employees utilizing AI, the report shows the adoption by businesses remains limited. It highlights that AI's impact on the economy is generally positive.",
            "While a majority of employers have not seen AI as a factor for decreasing employment counts, almost all employees will see some level of automation in their work when AI is sufficiently integrated. AI will increase the productivity of workers and free up time for higher level tasks as it becomes more integrated. This effect will likely be felt over the next decade as the adoption figures rise.",
            "Even without factoring potential impacts to the economy through productivity gains or effects to the labor market, investors are already heavily funding AI and its supporting infrastructure, which will, by itself, make a huge mark on economic growth. To power further adoption and advancement in AI, more AI-powering chips will need to be produced, additional data centers built to house them and greater electric supply secured to power them.",
            "In 2023, it was predicted that AI investment could reach USD200 billion by 2025. In 2024, the U.S. saw more than USD109 billion invested in AI \u2013 with a wide gap in investment between the U.S. and the EU, which saw less than USD20 billion in AI investment overall. This disparity in investment might be driving the EU\u2019s fear of missing out on an economic growth engine and its rethinking of constraining AI development and deployment.",
            "Countries seem to be looking for ways to address AI's negative impacts while simultaneously trying not to discourage investment or development. Keeping an eye on the developments and trends is important because each country will have its own approach in an ever-changing environment. This tension between economic growth and individual rights or consumer protections is seen across the globe. A poll recently found that 77% of Americans \"want companies to create AI slowly and get it right the first time, even if that delays breakthroughs.\" For policymakers, the difficulty is to set up the conditions to ensure companies are making breakthroughs while insuring they get it right the first time.",
            "It is likely organizations will pursue AI governance, regardless of the official AI policies and threat of increasing regulation. Organizations will still need to internally align the use and development of AI with their stakeholders and pursue risk-minimizing strategies \u2014 all of which an effective AI governance program will do. Even more so, non-AI-specific laws will still apply to AI systems, such as those concerning non-discrimination, data privacy and rules around non-consensual sexual imagery; organizations would have to comply with these targeted areas of AI legislation.",
            "Despite the change of emphasis from AI risk in global AI policy in favor of innovation, AI governance inside organizations will likely see more relevance in the next few years.",
            "Richard Sentinella is the AI governance research fellow at the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/eu-model-contractual-clauses-for-ai-procurement-a-practical-guide",
        "title": "EU model contractual clauses for AI procurement: A practical guide",
        "location": "",
        "date_published": "25 June 2025",
        "keywords": [
            "AI Governance",
            "Frameworks & Standards",
            "Law & Regulation",
            "Risk Management"
        ],
        "description": "In late March, the Public Buyers Community of the EU published model contractual clauses for the public procurement of artificial intelligence, which are rapidly becoming a reliable source of best practice standards for private-sector AI contracting. An initiative by the Directorate General of Growth of the European Commission, the Public Buyers Community aims to advance economic growth, competitiveness and business development, particularly among small and medium-sized businesses.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "In late March, the Public Buyers Community of the EU published model contractual clauses for the public procurement of artificial intelligence, which are rapidly becoming a reliable source of best practice standards for private-sector AI contracting. An initiative by the Directorate General of Growth of the European Commission, the Public Buyers Community aims to advance economic growth, competitiveness and business development, particularly among small and medium-sized businesses.",
            "As companies implement third-party risk policies as a part of their AI governance programs, these MCC-AI may influence procurement functions and guide customers' purchasing processes. The clauses largely follow the requirements for high-risk AI systems as defined under the EU AI Act.",
            "It is critical to make a conscious risk-based decision grounded on a set of best practices as AI capabilities evolve and become more impactful. The MCC-AI, published in light and high-risk versions along with helpful commentary, demonstrate two risk tiers of complete model contractual clauses and represent a library of clauses that are useful to address specific risks.",
            "The MCC-AI can be beneficial to private sector companies in accomplishing several goals, including aligning standards for best practices in AI contracting, creating a blueprint for risk management, ensuring international compliance, demonstrating supply-chain due diligence and mitigating litigation risk. Private sector companies and public sector organizations are not legally required to use the MCC-AI.",
            "A comprehensive approach should future-proof the procurement process to be able to adapt to new and changing AI system capabilities. Purchasers should think about how the MCC-AI specifically meet the needs of their AI use cases. Vendors should examine existing privacy, security, AI governance and compliance measures and/or standard terms to identify the measures they can and cannot honestly provide \u2014 as well as which provisions would be irrelevant to their services.",
            "The MCC-AI-High-Risk are intended for procuring AI systems defined as high-risk under the AI Act, those that \"may pose a high risk to the health and safety or fundamental rights of persons.\" The MCC-AI-Light are for those not classified as high-risk, but still requiring \"transparency obligation or requirements for explanation of individual decision-making by the public administration.\"",
            "Both sets of clauses address:",
            "Only the MCC-AI-High-Risk contain provisions that require a quality management system, including a strategy for regulatory compliance and accountability; a conformity assessment prior to delivery of the AI system; and an AI register for public transparency and comprehensive audit details.",
            "Certain provisions of MCC-AI-Light are enhanced in the MCC-AI-High Risk, including the option to continue risk management provisions after the contractual term, enhanced transparency to require disclosure of detailed performance metrics, the option to specify documentation language, and enhanced supplier and third-party data provisions with two-way indemnification structure.",
            "The purpose of a contract is to allocate and understand risks and costs between parties. The use case for an AI system is fundamental and must be understood. The MCC-AI, therefore, cannot be a one-size-fits-all solution. In many cases, even the light version may be overkill.",
            "For example, despite the intimidating breadth of the AI Act, most consumer-facing AI applications don't need MCC-AI at all because they would be low or minimal risk under the AI Act. These use cases include AI features of video games, spam filters, basic content recommendation algorithms and content generation tools \u2014 excluding deepfake creators \u2014 as well as broad categories of low-risk productivity and entertainment applications.",
            "If a system is generating content for a marketing department, the risk relates to the effects of what the system will help create. If the content generation is not using personal data and the worst-case scenario is essentially poor campaign quality, then most of these clauses would either be irrelevant or redundant to provisions usually found in standard terms for an online service. Such a use case is minimal risk.",
            "On the other hand, if the system gathers personal information and constructs behavioral profiles, serving content or on a schedule personalized to the target, then using the MCC-AI to address specific risks makes sense. For example, both the MCC-AI-Light and MCC-AI-High-Risk are designed to mitigate privacy risks and comply with the EU General Data Protection Regulation. That said, a well-constructed data protection addendum \u2014 as already offered by many software-as-a-service providers \u2014 would likely already meet the same requirements.",
            "There could be a non-high-risk scenario that nevertheless poses serious AI risks to a business, such as a system intended to predict important business outcomes \u2014 like logistics or demand and/or inventory predictions. In such a scenario, the key risks would center around the accuracy and usefulness of the AI system.",
            "Therefore, much of the MCC-AI-Light\u2014 such as cybersecurity and data governance, integrity and accuracy \u2014 would be helpful from the buyer's perspective. Even some of the MCC-AI-High-Risk might be a good idea, such as pre-delivery conformity assessment.",
            "For vendors, these requirements don't necessarily mean the contract has to look like these MCC-AI. For example, cybersecurity requirements can be met with existing security terms and agreeing to maintain ISO 9001 certification can demonstrate a sufficient quality management system.",
            "Alex Wall, AIGP, CIPP/E, CIPP/US, CIPM, FIP, is principal attorney at Wall Law."
        ]
    },
    {
        "url": "https://iapp.org/news/a/what-brazil-s-anpd-expects-from-companies-using-generative-ai",
        "title": "What Brazil's ANPD expects from companies using generative AI",
        "location": "South America",
        "date_published": "25 June 2025",
        "keywords": [
            "AI Governance",
            "Law & Regulation",
            "Regulatory Guidance"
        ],
        "description": "With Brazil's artificial intelligence bill still under discussion in Congress, its data protection authority, the Autoridade Nacional de Prote\u00e7\u00e3o de Dados, has taken a proactive step by releasing Technology Radar No. 3.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. \r",
            "With Brazil's artificial intelligence bill still under discussion in Congress, its data protection authority, the Autoridade Nacional de Prote\u00e7\u00e3o de Dados, has taken a proactive step by releasing Technology Radar No. 3.",
            "Issued in late 2024, the publication outlines the DPA's perspective on generative AI and its alignment with the country's General Data Protection Law. While not legally binding, the document provides important guidance organizations should not overlook.",
            "Generative AI models, such as large language models, rely on large volumes of data for training, fine-tuning and use. The ANPD sees the data life cycle of these models as closely connected to the processing of personal data. This includes collecting, processing, sharing and deleting data. Each step involves specific privacy risks that must be managed in line with LGPD requirements.",
            "In the data collection phase, the ANPD highlights the widespread use of web scraping tools that gather content from across the internet \u2014 often without checking whether that content includes personal or sensitive data. These datasets are often used without proper filtering or anonymization. The ANPD reminds organizations that even publicly available information is still subject to LGPD principles, especially when it comes to necessity, transparency and good faith.",
            "During the processing stage, although training models usually hide raw data behind mathematical structures, there is still a risk of revealing personal data through techniques like model inversion or membership inference attacks. Moreover, AI models can generate synthetic content that looks very real, and in some cases, may affect individuals' reputation, privacy or rights.",
            "Data sharing further complicates things. People might enter personal data into prompts or upload documents with sensitive content. The AI's responses may also include details that resemble personal information. And when companies reuse or share pre-trained models, they might unknowingly carry forward risks hidden in the original dataset. These situations call for strong internal governance and clear agreements between developers, providers and users.",
            "When it comes to deleting data, the ANPD points out generative AI doesn't follow a simple beginning-and-end life cycle. Once data enters a system \u2014 through training, prompts or uploads \u2014 it might be reused later during model updates or refinements. Organizations need to rethink when data use should end, how long is reasonable to store data and whether user consent still applies as the system evolves.",
            "The ANPD links these risks to key LGPD principles, like purpose limitation, necessity, transparency and accountability. The DPA recommends companies adopt technical and organizational safeguards and keep documentation \u2014 including data protection impact assessments \u2014 to show they are responsibly handling personal data.",
            "Even without specific AI legislation, the ANPD's document helps fill in the gaps by showing how Brazil's current data protection rules apply to emerging technologies. For companies doing business in Brazil or handling residents' data, this is more than a policy note \u2014 it's a practical roadmap.",
            "Technology Radar No. 3 isn't a list of rules, but it reflects the thoughts of  Brazil's privacy regulator. This is a valuable early guide for compliance and a strongindicator of what may come next for companies using generative AI.",
            "In short, generative AI should be built with considerations to privacy and data protection from the start. According to the ANPD, innovation and regulation go hand in hand. In Brazil, doing both \u2014 responsibly and transparently \u2014 is already the expectation.",
            "Tiago Neves Furtado, CIPP/E, CIPM, CDPO/BR, FIP, leads the Data Protection and Artificial Intelligence Team and the Incident Response Team at Opice Blum Advogados."
        ]
    },
    {
        "url": "https://iapp.org/news/a/cross-border-data-transfers-in-fintech-navigating-post-gdpr-regulations",
        "title": "Cross-border data transfers in fintech: Navigating post-GDPR regulations",
        "location": "Europe, North America",
        "date_published": "25 June 2025",
        "keywords": [
            "Finance & Banking",
            "International Data Transfers",
            "Law & Regulation",
            "Frameworks & Standards"
        ],
        "description": "In the financial technology sector, cross-border data flows are fundamental to operations. From instant payment platforms to artificial intelligence-powered lending tools, personal and financial data must flow seamlessly across borders for fintechs to remain competitive.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. ",
            "In the financial technology sector, cross-border data flows are fundamental to operations. From instant payment platforms to artificial intelligence-powered lending tools, personal and financial data must flow seamlessly across borders for fintechs to remain competitive.",
            "However, strict regulatory scrutiny \u2014 particularly with the enforcement of the EU General Data Protection Regulation and the landmark Schrems II ruling \u2014 has introduced significant compliance risks for companies managing international data transfers.",
            "The GDPR imposes stringent conditions on the transfer of personal data outside the European Economic Area. These transfers are only lawful when the destination ensures an \"essentially equivalent\" level of protection to that provided within the EU.",
            "To achieve this level of protection, the GDPR provides several mechanisms, including adequacy decisions, where the European Commission recognizes that a third country offers sufficient protection, and standard contractual clauses or binding corporate rules, which establish enforceable safeguards through legal agreements.",
            "To determine whether these measures are effective, organizations must conduct a transfer impact assessment, which involves evaluating the legal and practical landscape of the recipient country, including laws on government surveillance and enforcement mechanisms, to determine whether supplementary safeguards are needed.",
            "While the adoption of the EU-U.S. Data Privacy Framework has re-established a formal adequacy pathway for transfers to certified U.S. entities, uncertainty remains. Indeed, recent structural changes to the U.S. Privacy and Civil Liberties Oversight Board and the Federal Trade Commission have raised legitimate concerns about the framework's durability.",
            "For fintech companies, this situation presents unique complications. These companies often operate on cloud-based, decentralized infrastructures, handling vast amounts of personal and financial data that needs to move fluidly across borders to maintain operational agility.",
            "Unlike traditional financial institutions, the architecture of fintech companies is modular; their services are real-time; and their third-party dependencies are extensive. Application programming interfaces link customer data to analytics engines, fraud detection tools, payment gateways and customer support platforms. Many of these are hosted or managed outside the EU, which results in a network of data flows that is not always fully visible to the business itself, let alone data subjects.",
            "Mapping these data flows is one of the most fundamental, yet most difficult, steps toward compliance. Without a clear view of where data is going, it is nearly impossible to choose the right transfer mechanism or apply appropriate safeguards.",
            "However, for startups and scale-ups, this task is often inhibited by limited compliance expertise and resource constraints. What complicates matters further is the divergence in global privacy frameworks. Fintechs with international user bases frequently find themselves navigating conflicting obligations, such as EU data export requirements, Asian data localization laws or U.S. cloud access mandates\u2014 all while trying to maintain a seamless user experience.",
            "In this context, it is critical to choose the right data transfer mechanism. SCCs remain the most widely adopted solution due to their flexibility and accessibility. The 2021 revisions to the SCCs introduced modularity, allowing them to better reflect real-world transfer scenarios, including processor-to-processor and processor-to-controller arrangements.",
            "However, SCCs are not ready to use as-is for fintechs, since they must evaluate whether the legal environment in the recipient country permits effective enforcement of these clauses. For this, they must be accompanied by TIAs and, in many cases, supplemented with additional safeguards.",
            "For larger organizations with multiple entities around the world, BCRs can provide a more sustainable and robust solution. They provide a unified framework for intra-group transfers but require approval from EU data protection authorities, making them resource-intensive to implement and maintain.",
            "When available, adequacy decisions are the easiest solution since they reduce the need for additional safeguards. However, only a limited number of countries currently wholly or partially benefit from these decisions and their future may be uncertain. New models such as industry codes of conduct and certification schemes may offer alternative routes to compliance in the future, but these remain in early development stages.",
            "Beyond the choice of mechanism, effective compliance depends on building a privacy-resilient infrastructure from the ground up. The cornerstone of GDPR compliance for international transfers lies in conducting comprehensive TIAs that are not only rigorous but also operationally grounded.",
            "These assessments must look beyond the formal legal environment to examine practical realities, including the likelihood of government access to data, the technical capabilities of local providers, and the enforceability of rights.",
            "Due diligence also involves vetting third-party vendors and subprocessors. This includes reviewing their data protection practices, contractual safeguards and incident response capabilities, ideally as part of a broader third-party risk management strategy.",
            "Technical safeguards play a key role in mitigating residual risks. Strong encryption at rest and in transit, pseudonymization and strict access controls can significantly reduce the risks associated with international data transfers. When effectively implemented, under the European Data Protection Board's guidance, these controls can mitigate risks that SCCs or BCRs alone cannot fully address.",
            "Transparency with users is equally important. Individuals want to know where their data goes, who has access to it and what their rights are. Fintechs should offer clear, accessible privacy notices and, where consent is used as a legal basis, ensure it is informed, specific and freely given. Tools that allow users to manage preferences or view where their data is stored can also help reinforce trust.",
            "As the fintech ecosystem continues to evolve, so too does the regulatory and technological landscapes surrounding cross-border data transfers. Staying ahead of these changes is not only a compliance necessity, but also a strategic advantage.",
            "Looking ahead, the landscape for international data transfers is likely to become more complex, as regulatory fragmentation continues to increase. While the GDPR has become a global benchmark, it is not the only privacy regulation. Jurisdictions around the world, from Brazil to India to Kenya, are enacting their own data protection laws \u2014 each with different rules on cross-border transfers and user rights.",
            "For fintechs operating internationally, this diversity in legal frameworks demands greater agility in governance and potentially localized compliance strategies.",
            "The EU itself is not standing still. The long-term viability of the EU-U.S. DPF is currently being tested and further refinements to SCCs and sector-specific codes of conduct are under discussion.",
            "However, technologies may offer privacy-enhancing solutions for cross-border compliance. Advances in confidential computing, secure multi-party computation, and federated learning allow data to be analyzed across jurisdictions without the actual transfer of data.",
            "Moreover, automated consent and preference management tools, risk assessment platforms, and compliance-as-a service models are gaining traction, particularly among resource-limited fintechs seeking scalable solutions. Forward-looking organizations will invest in both regulatory foresight and tech-driven privacy engineering, to ensure they are prepared for what is next.",
            "Cross-border data transfers are essential to fintech growth and innovation, but they pose significant regulatory and operational challenges.",
            "GDPR-compliant mechanisms, such as SCCs, BCRs or adequacy decisions, must be embedded within a broader strategy of governance with technical safeguards and clear user communication.",
            "Success depends on adopting a proactive mindset to anticipate changes, leverage technology and treat privacy not as a constraint, but as a cornerstone of trust and resilience.",
            "Paul Krasy is data protection officer for the Mentor Group. "
        ]
    },
    {
        "url": "https://iapp.org/news/a/from-compliance-cost-to-competitive-edge-how-privacy-leaders-can-command-the-executive-table",
        "title": "From compliance cost to competitive edge: How privacy leaders can command the executive table",
        "location": "",
        "date_published": "25 June 2025",
        "keywords": [
            "AI Governance",
            "Data Ethics",
            "Data Security",
            "Risk Management"
        ],
        "description": "Amid accelerating innovation, particularly in generative artificial intelligence and data-driven technologies, privacy leaders are being called to the executive table more often \u2014 but their voices aren't always fully heard.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. \r",
            "Amid accelerating innovation, particularly in generative artificial intelligence and data-driven technologies, privacy leaders are being called to the executive table more often \u2014 but their voices aren't always fully heard.",
            "The latest IAPP Privacy Governance Report shows more than 80% of privacy professionals now manage responsibilities far beyond traditional data protection, including AI governance, data ethics, cybersecurity and platform liability initiatives. Despite this expanded scope, privacy is still too often framed as a compliance cost rather than a strategic enabler.",
            "As technology continues to outpace regulation and nearly half of organizations identify AI governance as a top business priority, privacy has become the integrating force across emerging risks, placing leaders at the center of complex, high-stakes decisions that shape market trust and business growth.",
            "This is the moment to redefine the conversation and show how privacy drives responsible innovation, operational resilience and long-term value. And it starts by communicating evolving risks in business terms that command executive attention and reposition privacy as a critical investment in competitive advantage.",
            "In fast-moving sectors, speed is everything. Yet privacy is often perceived as a barrier to innovation, a function that slows down development in the name of compliance. This perception is both outdated and counterproductive.",
            "Leading technology companies demonstrate that when privacy is embedded early, it accelerates product development rather than becoming a last-minute hurdle. Engaging privacy teams during the design phase helps surface potential risks before significant resources have been spent, reducing costly rework and ensuring products enter the market with trust and confidence already built in.",
            "Standardized privacy frameworks, internal documentation and predictable review processes help organizations maintain their speed-to-market advantage. When engineering and product teams understand privacy expectations from the outset, they can design accordingly, reducing delays and eliminating last-minute surprises.",
            "The real unlock happens when privacy shifts from being perceived as a set of roadblocks to a source of clarity and confidence for innovative teams.",
            "For privacy leaders to command influence, they must speak the language of business strategy. Executives care about growth, market differentiation and customer loyalty \u2014 privacy must be positioned as a contributor to these very outcomes.",
            "Rather than focusing solely on regulatory risks, successful privacy leaders demonstrate how their work directly supports strategic priorities, accelerating digital transformation, reducing regulatory friction and strengthening customer trust.",
            "Influence grows from sustained collaboration, not isolated interventions. The most effective privacy programs foster deep, ongoing partnerships across product, engineering, marketing and sales teams. Privacy leaders who actively participate in shaping product strategies naturally position themselves as strategic partners, not compliance gatekeepers.",
            "Privacy risks often surface too late: when data protection agreements are finalized or products are ready to launch. By then, business flexibility is already compromised, leaving leaders to navigate rigid contractual terms or scramble to retrofit compliance.",
            "The most forward-looking organizations understand privacy creates the greatest value when embedded early in decision-making.",
            "In high-stakes industries like technology and financial services, this isn't just best practice, it's a competitive necessity. Privacy teams that work directly with commercial stakeholders before contracts are signed help preserve long-term market access and operational agility.",
            "Framing privacy terms as growth enablers, protecting against hidden costs of regulatory shifts and market barriers, makes privacy immediately relevant to leadership's bottom line.",
            "This approach helps organizations avoid the trap of short-term thinking. Companies that negotiate with evolving regulations and future market opportunities in mind position themselves to pivot quickly, rather than lose critical time and momentum when the landscape changes.",
            "One of the greatest challenges privacy leaders face is that a well-run program often makes its success invisible. No fines. No breaches. No headlines. And while that's the goal, it makes privacy's value less visible to leadership.",
            "The IAPP Privacy Governance Report reinforces this challenge \u2014 while privacy programs expand in scope, success metrics often lag behind. This makes it even more critical for privacy leaders to translate their work into measurable outcomes that resonate with executive decision-makers.",
            "Real-world examples of competitors facing regulatory penalties or reputational damage serve as powerful reminders of the risks avoided through proactive privacy programs. Operational metrics \u2014 such as faster vendor approvals, reduced negotiation times and lower incident response costs \u2014 help quantify how privacy drives efficiency and enables business agility.",
            "Above all, privacy must be positioned as a strategic investment that supports and grows revenue. Companies that integrate privacy into their brand narrative create meaningful market differentiators and earn lasting customer loyalty in a privacy-conscious world.",
            "Privacy by design must move from principle to practice, becoming a core operational standard that supports product innovation and business growth from day one.",
            "Organizations that excel in this area integrate privacy checkpoints directly into agile development cycles, treating privacy as a standard success metric alongside functionality and user experience. Cross-functional privacy champions identify potential issues early and ensure product teams have the tools and guidance needed to navigate them effectively.",
            "Automation also plays an increasingly critical role. Scalable privacy tools for data mapping, risk assessment and continuous monitoring allow organizations to stay ahead of compliance requirements without slowing innovation.",
            "Technology will always outpace regulation. Waiting for new laws to define what's permissible keeps organizations on the defensive. Instead, privacy leaders must act as strategic forecasters, anticipating emerging risks and preparing their organizations to navigate change before it arrives.",
            "Staying ahead requires continuous investment in technical literacy and global regulatory awareness. It also demands close collaboration across legal, compliance, product, and engineering teams to create resilient, future-proof privacy strategies.",
            "Above all, privacy leaders must position early action as a competitive advantage. Organizations that anticipate privacy risks before the market does are better positioned to lead in new industries, navigate regulatory uncertainty with confidence and build trust long before competitors.",
            "In a world where consumer trust is a defining currency of business success, privacy leadership is no longer just about compliance \u2014 it is a driver of growth, resilience and long-term value.",
            "The organizations that embrace this reality, and empower their privacy leaders accordingly, won't just survive the next wave of technological disruption. They'll define it and set new standards for how responsible innovation and trusted customer relationships shape the future of business.",
            "Basia Walczak is privacy and product counsel at Trulioo; Hussein Abdulghani, CIPP/E, CIPT, FIP, is a manager at Boston Consulting Group; Benjamin Kaplan, CIPP/E, CIPM, CIPT, FIP, is a privacy engineer at a leading technology company; and Melanie Selvadurai, CIPP/C, is privacy program manager at TikTok."
        ]
    },
    {
        "url": "https://iapp.org/news/a/don-t-abandon-our-values-why-the-eu-must-stay-the-course-on-ai-regulation",
        "title": "Don't abandon our values: Why the EU must stay the course on AI regulation",
        "location": "Europe",
        "date_published": "24 June 2025",
        "keywords": [
            "AI Governance",
            "Law & Regulation"
        ],
        "description": "The European Commission is reportedly considering a pause to the entry into application of the Artificial Intelligence Act, citing challenges around technical standards, industry backlash and geopolitical tensions \u2014 including direct requests from the U.S. government. At first glance, this looks like prudent regulatory realism. But a deeper look suggests something else: a loss of nerve at the very moment Europe needs genuine leadership. The EU should address implementation challenges head-on \u2014 not by deferring ambition, but by doubling down on its digital strategy.",
        "content": [
            "The European Commission is reportedly considering a pause to the entry into application of the Artificial Intelligence Act, citing challenges around technical standards, industry backlash and geopolitical tensions \u2014 including direct requests from the U.S. government. At first glance, this looks like prudent regulatory realism. But a deeper look suggests something else: a loss of nerve at the very moment Europe needs genuine leadership. The EU should address implementation challenges head-on \u2014 not by deferring ambition, but by doubling down on its digital strategy.",
            "The AI Act is no ordinary piece of legislation. EU policymakers as well as international observers have celebrated the act as the flagship of the EU's claim to global leadership in shaping rules for emerging technologies. From the 2020 white paper \"On Artificial Intelligence - A European approach to excellence and trust\" onward, its purpose was not just to ensure safety, but to define a European path toward trustworthy, human-centric innovation in AI. A significant delay or full-scale modification of the law, even if framed as technical, would send the opposite message \u2014 that the EU no longer has confidence in its own ambitions.",
            "Yes, the AI Act's implementation is difficult. Member states are racing to staff national authorities. The AI Office is still being set up. Harmonized standards still need a lot of work. The Code of Practice for General Purpose Artificial Intelligence models remain mired in legal and political complexity, not least due to trans-Atlantic tensions. But none of these challenges justify throwing all of our AI plans into disarray.",
            "In a recently published policy paper, the \"European Way. A blueprint for reclaiming our digital future,\" our co-authors and us advocated for an EU that moves beyond fragmented policies or erratic actions and instead pursues a coherent values-based digital strategy across the entire technology stack \u2014 from e-commerce over data spaces to chips and quantum. The AI Act is one important element of this overall vision. Weakening or significantly delaying it now without a compelling rationale would not only prolong legal uncertainty for our European AI firms, but hollow out one of the EU's most ambitious regulatory projects.",
            "Let us be clear: simplification, clarification and even some recalibration of the AI Act are necessary. Giving the AI ecosystem a few more months to prepare for the application of the new, high-risk obligations might even be imperative. But that's not the same as deregulation. It would be a major strategic error to conflate the need for a sound preparation with a justification for the long-term suspension of the AI Act's enforcement. If anything, it would confirm what many critics have long warned: the EU is strong in drafting legislation but weak in its implementation and enforcement.",
            "Moreover, submitting to geopolitical pressure would be a self-inflicted wound. Washington has reportedly asked Brussels to stop the law's enforcement. The EU should not subordinate its regulatory autonomy to a negotiating chip in trade talks. While the EU must always remain strongly committed to the trans-Atlantic partnership, it must also defend its foundational values. After all, it is precisely the EU's insistence on fundamental rights, risk classification, accountability and transparency that distinguishes its AI approach from laissez-faire or state-driven models.",
            "The real lesson from this whole debate is not so much that the EU has overregulated the tech sector, but that it underestimated what an effective policy strategy really entails. The \"European Way\" policy paper fills this vacuum by developing a strong overall digital vision, complemented by a coherent policy roadmap. What does it have in store for the AI Act? Instead of retreating from the law, the Commission should use this moment to take three bold steps:",
            "First, it should consolidate the scattered efforts to support small and medium-sized enterprises. SMEs need support that is both authoritative and useful, not just an extensive patchwork of guides, some with questionable correctness, published by numerous public institutions, initiatives and private companies. The Commission could launch a comprehensive easy compliance package for SMEs, bundling legal guidance, flowcharts, checklists, and establish an ambitious EU one-stop shop, using regulatory sandboxes and giving financial incentives. Compliance should be a path to innovation \u2014 not a bureaucratic minefield.",
            "Second, it should reconsider whether AI Act enforcement should really be left to decentralized authorities, and whether it should really be separate from the enforcement of other digital regulation. One option would be to move towards a digital enforcement agency with a clear mandate to operationalize the AI Act and related digital laws, such as the EU Digital Services Act or EU General Data Protection Regulation. Decentralized or political enforcement by member states or the Commission risk divergence and regulatory hesitation. Strong central capacity is key to legal certainty and tech investor confidence.",
            "Third, it should roll out a comprehensive \"Digital Industrial Strategy\" focused on building sovereign digital infrastructure where it matters most: AI compute, AI quality with measurable indicators, resilient cloud, trusted connectivity and applied AI. This is not about replacing global partners, but about ensuring Europe can shape \u2014 and not just consume \u2014 tomorrow's technologies and make better use of our strengths as well as strategic advantages.",
            "Each of the three steps will face fierce resistance. None will be easy. But then again, neither was the creation of the single market, the launch of the euro, nor the EU's unified response to the COVID-19 or Russia's war against Ukraine. Every milestone in European integration began in doubt and debate \u2014 and ended as a defining moment of strength and solidarity. The EU now stands before another such moment. Let us not hesitate. Let us write the next chapter in Europe's story \u2014 one defined by purpose, not pressure.",
            "All expressed views are personal and do represent neither the position of the European Parliament nor of the EPP Group.",
            "Kai Zenner is head of Office and Digital Policy Adviser for MEP Axel Voss (European People's Party) in the European Parliament.",
            "Sebastian Hallensleben is chief trust officer at Resaro. He is also co-chair of the AI risk and accountability work at OECD and chair of CEN-CENELEC AI standardization group JTC 21."
        ]
    },
    {
        "url": "https://iapp.org/news/a/beyond-data-breaches-court-ruling-signals-broader-ccpa-liability-for-tracking-technologies",
        "title": "Beyond data breaches: Court ruling signals broader CCPA liability for tracking technologies",
        "location": "North America",
        "date_published": "24 June 2025",
        "keywords": [
            "Advertising & Marketing",
            "Enforcement",
            "Law & Regulation",
            "Litigation & Case Law",
            "Privacy Program Management"
        ],
        "description": "A March ruling from the U.S. District Court for the Northern District of California could significantly reshape the scope of consumer privacy litigation under the California Consumer Privacy Act.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains. \r",
            "A March ruling from the U.S. District Court for the Northern District of California could significantly reshape the scope of consumer privacy litigation under the California Consumer Privacy Act.",
            "In Shah v. Capital One Financial Corporation, the court ruled claims can proceed based not on a data breach, but on the unauthorized disclosure of personal information via embedded tracking tools. This signals a growing judicial openness to interpreting the CCPA's private right of action more broadly to reach beyond security incidents.",
            "As plaintiffs' lawyers continue to push the boundaries of privacy enforcement, the ruling may mark a shift that expands litigation risk for companies that rely on analytics and adtech tools. The case also raises questions about how businesses approach consent, transparency and third-party data flows.",
            "In Shah v. Capital One Financial Corporation, plaintiffs alleged the company's website employed third-party tracking tools, such as Meta Pixel and Google Analytics, that collected and transmitted users' personal and financial information to advertisers without proper consent.",
            "The court denied Capital One's motion to dismiss several key claims, notably under the CCPA, California Invasion of Privacy Act, and the Electronic Communications Privacy Act. The California Invasion of Privacy Act, a California wiretapping statute, prohibits the unauthorized interception or recording of communications, and has increasingly been used in privacy litigation targeting website session replay and tracking technologies. The Electronic Communications Privacy Act, a federal law originally designed to protect against government surveillance, has similarly become a tool for plaintiffs challenging interception of electronic communications by private entities through embedded website tracking tools.",
            "Together, these statutes reflect a growing trend of litigation using older communications laws to address modern digital privacy harms.",
            "The court's decision clarified that the unauthorized disclosure of personal information through embedded tracking technologies can violate the CCPA, even absent a traditional data breach. Specifically, the court found that because the plaintiffs allege Capital One \"allowed third parties to embed trackers, such as Google and Microsoft, on its website and that these trackers transmitted Plaintiffs' personal information,\" their claims were sufficient under the CCPA.",
            "Additionally, the court upheld claims under the California Invasion of Privacy Act determining that intercepting and recording electronic communications through tracking tools without explicit consent could breach state wiretapping laws. Lastly, the court allowed claims under the Electronic Communications Privacy Act to proceed, finding that even a party to a communication may be liable if it intercepts electronic communications via tracking technologies without proper consent.",
            "The ruling underscores the necessity for businesses to reassess their data collection and sharing practices, particularly concerning third-party tracking technologies. For companies relying on adtech or other embedded third-party tools, the Shah ruling offers a reminder that compliance with privacy laws requires more than data breach response protocols.",
            "Businesses should take proactive steps to assess and address the legal risks associated with routine tracking technologies including:",
            "While this case does not establish a final ruling on the merits, it reflects a judicial willingness to entertain broader interpretations of what constitutes a data breach or unauthorized disclosure under state and federal privacy laws. The decision could encourage plaintiffs to frame privacy violations through the lens of passive data collection technologies, rather than requiring evidence of malicious hacking or theft.",
            "This shift comes amid increased regulatory scrutiny of data-sharing practices tied to behavioral advertising, analytics and cross-site tracking. Regulatory bodies, such as the U.S. Federal Trade Commission and state attorneys general, have signaled that lack of transparency around these practices may constitute unfair or deceptive conduct under consumer protection laws. Thus, litigation risk is only one side of the equation,; regulatory enforcement may also follow.",
            "As a result, businesses need to think beyond compliance checklists and adopt a more dynamic approach to data governance. This includes routine assessments of tracking tools, updates to cookie banners and consent flows and clear internal policies about data flows across platforms and partners. Legal, compliance and marketing teams should be aligned in reviewing how technology stacks impact user privacy rights under state and federal law.",
            "Jennifer Dickey, AIGP, CIPP/E, CIPP/US, CIPM, CIPT, FIP, is an attorney at Dykema."
        ]
    },
    {
        "url": "https://iapp.org/news/a/new-threads-in-the-patchwork-key-trends-in-us-comprehensive-state-privacy-law-amendments",
        "title": "New threads in the patchwork: Key trends in US comprehensive state privacy law amendments",
        "location": "North America",
        "date_published": "23 June 2025",
        "keywords": [
            "Advertising & Marketing",
            "Children's Privacy",
            "Data Subject Rights",
            "Law & Regulation",
            "Data Protection Obligations"
        ],
        "description": "As of 28 June, this year, the oldest comprehensive U.S. state privacy law \u2014 the California Consumer Privacy Act \u2014 will be old enough to enter the second grade. Even though U.S. state privacy laws are fresh-faced newcomers, they can still struggle to account for changes in the rapidly developing technological landscape.",
        "content": [
            "Editor's note: This article has been updated to reflect that Connecticut SB 1356 failed and not passed as originally indicated. ",
            "As of 28 June, this year, the oldest comprehensive U.S. state privacy law \u2014 the California Consumer Privacy Act \u2014 will be old enough to enter the second grade. Even though U.S. state privacy laws are fresh-faced newcomers, they can still struggle to account for changes in the rapidly developing technological landscape.",
            "To address shifting needs and new issues, lawmakers have proposed a flurry of amendments to the 19 comprehensive U.S. state privacy laws. While some amendments implement changes that mirror language in other states' laws, some respond to developments in public priorities or to highly public enforcement actions.",
            "Some commentators have said the law trails behind technology, but these amendments look forward, seeking to keep up with the times so legislation can be flexible enough to adapt alongside technology. Even if the bills fail, they can still signal legislators' values, priorities and the focus of their attention. Taken collectively, proposed amendments offer a window into the key trends shaping the future of U.S. state privacy legislation.",
            "Several proposed amendments aim to make exercising consumer privacy rights easier. The first way they do this is by introducing requirements around allowing consumers to use an automated tool to opt out of the sale or sharing of their personal information or to exercise similar privacy rights based on the consumer's jurisdiction. This idea goes by many names, including universal opt-out mechanisms, opt-out preference signals, consumer choice mechanisms or privacy preference tools. There are technical differences between these terms, but the general idea is the UOOM allows the consumer to automatically indicate their privacy preferences instead of clicking on cookie banners on a site-by-site basis.",
            "The most widely known UOOM tool is the Global Privacy Control, a protocol available as a browser extension or an option built into some browsers. To simplify, if a consumer has GPC enabled, their web browser automatically sends a signal with each website request that tells the site the consumer wants to exercise their privacy rights as given by their jurisdiction. If the site is configured to accept the GPC signal, then it can voluntarily choose to comply with the user's preferences. The IAPP has a resource page with more information about GPC.",
            "Most of the laws on the books implement UOOMs by allowing consumers to designate an \"authorized agent,\" which can be a person or a \"technology, including a link to an internet website, an internet browser setting or extension, or a global setting on an electronic device, that allows the consumer to indicate the consumer's intent to opt out of (personal information) processing.\" Slight variations on this wording appear in all of the state privacy laws and rules except for Indiana, Iowa, Kentucky, New Jersey, Tennessee, Utah and Virginia. Rhode Island mentions authorizing an agent but does not say whether the agent can be a technology. In states with this provision, businesses must comply with UOOM requests.",
            "Several amendments would incorporate or increase UOOM applicability in their respective laws. Tennessee's legislative session has ended, but Senate Bill 663 would have added the \"authorized agent\" provision into its law, mimicking the language seen across the other states' laws. California's Assembly Bill 566 would require all businesses that \"develop or maintain a browser\" to incorporate a UOOM setting, including mobile browsers. Texas House Bill 5495, which failed, would have added a similar provision requiring controllers that operate browsers to \"automatically recognize and comply with a consumer's global privacy control choices.\"",
            "Additionally, although Texas state privacy law already includes the \"authorized agent\" provision, HB 5495 would have added a section that defines \"global privacy control\" and requires controllers to \"treat the consumer's use of a global privacy control as a valid request submitted by the consumer not to sell, share, or disclose the consumer's personal data.\" Violators of that provision would be subject to civil penalties of up to USD5,000 per violation, with repeat offenders fined an amount that is \"sufficient to deter future violations of that section, as determined by the court.\"",
            "These amendments show lawmakers hear and understand their constituents' complaints that consent management for privacy choices is difficult and tedious. Around the world, users overexposed to repeated data processing consent requests have started to get consent fatigue, also called cookie fatigue. Some banners pop up in the middle of the screen and obscure the content the user was trying to view, which can cause frustration and lead to the user trying to click the option that makes the pop-up go away the fastest or sometimes exiting the page entirely. Other consumers don't read or don't trust promises not to process their information, so they may not indicate their actual preferences, which can tamper with marketing data or analytics.",
            "To combat cookie fatigue, the European Commission has coordinated a voluntary initiative to simplify the cookie consent process by, for example, allowing users to indicate their cookie preferences with a UOOM. These amendments take that concept a step further by imposing legal obligations on businesses to comply with the consumer's signals. As states refine how adults assert control over their data, they are also turning their attention to the privacy of younger users.",
            "Many of the U.S. state privacy amendments proposed this year would increase privacy protections for children. This reflects a broader trend in the privacy field; for example, this year the FTC published final amendments to the Children's Online Privacy Protection Rule, which went into effect 23 June 2025. At IAPP's Global Privacy Summit, Federal Trade Commissioner Melissa Holyoak explained in her keynote speech that COPPA amendments seek to give parents \"meaningful choices to protect their children, not mere fig leaves to insulate the operator from liability for design choices that expose kids to sexual predators, obscene content, violence or other such harms.\"",
            "State legislators are addressing concerns about children's privacy on social media platforms via amendments like Virginia's SB 854, now passed into law, which requires social media platforms to age-screen users and limit any minor's use of the social media to one hour per day by default, with parental consent needed to increase or decrease this limit. Connecticut's SB 1295, which also passed, requires social media platform operators to create an online safety center, a cyberbullying policy and a plan for mitigating or eliminating any heightened risk of harm to minors, which it defines expansively. It also requires platforms to refrain from using features to keep a minor scrolling as well as a setting that, by default, bars adults from sending unsolicited communications to minors.",
            "Other bills come at this from a different angle: they regulate collecting and processing children's data. Oregon's HB 2008, which passed, entirely prohibits controllers from selling a minor's data or processing their data for purposes of targeted advertising or to make legally significant decisions. It also raises the upper age limit from 15 to 16, similar to Iowa's failed Senate File 143, which would have changed the definition of \"child\" from those under 13 to those under 18. In Colorado, processors must obtain a parent or guardian's consent before processing a child's data, and a rider in SB 276 amends the Colorado Privacy Act to require consent before selling a child's data as well.",
            "In laws that regulate how controllers process a minor's data, there is a standard for when the controller can be liable that varies by jurisdiction. For example, the Montana Consumer Data Privacy Act has specific provisions that apply when a controller \"has actual knowledge\" that a consumer is a minor. Montana's SB 297 would expand that standard to when a controller \"has actual knowledge or willfully disregards\" that a consumer is a minor. Connecticut has passed SB 1295, which expands the standard even more; currently, the Connecticut Data Privacy Act encompasses when a controller \"has actual knowledge, or willfully disregards\" a consumer is a minor, but SB 1295 changes it to protect \"consumers whom such controller has actual knowledge, or knowledge fairly implied based on objective circumstances, are minors.\"",
            "Texas, which has positioned itself as a strong enforcer of its privacy laws, proposed a bill broadly limiting AI development and deployment that includes provisions to protect children. HB 149 prohibits developing or distributing an AI solely intended to produce sexually explicit deepfakes or child sexual abuse material. It also forbids intentionally developing or distributing conversational AI systems that can simulate or describe sexual conduct while impersonating or imitating a child.",
            "These are far from the only approaches legislators are taking to address increasing children's privacy. For example, some states have passed standalone age-appropriate design codes, social media addiction laws or laws strictly limiting the collection and processing of children's data. Kids aren't the only ones getting new layers of protection though; some amendments zero in on what kinds of data deserve special treatment.",
            "States are also expanding protection for sensitive data, with some specifically focusing on geolocation data. For example, Colorado's SB 25-276 expands the definition of \"precise geolocation data\" and adds precise geolocation data as a subcategory of sensitive data. This imposes additional obligations on collecting and processing geolocation data, including requiring consent before collection.",
            "Texas's HB 4636 adds \"real-time driving data\" to the definition of sensitive data. It requires controllers that sell precise geolocation data to include \"NOTICE: We may sell your precise geolocation data\" in its privacy notice. This bill follows in the wake of enforcement actions by Texas Attorney General Ken Paxton against vehicle manufacturers and insurance providers that allege widespread data collection about drivers.",
            "Similarly, Oregon's HB 3875, now passed, changes the current applicability of the law to specifically include \"motor vehicle manufacturer(s) and any affiliate of a motor vehicle manufacturer that controls or processes any personal data obtained from a consumer's use of a motor vehicle or any component of a motor vehicle\" regardless of their size. Moreover, HB 2008 from the same state would completely bar selling precise geolocation data. Oregon doesn't stop there, though \u2014 HB 3899 would forbid processing any category of sensitive data for the purpose of targeted advertising or for profiling for a legally significant decision \"whether the controller has the consumer's consent or not.\" It also proscribes selling sensitive data for any reason, with or without consent.",
            "Minnesota's failed SF 2940 would have taken a narrower approach by allowing processing and sharing sensitive data with consent, but it required that a controller acquire \"separate and distinct\" consent to process a consumer's health data. A controller would also have needed to obtain separate and distinct valid authorization to sell any category of personal data.",
            "Connecticut's SB 1356, which failed, would amend \"sensitive data\" to include similar categories as those found in California and Colorado: neural data, data revealing a disability or treatment, status as nonbinary or transgender, financial information data and government-issued ID numbers. Genetic and biometric data were already included in sensitive data, but the amendment would add information derived from genetic and biometric data.",
            "It would also significantly change the Connecticut Data Privacy Act's applicability thresholds. Instead of the law applying to entities that process the data of more than 100,000 consumers per year, SB 1356 would lower the threshold to 35,000 per year. Connecticut's law also applies to entities that process the data of more than 25,000 consumers per year and derive more than 25% of their gross revenue from selling personal data. SB 1356 would reduce that to 10,000 consumers per year and 20% of gross revenue. The bill would also add blanket inclusion for entities that control or process sensitive data or offer consumers' personal data for sale in trade and commerce.",
            "SB 1356 is just one of several amendments with the goal of tweaking what kinds of data the law protects, limiting access to that data or reducing what a controller may do with it. This current wave of bills signals a deliberate shift toward more granular and assertive data governance frameworks. Many proposals will fail, but their cumulative direction is clear: states are filling perceived regulatory voids with increasingly sophisticated privacy legislation.",
            "These laws are still relatively young, but some of them are clearly entering a new phase: refinement and maintenance. These amendments help the law grow to fit emerging technologies and priorities. Taking cues from the world around them, U.S. state privacy laws are maturing into more permanent but still evolving fixtures of the legal landscape.",
            "C. Kibby is a Westin Research Fellow for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/governor-signs-texas-responsible-artificial-intelligence-governance-act",
        "title": "Governor signs Texas Responsible Artificial Intelligence Governance Act",
        "location": "North America",
        "date_published": "23 June 2025",
        "keywords": [
            "AI Governance",
            "Data Subject Rights",
            "Employment Privacy",
            "Enforcement",
            "Law & Regulation"
        ],
        "description": "Texas became the fourth U.S. state to pass a cross-sectoral law regulating the use of artificial intelligence when Gov. Greg Abbott, R-Texas, signed House Bill 149, the Texas Responsible Artificial Intelligence Governance Act, into law 22 June.",
        "content": [
            "Texas became the fourth U.S. state to pass a cross-sectoral law regulating the use of artificial intelligence when Gov. Greg Abbott, R-Texas, signed House Bill 149, the Texas Responsible Artificial Intelligence Governance Act, into law 22 June.",
            "Amid the backdrop of a proposed federal moratorium on state governments' abilities to draft legislation regulating various applications of AI, Texas is forging ahead with some guardrails in place on the use of the technology, following on heels of AI governance-related laws in California, Colorado and Utah. The TRAIGA enters into force 1 Jan. 2026, one month before the Colorado AI Act.",
            "State Rep. Giovanni Capriglione, R-Texas, sponsored the TRAIGA in the House and identified notable differences between Texas' approach versus that of Colorado. He told the IAPP, while Colorado's law seeks to regulate high-risk uses of AI, Texas' law aims to prevent and respond to harms caused by misuse of AI systems.",
            "Capriglione opined the broader push among states to explore passing AI regulations was partly borne out of the recognition they were behind on passing consumer data privacy laws in the past. He said he wanted Texas to be proactive in attempting to get ahead of the rapidly changing AI ecosystem to have some baseline guardrails in place going forward.",
            "\"We didn't want to be overburdensome, and we wanted to try to do this in a way that is reasonable and protects people from some of the biggest harms,\" Capriglione said. \"We thought that we had to hit the very high-level issues, and that means looking at some of the outputs that are problematic, making sure there are some disclosure requirements, we were updating our privacy laws and that we were listening to industry.\"",
            "Key provisions of the TRAIGA include disclosure requirements for state agencies when citizens interact with AI tools a specific agency may be using, bans on capturing biometric identifiers without consent and AI developers are prohibited from creating systems designed to manipulate human behavior, make discriminatory decisions and produce deepfakes that exploit children.",
            "The TRAIGA also establishes a regulatory sandbox contained within the newly created Artificial Intelligence Council under the state Department of Information Resources for companies to test AI models without fear of violating the law.",
            "Capriglione said the TRAIGA will likely have different impacts on public entities and the private sector.",
            "Under the law, public-sector entities' use of AI will be more heavily scrutinized to ensure systems being used uphold citizens' rights. In the private sector, Capriglione indicated much of TRAIGA was written to prevent businesses from knowingly deploying AI systems that cause harm to consumers, he said.",
            "\"Making sure the government is restricted in how it uses AI is actually easier to get done because it's a public process,\" he said. \"Agencies are going to have to come up with acceptable use policies and ethics on how each individual agency may or may not want its employees to use AI based on the risk levels.\"",
            "Latham & Watkins Partner Robert Brown, CIPP/US, CIPM, PLS, said a key dynamic of the TRAIGA is its \"intent element,\" which means entities developing and deploying an AI model would have to have been found that they disregarded key requirements of the law while creating or using the model to be found in violation.",
            "\"Governmental agencies will feel the greatest impact, as many of the requirements under the final version of the bill apply exclusively to them,\" Brown told the IAPP. \"The impact on private companies will be more limited \u2014 the law prohibits them from developing or deploying AI systems for various illicit purposes, but critically, each of these prohibitions includes an 'intent' element.\"",
            "The TRAIGA empowers state agencies to issue fines up to USD100,000 to any licensed individuals or organizations for violations caused by misuse of their AI systems.",
            "Capriglione said the law, as written, allows for per-violation penalties similar to how the Illinois Biometric Information Privacy Act functioned prior to reforms passed in 2024 that removed the per-scan violations, due to in part to significant fines issued to businesses for noncompliance. If covered entities do not rectify a violation within a 60-day cure period, the attorney general may assess an administrative fine \"of not less than USD80,000 and not more than USD200,000 per violation,\" according to the statute.",
            "The per-violation nature of enforcement could prove costly. Capriglione outlined a hypothetical scenario where if an insurance company deployed an AI tool that evaluates homeowners' viability to receive a policy and wrongfully denied 5,000 of them insurance, that insurance company could be liable for each erroneous denial their AI tool rendered.",
            "However, he also said the intent of the TRAIGA is not to grossly penalize businesses using AI and includes provisions to ensure that good faith compliance efforts on the part of AI deployers resulting in unexpected violations do not receive major fines. Unlike the BIPA, the TRAIGA does not allow for a private right of action.",
            "\"We allow for an opportunity to cure (the unlawful activity),\" Capriglione said. \"We provide sufficient time for someone to go in and fix their violation. And that is a benefit to the business, which is as long as they fix the problem, they'll avoid penalties.\"",
            "Brown said much of how the TRAIGA's penalties may ultimately be decided on a case-by-case basis by the state attorney general's office.",
            "\"While we don't yet know how the Texas Attorney General will interpret TRAIGA, the prohibitions under the law apply to the development, deployment, and/or distribution of AI systems for certain purposes,\" Brown said. \"The law is to be 'broadly construed,' and the attorney general has not been shy about bringing enforcement actions centered on the use of AI technologies in recent years. It's also worth noting that unlike under BIPA, TRAIGA is exclusively enforced by the Attorney General and does not provide a private right of action.\"\u00a0",
            "Still, the prospect of Congress approving a 10-year ban on enforcing AI legislation raises uncertainty over TRAIGA's enforcement and other states' AI legislative work.",
            "Capriglione said the majority of the work on TRAIGA and its filing were completed before Congress floated moratorium in its reconciliation bill. He does not support federal lawmakers including the AI provision because the proposals so far are simultaneously too vague and too proscriptive. For example, he said the moratorium's lack of clarity could prevent municipalities from approving data centers being constructed.",
            "Regardless of what the final language of the moratorium may say, Capriglione said it will likely lead to \"thousands of court cases,\" if it passes.",
            "\"I appreciate all the federal government does, however they have not really been able to work on super complicated, technical things like this for a long time and actually get them passed,\" he said. \"I would make the case (Congress) is still quite a ways way from having something in place that will sufficiently protect my constituents here in the state of Texas.\"",
            "Brown believes the final iteration of TRAIGA was written with an eye toward the moratorium, although he doesn't think the law in any form will remain in place if Congress ultimately passes its reconciliation bill with the moratorium included.",
            "\"It's possible one of the goals of scaling back the law was to placate federal lawmakers enough to avoid a complete moratorium on state AI laws,\" Brown said. \"Given how broadly the proposed moratorium is drafted, there's really no version of this bill that could survive it.\"",
            "Capriglione also said while the TRAIGA is the first AI governance law passed in Texas, it is unlikely to be the last governing how the technology is used within the state.",
            "\"I've spent the last six years working on these policy issues, and it's important that we continue our work because the technology is just changing so quickly,\u201d Capriglione said. \"I'm happy to work with anybody, anywhere, any time on crafting really good AI policy.\"",
            "Alex LaCasse is a staff writer for the IAPP."
        ]
    },
    {
        "url": "https://iapp.org/news/a/a-view-from-dc-former-ftc-chair-khan-reflects-on-her-privacy-legacy",
        "title": "A View from DC: Former FTC Chair Khan reflects on her privacy legacy",
        "location": "North America",
        "date_published": "20 June 2025",
        "keywords": [
            "Enforcement",
            "Law & Regulation"
        ],
        "description": "In the fields of battle and regulatory enforcement alike, the thoughtful accumulation of incremental victories matters a lot toward shaping final outcomes. Without strategy, there can be no lasting path to victory.",
        "content": [
            "Editor's note: The IAPP is policy neutral. We publish contributed opinion and analysis pieces to enable our members to hear a broad spectrum of views in our domains.",
            "In the fields of battle and regulatory enforcement alike, the thoughtful accumulation of incremental victories matters a lot toward shaping final outcomes. Without strategy, there can be no lasting path to victory.",
            "As Sun Tzu wrote, \"Victorious warriors win first and then go to war, while defeated warriors go to war first and then seek to win.\u201d",
            "A cohesive strategy matters just as much in the ongoing policy debates over how the U.S. Federal Trade Commission's consumer protection authorities should be used in the effort to influence our understanding of reasonable privacy and cybersecurity practices.",
            "As it happens, not all history is written by the victors. Exercising a solid attempt to shape how academics and practitioners remember her term at the FTC, former Chair Lina Khan has published a major feature in the Stanford Law Review. Alongside Samuel Levine and Stephanie Nguyen, her director of consumer protection and chief technologist, respectively, Khan seeks to explain the cohesive strategy behind the data privacy efforts she oversaw at the commission during her tenure.",
            "On reflection, the trodden path always looks clearer than the path before us. In reality, FTC enforcement always represents the coming together of many factors \u2014 from staff interest and expertise to commissioner buy-in and the strategic engagement of agency leadership \u2014 all of which evolve and iterate over time. Nevertheless, the authors' accumulated learnings and strategic thinking on privacy provides a meaningful reflection and will serve as an important contribution to the practice of privacy in the consumer protection context. Though echoing the public statements of the authors across their years at the agency, the analysis represents the first time that their final strategies have been so coherently revealed and described.",
            "Overall, Khan, Levine and Nguyen characterize their FTC privacy legacy as one that shifted the agency's focus from \"procedural\" enforcement of notice and choice to \"substantive\" interventions into the root harms of the privacy practices undergirding the modern \"commercial surveillance\" ecosystem.",
            "To illustrate this shift, they focus on four areas of \"Biden-era\" privacy enforcement priority.",
            "\"First, the Commission would examine and target the upstream drivers of data abuses, focusing on the underlying collection of data and the business models driving this unchecked surveillance. Second, the Commission would scrutinize how firms design online architecture, especially 'dark patterns' that manipulate people and cost consumers money or time. Third, the Commission would recognize children and teens as a distinct category of consumers requiring strong protections. Finally, responding to the failures of self-regulation, the Commission would focus on deterrence, crafting remedies that disincentivize lawbreaking rather than encourage it.\"",
            "To some extent, this may seem like a grab bag of policy achievements, but Khan and her colleagues are careful to explain how each of these four \"pillars\" relate to what they see as their overall privacy legacy. As they see it, \"The FTC's consumer protection work these last few years modeled a break from the laissez-faire framework that had largely persisted since the Reagan revolution. By pursuing an approach rooted in fidelity to the FTC's full suite of authorities and the market realities of the digital age, the agency set out a new paradigm for consumer protection.\"",
            "The primary tool toward achieving this shift \u2014 as I wrote about frequently during the Khan FTC \u2014 has been the expanded use of unfairness authority under the FTC Act. With this in mind, a large portion of the meaty analysis in the law review article is focused on the shifting philosophy around the use of unfairness and how it was applied to missteps throughout the data life cycle. The title of the piece, in fact, is \"After Notice and Choice: Reinvigorating 'Unfairness' to Rein In Data Abuses.\"",
            "Beyond these helpful contributions, the law review feature also spends much time contextualizing the Khan FTC's efforts against the backdrop of prior FTC history. It paints a stark picture of the unwillingness of many prior FTC commissioners to take an expansive view of the agency\u2019s authority over privacy practices, especially through the use of unfairness. One quote that was new to me: when in 2001 Commissioner Thomas Leary called concerns around online privacy \"a new hysteria.\"",
            "Overall, Khan believes one of the chief failures of prior FTC privacy philosophies was the \"narrow focus on downstream harms rather than upstream data practices.\" This is best illustrated by the Do Not Call registry and identity theft enforcement efforts, which the authors go so far as to say were a distraction from the potential to shape meaningful data collection and use practices at the outset, by instead focusing on the end harms of an increasingly predatory data ecosystem.",
            "Oddly, the article ignores some of the important precedent-building work for the expanding use of unfairness during the FTC of the 2010s \u2014 such as through the landmark Vizio enforcement \u2014 but it rightly highlights how the Khan FTC began to bring unfairness to its full potential as a tool to curtail harmful data practices when privacy notices alone are not enough for consumers to avoid injury.",
            "Finally and importantly, the article includes a number of reflections on how to build lasting enforcement capacity at the FTC. Of course, this comes at a time when the extent of privacy's future prioritization at the agency is subject to debate.",
            "Khan raises this uncertainty, even as she highlights the potential of the strategy she helped to oversee. As she succinctly puts it, \"The FTC's new strategy remains nascent \u2014 and its institutional durability remains an open question.\"",
            "Please send feedback, updates and legacy reflections to cobun@iapp.org.",
            "Cobun Zweifel-Keegan, CIPP/US, CIPM, is the managing director, Washington, D.C., for the IAPP.",
            "This article originally appeared in The Daily Dashboard and U.S. Privacy Digest,\u00a0free weekly IAPP newsletters. Subscriptions to this and other IAPP newsletters can be found\u00a0here."
        ]
    }
]